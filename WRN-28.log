I0129 22:47:02.879209  7239 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I0129 22:47:02.880045  7239 caffe.cpp:223] GPU 0: GeForce GTX 1080 Ti
I0129 22:47:02.880674  7239 caffe.cpp:223] GPU 1: GeForce GTX 1080 Ti
I0129 22:47:02.881541  7239 caffe.cpp:223] GPU 2: GeForce GTX 1080 Ti
I0129 22:47:02.882401  7239 caffe.cpp:223] GPU 3: GeForce GTX 1080 Ti
I0129 22:47:03.234357  7239 solver.cpp:44] Initializing solver from parameters: 
test_iter: 200
test_interval: 400
base_lr: 0.1
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.2
momentum: 0.9
weight_decay: 0.0005
snapshot: 12000
snapshot_prefix: "examples/bao/WRN-28"
solver_mode: GPU
device_id: 0
net: "examples/bao/WRN-28.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 24000
stepvalue: 48000
stepvalue: 64000
type: "Nesterov"
I0129 22:47:03.234493  7239 solver.cpp:87] Creating training net from net file: examples/bao/WRN-28.prototxt
I0129 22:47:03.235082  7239 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/bao/WRN-28.prototxt
I0129 22:47:03.235095  7239 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0129 22:47:03.235226  7239 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0129 22:47:03.235275  7239 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0129 22:47:03.235729  7239 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_file: "data/cifar10/pad4_mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_pad4_train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution29"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution31"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise14"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I0129 22:47:03.236222  7239 layer_factory.hpp:77] Creating layer Data1
I0129 22:47:03.236331  7239 db_lmdb.cpp:35] Opened lmdb data/cifar10/cifar10_pad4_train_lmdb
I0129 22:47:03.236356  7239 net.cpp:84] Creating Layer Data1
I0129 22:47:03.236366  7239 net.cpp:380] Data1 -> Data1
I0129 22:47:03.236387  7239 net.cpp:380] Data1 -> Data2
I0129 22:47:03.236398  7239 data_transformer.cpp:25] Loading mean file from: data/cifar10/pad4_mean.binaryproto
I0129 22:47:03.238008  7239 data_layer.cpp:45] output data size: 32,3,32,32
I0129 22:47:03.239398  7239 net.cpp:122] Setting up Data1
I0129 22:47:03.239413  7239 net.cpp:129] Top shape: 32 3 32 32 (98304)
I0129 22:47:03.239419  7239 net.cpp:129] Top shape: 32 (32)
I0129 22:47:03.239423  7239 net.cpp:137] Memory required for data: 393344
I0129 22:47:03.239429  7239 layer_factory.hpp:77] Creating layer Convolution1
I0129 22:47:03.239446  7239 net.cpp:84] Creating Layer Convolution1
I0129 22:47:03.239452  7239 net.cpp:406] Convolution1 <- Data1
I0129 22:47:03.239464  7239 net.cpp:380] Convolution1 -> Convolution1
I0129 22:47:03.443248  7239 net.cpp:122] Setting up Convolution1
I0129 22:47:03.443274  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.443277  7239 net.cpp:137] Memory required for data: 21364864
I0129 22:47:03.443298  7239 layer_factory.hpp:77] Creating layer BatchNorm1
I0129 22:47:03.443310  7239 net.cpp:84] Creating Layer BatchNorm1
I0129 22:47:03.443315  7239 net.cpp:406] BatchNorm1 <- Convolution1
I0129 22:47:03.443320  7239 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0129 22:47:03.443459  7239 net.cpp:122] Setting up BatchNorm1
I0129 22:47:03.443465  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.443467  7239 net.cpp:137] Memory required for data: 42336384
I0129 22:47:03.443475  7239 layer_factory.hpp:77] Creating layer Scale1
I0129 22:47:03.443482  7239 net.cpp:84] Creating Layer Scale1
I0129 22:47:03.443485  7239 net.cpp:406] Scale1 <- Convolution1
I0129 22:47:03.443490  7239 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0129 22:47:03.443521  7239 layer_factory.hpp:77] Creating layer Scale1
I0129 22:47:03.443594  7239 net.cpp:122] Setting up Scale1
I0129 22:47:03.443600  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.443603  7239 net.cpp:137] Memory required for data: 63307904
I0129 22:47:03.443608  7239 layer_factory.hpp:77] Creating layer ReLU1
I0129 22:47:03.443614  7239 net.cpp:84] Creating Layer ReLU1
I0129 22:47:03.443616  7239 net.cpp:406] ReLU1 <- Convolution1
I0129 22:47:03.443619  7239 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I0129 22:47:03.443752  7239 net.cpp:122] Setting up ReLU1
I0129 22:47:03.443758  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.443760  7239 net.cpp:137] Memory required for data: 84279424
I0129 22:47:03.443763  7239 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0129 22:47:03.443768  7239 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I0129 22:47:03.443770  7239 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I0129 22:47:03.443774  7239 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0129 22:47:03.443780  7239 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0129 22:47:03.443810  7239 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I0129 22:47:03.443815  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.443819  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.443821  7239 net.cpp:137] Memory required for data: 126222464
I0129 22:47:03.443825  7239 layer_factory.hpp:77] Creating layer Convolution2
I0129 22:47:03.443832  7239 net.cpp:84] Creating Layer Convolution2
I0129 22:47:03.443835  7239 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I0129 22:47:03.443853  7239 net.cpp:380] Convolution2 -> Convolution2
I0129 22:47:03.447315  7239 net.cpp:122] Setting up Convolution2
I0129 22:47:03.447327  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.447331  7239 net.cpp:137] Memory required for data: 147193984
I0129 22:47:03.447340  7239 layer_factory.hpp:77] Creating layer BatchNorm2
I0129 22:47:03.447345  7239 net.cpp:84] Creating Layer BatchNorm2
I0129 22:47:03.447350  7239 net.cpp:406] BatchNorm2 <- Convolution2
I0129 22:47:03.447353  7239 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0129 22:47:03.447481  7239 net.cpp:122] Setting up BatchNorm2
I0129 22:47:03.447487  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.447489  7239 net.cpp:137] Memory required for data: 168165504
I0129 22:47:03.447494  7239 layer_factory.hpp:77] Creating layer Scale2
I0129 22:47:03.447501  7239 net.cpp:84] Creating Layer Scale2
I0129 22:47:03.447505  7239 net.cpp:406] Scale2 <- Convolution2
I0129 22:47:03.447509  7239 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0129 22:47:03.447533  7239 layer_factory.hpp:77] Creating layer Scale2
I0129 22:47:03.447600  7239 net.cpp:122] Setting up Scale2
I0129 22:47:03.447607  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.447608  7239 net.cpp:137] Memory required for data: 189137024
I0129 22:47:03.447613  7239 layer_factory.hpp:77] Creating layer ReLU2
I0129 22:47:03.447616  7239 net.cpp:84] Creating Layer ReLU2
I0129 22:47:03.447619  7239 net.cpp:406] ReLU2 <- Convolution2
I0129 22:47:03.447623  7239 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I0129 22:47:03.447747  7239 net.cpp:122] Setting up ReLU2
I0129 22:47:03.447754  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.447757  7239 net.cpp:137] Memory required for data: 210108544
I0129 22:47:03.447759  7239 layer_factory.hpp:77] Creating layer Convolution3
I0129 22:47:03.447767  7239 net.cpp:84] Creating Layer Convolution3
I0129 22:47:03.447769  7239 net.cpp:406] Convolution3 <- Convolution2
I0129 22:47:03.447773  7239 net.cpp:380] Convolution3 -> Convolution3
I0129 22:47:03.450495  7239 net.cpp:122] Setting up Convolution3
I0129 22:47:03.450507  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.450510  7239 net.cpp:137] Memory required for data: 231080064
I0129 22:47:03.450516  7239 layer_factory.hpp:77] Creating layer BatchNorm3
I0129 22:47:03.450522  7239 net.cpp:84] Creating Layer BatchNorm3
I0129 22:47:03.450526  7239 net.cpp:406] BatchNorm3 <- Convolution3
I0129 22:47:03.450531  7239 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0129 22:47:03.450661  7239 net.cpp:122] Setting up BatchNorm3
I0129 22:47:03.450667  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.450670  7239 net.cpp:137] Memory required for data: 252051584
I0129 22:47:03.450677  7239 layer_factory.hpp:77] Creating layer Scale3
I0129 22:47:03.450683  7239 net.cpp:84] Creating Layer Scale3
I0129 22:47:03.450685  7239 net.cpp:406] Scale3 <- Convolution3
I0129 22:47:03.450690  7239 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0129 22:47:03.450716  7239 layer_factory.hpp:77] Creating layer Scale3
I0129 22:47:03.450793  7239 net.cpp:122] Setting up Scale3
I0129 22:47:03.450800  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.450803  7239 net.cpp:137] Memory required for data: 273023104
I0129 22:47:03.450806  7239 layer_factory.hpp:77] Creating layer Eltwise1
I0129 22:47:03.450814  7239 net.cpp:84] Creating Layer Eltwise1
I0129 22:47:03.450816  7239 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0129 22:47:03.450819  7239 net.cpp:406] Eltwise1 <- Convolution3
I0129 22:47:03.450824  7239 net.cpp:380] Eltwise1 -> Eltwise1
I0129 22:47:03.450842  7239 net.cpp:122] Setting up Eltwise1
I0129 22:47:03.450847  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.450850  7239 net.cpp:137] Memory required for data: 293994624
I0129 22:47:03.450851  7239 layer_factory.hpp:77] Creating layer ReLU3
I0129 22:47:03.450855  7239 net.cpp:84] Creating Layer ReLU3
I0129 22:47:03.450868  7239 net.cpp:406] ReLU3 <- Eltwise1
I0129 22:47:03.450872  7239 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I0129 22:47:03.450996  7239 net.cpp:122] Setting up ReLU3
I0129 22:47:03.451004  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.451005  7239 net.cpp:137] Memory required for data: 314966144
I0129 22:47:03.451007  7239 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0129 22:47:03.451012  7239 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I0129 22:47:03.451015  7239 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I0129 22:47:03.451019  7239 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0129 22:47:03.451025  7239 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0129 22:47:03.451050  7239 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I0129 22:47:03.451056  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.451058  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.451061  7239 net.cpp:137] Memory required for data: 356909184
I0129 22:47:03.451063  7239 layer_factory.hpp:77] Creating layer Convolution4
I0129 22:47:03.451071  7239 net.cpp:84] Creating Layer Convolution4
I0129 22:47:03.451074  7239 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0129 22:47:03.451079  7239 net.cpp:380] Convolution4 -> Convolution4
I0129 22:47:03.454538  7239 net.cpp:122] Setting up Convolution4
I0129 22:47:03.454551  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.454555  7239 net.cpp:137] Memory required for data: 377880704
I0129 22:47:03.454560  7239 layer_factory.hpp:77] Creating layer BatchNorm4
I0129 22:47:03.454566  7239 net.cpp:84] Creating Layer BatchNorm4
I0129 22:47:03.454571  7239 net.cpp:406] BatchNorm4 <- Convolution4
I0129 22:47:03.454574  7239 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0129 22:47:03.454706  7239 net.cpp:122] Setting up BatchNorm4
I0129 22:47:03.454711  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.454715  7239 net.cpp:137] Memory required for data: 398852224
I0129 22:47:03.454725  7239 layer_factory.hpp:77] Creating layer Scale4
I0129 22:47:03.454730  7239 net.cpp:84] Creating Layer Scale4
I0129 22:47:03.454732  7239 net.cpp:406] Scale4 <- Convolution4
I0129 22:47:03.454736  7239 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0129 22:47:03.454763  7239 layer_factory.hpp:77] Creating layer Scale4
I0129 22:47:03.454838  7239 net.cpp:122] Setting up Scale4
I0129 22:47:03.454843  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.454845  7239 net.cpp:137] Memory required for data: 419823744
I0129 22:47:03.454849  7239 layer_factory.hpp:77] Creating layer ReLU4
I0129 22:47:03.454854  7239 net.cpp:84] Creating Layer ReLU4
I0129 22:47:03.454856  7239 net.cpp:406] ReLU4 <- Convolution4
I0129 22:47:03.454860  7239 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I0129 22:47:03.454998  7239 net.cpp:122] Setting up ReLU4
I0129 22:47:03.455008  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.455010  7239 net.cpp:137] Memory required for data: 440795264
I0129 22:47:03.455013  7239 layer_factory.hpp:77] Creating layer Convolution5
I0129 22:47:03.455020  7239 net.cpp:84] Creating Layer Convolution5
I0129 22:47:03.455024  7239 net.cpp:406] Convolution5 <- Convolution4
I0129 22:47:03.455029  7239 net.cpp:380] Convolution5 -> Convolution5
I0129 22:47:03.457873  7239 net.cpp:122] Setting up Convolution5
I0129 22:47:03.457885  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.457890  7239 net.cpp:137] Memory required for data: 461766784
I0129 22:47:03.457895  7239 layer_factory.hpp:77] Creating layer BatchNorm5
I0129 22:47:03.457901  7239 net.cpp:84] Creating Layer BatchNorm5
I0129 22:47:03.457906  7239 net.cpp:406] BatchNorm5 <- Convolution5
I0129 22:47:03.457911  7239 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0129 22:47:03.458055  7239 net.cpp:122] Setting up BatchNorm5
I0129 22:47:03.458061  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.458063  7239 net.cpp:137] Memory required for data: 482738304
I0129 22:47:03.458082  7239 layer_factory.hpp:77] Creating layer Scale5
I0129 22:47:03.458088  7239 net.cpp:84] Creating Layer Scale5
I0129 22:47:03.458092  7239 net.cpp:406] Scale5 <- Convolution5
I0129 22:47:03.458096  7239 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0129 22:47:03.458125  7239 layer_factory.hpp:77] Creating layer Scale5
I0129 22:47:03.458202  7239 net.cpp:122] Setting up Scale5
I0129 22:47:03.458209  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.458210  7239 net.cpp:137] Memory required for data: 503709824
I0129 22:47:03.458214  7239 layer_factory.hpp:77] Creating layer Eltwise2
I0129 22:47:03.458220  7239 net.cpp:84] Creating Layer Eltwise2
I0129 22:47:03.458223  7239 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0129 22:47:03.458227  7239 net.cpp:406] Eltwise2 <- Convolution5
I0129 22:47:03.458232  7239 net.cpp:380] Eltwise2 -> Eltwise2
I0129 22:47:03.458248  7239 net.cpp:122] Setting up Eltwise2
I0129 22:47:03.458253  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.458256  7239 net.cpp:137] Memory required for data: 524681344
I0129 22:47:03.458257  7239 layer_factory.hpp:77] Creating layer ReLU5
I0129 22:47:03.458261  7239 net.cpp:84] Creating Layer ReLU5
I0129 22:47:03.458264  7239 net.cpp:406] ReLU5 <- Eltwise2
I0129 22:47:03.458269  7239 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I0129 22:47:03.458740  7239 net.cpp:122] Setting up ReLU5
I0129 22:47:03.458751  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.458755  7239 net.cpp:137] Memory required for data: 545652864
I0129 22:47:03.458757  7239 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0129 22:47:03.458761  7239 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I0129 22:47:03.458765  7239 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I0129 22:47:03.458770  7239 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0129 22:47:03.458777  7239 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0129 22:47:03.458811  7239 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I0129 22:47:03.458815  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.458819  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.458822  7239 net.cpp:137] Memory required for data: 587595904
I0129 22:47:03.458823  7239 layer_factory.hpp:77] Creating layer Convolution6
I0129 22:47:03.458832  7239 net.cpp:84] Creating Layer Convolution6
I0129 22:47:03.458835  7239 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0129 22:47:03.458840  7239 net.cpp:380] Convolution6 -> Convolution6
I0129 22:47:03.462160  7239 net.cpp:122] Setting up Convolution6
I0129 22:47:03.462172  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.462177  7239 net.cpp:137] Memory required for data: 608567424
I0129 22:47:03.462182  7239 layer_factory.hpp:77] Creating layer BatchNorm6
I0129 22:47:03.462188  7239 net.cpp:84] Creating Layer BatchNorm6
I0129 22:47:03.462193  7239 net.cpp:406] BatchNorm6 <- Convolution6
I0129 22:47:03.462196  7239 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0129 22:47:03.462343  7239 net.cpp:122] Setting up BatchNorm6
I0129 22:47:03.462349  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.462352  7239 net.cpp:137] Memory required for data: 629538944
I0129 22:47:03.462357  7239 layer_factory.hpp:77] Creating layer Scale6
I0129 22:47:03.462361  7239 net.cpp:84] Creating Layer Scale6
I0129 22:47:03.462364  7239 net.cpp:406] Scale6 <- Convolution6
I0129 22:47:03.462368  7239 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0129 22:47:03.462397  7239 layer_factory.hpp:77] Creating layer Scale6
I0129 22:47:03.462476  7239 net.cpp:122] Setting up Scale6
I0129 22:47:03.462481  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.462484  7239 net.cpp:137] Memory required for data: 650510464
I0129 22:47:03.462488  7239 layer_factory.hpp:77] Creating layer ReLU6
I0129 22:47:03.462492  7239 net.cpp:84] Creating Layer ReLU6
I0129 22:47:03.462496  7239 net.cpp:406] ReLU6 <- Convolution6
I0129 22:47:03.462512  7239 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I0129 22:47:03.462930  7239 net.cpp:122] Setting up ReLU6
I0129 22:47:03.462942  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.462946  7239 net.cpp:137] Memory required for data: 671481984
I0129 22:47:03.462949  7239 layer_factory.hpp:77] Creating layer Convolution7
I0129 22:47:03.462957  7239 net.cpp:84] Creating Layer Convolution7
I0129 22:47:03.462960  7239 net.cpp:406] Convolution7 <- Convolution6
I0129 22:47:03.462965  7239 net.cpp:380] Convolution7 -> Convolution7
I0129 22:47:03.465768  7239 net.cpp:122] Setting up Convolution7
I0129 22:47:03.465780  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.465783  7239 net.cpp:137] Memory required for data: 692453504
I0129 22:47:03.465788  7239 layer_factory.hpp:77] Creating layer BatchNorm7
I0129 22:47:03.465795  7239 net.cpp:84] Creating Layer BatchNorm7
I0129 22:47:03.465800  7239 net.cpp:406] BatchNorm7 <- Convolution7
I0129 22:47:03.465803  7239 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0129 22:47:03.465950  7239 net.cpp:122] Setting up BatchNorm7
I0129 22:47:03.465956  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.465958  7239 net.cpp:137] Memory required for data: 713425024
I0129 22:47:03.465965  7239 layer_factory.hpp:77] Creating layer Scale7
I0129 22:47:03.465972  7239 net.cpp:84] Creating Layer Scale7
I0129 22:47:03.465976  7239 net.cpp:406] Scale7 <- Convolution7
I0129 22:47:03.465981  7239 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0129 22:47:03.466011  7239 layer_factory.hpp:77] Creating layer Scale7
I0129 22:47:03.466091  7239 net.cpp:122] Setting up Scale7
I0129 22:47:03.466097  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.466099  7239 net.cpp:137] Memory required for data: 734396544
I0129 22:47:03.466104  7239 layer_factory.hpp:77] Creating layer Eltwise3
I0129 22:47:03.466109  7239 net.cpp:84] Creating Layer Eltwise3
I0129 22:47:03.466111  7239 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0129 22:47:03.466115  7239 net.cpp:406] Eltwise3 <- Convolution7
I0129 22:47:03.466118  7239 net.cpp:380] Eltwise3 -> Eltwise3
I0129 22:47:03.466137  7239 net.cpp:122] Setting up Eltwise3
I0129 22:47:03.466143  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.466146  7239 net.cpp:137] Memory required for data: 755368064
I0129 22:47:03.466150  7239 layer_factory.hpp:77] Creating layer ReLU7
I0129 22:47:03.466152  7239 net.cpp:84] Creating Layer ReLU7
I0129 22:47:03.466156  7239 net.cpp:406] ReLU7 <- Eltwise3
I0129 22:47:03.466158  7239 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I0129 22:47:03.466295  7239 net.cpp:122] Setting up ReLU7
I0129 22:47:03.466301  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.466303  7239 net.cpp:137] Memory required for data: 776339584
I0129 22:47:03.466306  7239 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0129 22:47:03.466310  7239 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I0129 22:47:03.466312  7239 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I0129 22:47:03.466318  7239 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0129 22:47:03.466325  7239 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0129 22:47:03.466354  7239 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I0129 22:47:03.466359  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.466362  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.466364  7239 net.cpp:137] Memory required for data: 818282624
I0129 22:47:03.466367  7239 layer_factory.hpp:77] Creating layer Convolution8
I0129 22:47:03.466374  7239 net.cpp:84] Creating Layer Convolution8
I0129 22:47:03.466377  7239 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0129 22:47:03.466383  7239 net.cpp:380] Convolution8 -> Convolution8
I0129 22:47:03.469924  7239 net.cpp:122] Setting up Convolution8
I0129 22:47:03.469936  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.469939  7239 net.cpp:137] Memory required for data: 839254144
I0129 22:47:03.469954  7239 layer_factory.hpp:77] Creating layer BatchNorm8
I0129 22:47:03.469962  7239 net.cpp:84] Creating Layer BatchNorm8
I0129 22:47:03.469965  7239 net.cpp:406] BatchNorm8 <- Convolution8
I0129 22:47:03.469969  7239 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0129 22:47:03.470118  7239 net.cpp:122] Setting up BatchNorm8
I0129 22:47:03.470124  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.470125  7239 net.cpp:137] Memory required for data: 860225664
I0129 22:47:03.470130  7239 layer_factory.hpp:77] Creating layer Scale8
I0129 22:47:03.470137  7239 net.cpp:84] Creating Layer Scale8
I0129 22:47:03.470140  7239 net.cpp:406] Scale8 <- Convolution8
I0129 22:47:03.470144  7239 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0129 22:47:03.470172  7239 layer_factory.hpp:77] Creating layer Scale8
I0129 22:47:03.470252  7239 net.cpp:122] Setting up Scale8
I0129 22:47:03.470258  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.470260  7239 net.cpp:137] Memory required for data: 881197184
I0129 22:47:03.470264  7239 layer_factory.hpp:77] Creating layer ReLU8
I0129 22:47:03.470270  7239 net.cpp:84] Creating Layer ReLU8
I0129 22:47:03.470273  7239 net.cpp:406] ReLU8 <- Convolution8
I0129 22:47:03.470276  7239 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I0129 22:47:03.470417  7239 net.cpp:122] Setting up ReLU8
I0129 22:47:03.470424  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.470427  7239 net.cpp:137] Memory required for data: 902168704
I0129 22:47:03.470429  7239 layer_factory.hpp:77] Creating layer Convolution9
I0129 22:47:03.470437  7239 net.cpp:84] Creating Layer Convolution9
I0129 22:47:03.470440  7239 net.cpp:406] Convolution9 <- Convolution8
I0129 22:47:03.470451  7239 net.cpp:380] Convolution9 -> Convolution9
I0129 22:47:03.473338  7239 net.cpp:122] Setting up Convolution9
I0129 22:47:03.473352  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.473356  7239 net.cpp:137] Memory required for data: 923140224
I0129 22:47:03.473361  7239 layer_factory.hpp:77] Creating layer BatchNorm9
I0129 22:47:03.473367  7239 net.cpp:84] Creating Layer BatchNorm9
I0129 22:47:03.473371  7239 net.cpp:406] BatchNorm9 <- Convolution9
I0129 22:47:03.473376  7239 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0129 22:47:03.473525  7239 net.cpp:122] Setting up BatchNorm9
I0129 22:47:03.473531  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.473532  7239 net.cpp:137] Memory required for data: 944111744
I0129 22:47:03.473538  7239 layer_factory.hpp:77] Creating layer Scale9
I0129 22:47:03.473544  7239 net.cpp:84] Creating Layer Scale9
I0129 22:47:03.473547  7239 net.cpp:406] Scale9 <- Convolution9
I0129 22:47:03.473551  7239 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0129 22:47:03.473579  7239 layer_factory.hpp:77] Creating layer Scale9
I0129 22:47:03.473659  7239 net.cpp:122] Setting up Scale9
I0129 22:47:03.473664  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.473666  7239 net.cpp:137] Memory required for data: 965083264
I0129 22:47:03.473671  7239 layer_factory.hpp:77] Creating layer Eltwise4
I0129 22:47:03.473677  7239 net.cpp:84] Creating Layer Eltwise4
I0129 22:47:03.473680  7239 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0129 22:47:03.473683  7239 net.cpp:406] Eltwise4 <- Convolution9
I0129 22:47:03.473688  7239 net.cpp:380] Eltwise4 -> Eltwise4
I0129 22:47:03.473706  7239 net.cpp:122] Setting up Eltwise4
I0129 22:47:03.473711  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.473712  7239 net.cpp:137] Memory required for data: 986054784
I0129 22:47:03.473716  7239 layer_factory.hpp:77] Creating layer ReLU9
I0129 22:47:03.473718  7239 net.cpp:84] Creating Layer ReLU9
I0129 22:47:03.473721  7239 net.cpp:406] ReLU9 <- Eltwise4
I0129 22:47:03.473726  7239 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I0129 22:47:03.473862  7239 net.cpp:122] Setting up ReLU9
I0129 22:47:03.473870  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.473881  7239 net.cpp:137] Memory required for data: 1007026304
I0129 22:47:03.473884  7239 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0129 22:47:03.473891  7239 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I0129 22:47:03.473893  7239 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I0129 22:47:03.473897  7239 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0129 22:47:03.473901  7239 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0129 22:47:03.473934  7239 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I0129 22:47:03.473939  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.473942  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.473944  7239 net.cpp:137] Memory required for data: 1048969344
I0129 22:47:03.473947  7239 layer_factory.hpp:77] Creating layer Convolution10
I0129 22:47:03.473955  7239 net.cpp:84] Creating Layer Convolution10
I0129 22:47:03.473958  7239 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0129 22:47:03.473964  7239 net.cpp:380] Convolution10 -> Convolution10
I0129 22:47:03.477537  7239 net.cpp:122] Setting up Convolution10
I0129 22:47:03.477550  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.477552  7239 net.cpp:137] Memory required for data: 1069940864
I0129 22:47:03.477567  7239 layer_factory.hpp:77] Creating layer BatchNorm10
I0129 22:47:03.477576  7239 net.cpp:84] Creating Layer BatchNorm10
I0129 22:47:03.477578  7239 net.cpp:406] BatchNorm10 <- Convolution10
I0129 22:47:03.477582  7239 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0129 22:47:03.477733  7239 net.cpp:122] Setting up BatchNorm10
I0129 22:47:03.477741  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.477742  7239 net.cpp:137] Memory required for data: 1090912384
I0129 22:47:03.477748  7239 layer_factory.hpp:77] Creating layer Scale10
I0129 22:47:03.477752  7239 net.cpp:84] Creating Layer Scale10
I0129 22:47:03.477756  7239 net.cpp:406] Scale10 <- Convolution10
I0129 22:47:03.477761  7239 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0129 22:47:03.477788  7239 layer_factory.hpp:77] Creating layer Scale10
I0129 22:47:03.477869  7239 net.cpp:122] Setting up Scale10
I0129 22:47:03.477876  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.477880  7239 net.cpp:137] Memory required for data: 1111883904
I0129 22:47:03.477883  7239 layer_factory.hpp:77] Creating layer ReLU10
I0129 22:47:03.477887  7239 net.cpp:84] Creating Layer ReLU10
I0129 22:47:03.477890  7239 net.cpp:406] ReLU10 <- Convolution10
I0129 22:47:03.477895  7239 net.cpp:367] ReLU10 -> Convolution10 (in-place)
I0129 22:47:03.478032  7239 net.cpp:122] Setting up ReLU10
I0129 22:47:03.478039  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.478041  7239 net.cpp:137] Memory required for data: 1132855424
I0129 22:47:03.478044  7239 layer_factory.hpp:77] Creating layer Convolution11
I0129 22:47:03.478052  7239 net.cpp:84] Creating Layer Convolution11
I0129 22:47:03.478055  7239 net.cpp:406] Convolution11 <- Convolution10
I0129 22:47:03.478060  7239 net.cpp:380] Convolution11 -> Convolution11
I0129 22:47:03.480896  7239 net.cpp:122] Setting up Convolution11
I0129 22:47:03.480908  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.480912  7239 net.cpp:137] Memory required for data: 1153826944
I0129 22:47:03.480917  7239 layer_factory.hpp:77] Creating layer BatchNorm11
I0129 22:47:03.480923  7239 net.cpp:84] Creating Layer BatchNorm11
I0129 22:47:03.480927  7239 net.cpp:406] BatchNorm11 <- Convolution11
I0129 22:47:03.480931  7239 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0129 22:47:03.481086  7239 net.cpp:122] Setting up BatchNorm11
I0129 22:47:03.481092  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.481094  7239 net.cpp:137] Memory required for data: 1174798464
I0129 22:47:03.481099  7239 layer_factory.hpp:77] Creating layer Scale11
I0129 22:47:03.481107  7239 net.cpp:84] Creating Layer Scale11
I0129 22:47:03.481111  7239 net.cpp:406] Scale11 <- Convolution11
I0129 22:47:03.481123  7239 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0129 22:47:03.481154  7239 layer_factory.hpp:77] Creating layer Scale11
I0129 22:47:03.481238  7239 net.cpp:122] Setting up Scale11
I0129 22:47:03.481245  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.481246  7239 net.cpp:137] Memory required for data: 1195769984
I0129 22:47:03.481251  7239 layer_factory.hpp:77] Creating layer Eltwise5
I0129 22:47:03.481256  7239 net.cpp:84] Creating Layer Eltwise5
I0129 22:47:03.481258  7239 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0129 22:47:03.481261  7239 net.cpp:406] Eltwise5 <- Convolution11
I0129 22:47:03.481266  7239 net.cpp:380] Eltwise5 -> Eltwise5
I0129 22:47:03.481286  7239 net.cpp:122] Setting up Eltwise5
I0129 22:47:03.481289  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.481292  7239 net.cpp:137] Memory required for data: 1216741504
I0129 22:47:03.481294  7239 layer_factory.hpp:77] Creating layer ReLU11
I0129 22:47:03.481298  7239 net.cpp:84] Creating Layer ReLU11
I0129 22:47:03.481300  7239 net.cpp:406] ReLU11 <- Eltwise5
I0129 22:47:03.481303  7239 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I0129 22:47:03.481729  7239 net.cpp:122] Setting up ReLU11
I0129 22:47:03.481740  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.481745  7239 net.cpp:137] Memory required for data: 1237713024
I0129 22:47:03.481746  7239 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0129 22:47:03.481751  7239 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I0129 22:47:03.481755  7239 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I0129 22:47:03.481758  7239 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0129 22:47:03.481765  7239 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0129 22:47:03.481799  7239 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I0129 22:47:03.481806  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.481808  7239 net.cpp:129] Top shape: 32 160 32 32 (5242880)
I0129 22:47:03.481811  7239 net.cpp:137] Memory required for data: 1279656064
I0129 22:47:03.481812  7239 layer_factory.hpp:77] Creating layer Convolution12
I0129 22:47:03.481822  7239 net.cpp:84] Creating Layer Convolution12
I0129 22:47:03.481824  7239 net.cpp:406] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0129 22:47:03.481829  7239 net.cpp:380] Convolution12 -> Convolution12
I0129 22:47:03.483801  7239 net.cpp:122] Setting up Convolution12
I0129 22:47:03.483814  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.483817  7239 net.cpp:137] Memory required for data: 1290141824
I0129 22:47:03.483822  7239 layer_factory.hpp:77] Creating layer BatchNorm12
I0129 22:47:03.483829  7239 net.cpp:84] Creating Layer BatchNorm12
I0129 22:47:03.483832  7239 net.cpp:406] BatchNorm12 <- Convolution12
I0129 22:47:03.483839  7239 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0129 22:47:03.483994  7239 net.cpp:122] Setting up BatchNorm12
I0129 22:47:03.484000  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.484004  7239 net.cpp:137] Memory required for data: 1300627584
I0129 22:47:03.484009  7239 layer_factory.hpp:77] Creating layer Scale12
I0129 22:47:03.484014  7239 net.cpp:84] Creating Layer Scale12
I0129 22:47:03.484017  7239 net.cpp:406] Scale12 <- Convolution12
I0129 22:47:03.484021  7239 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0129 22:47:03.484053  7239 layer_factory.hpp:77] Creating layer Scale12
I0129 22:47:03.484138  7239 net.cpp:122] Setting up Scale12
I0129 22:47:03.484144  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.484146  7239 net.cpp:137] Memory required for data: 1311113344
I0129 22:47:03.484150  7239 layer_factory.hpp:77] Creating layer Convolution13
I0129 22:47:03.484160  7239 net.cpp:84] Creating Layer Convolution13
I0129 22:47:03.484163  7239 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_1
I0129 22:47:03.484169  7239 net.cpp:380] Convolution13 -> Convolution13
I0129 22:47:03.489071  7239 net.cpp:122] Setting up Convolution13
I0129 22:47:03.489094  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.489096  7239 net.cpp:137] Memory required for data: 1321599104
I0129 22:47:03.489102  7239 layer_factory.hpp:77] Creating layer BatchNorm13
I0129 22:47:03.489109  7239 net.cpp:84] Creating Layer BatchNorm13
I0129 22:47:03.489114  7239 net.cpp:406] BatchNorm13 <- Convolution13
I0129 22:47:03.489118  7239 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0129 22:47:03.489270  7239 net.cpp:122] Setting up BatchNorm13
I0129 22:47:03.489276  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.489279  7239 net.cpp:137] Memory required for data: 1332084864
I0129 22:47:03.489284  7239 layer_factory.hpp:77] Creating layer Scale13
I0129 22:47:03.489290  7239 net.cpp:84] Creating Layer Scale13
I0129 22:47:03.489293  7239 net.cpp:406] Scale13 <- Convolution13
I0129 22:47:03.489296  7239 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0129 22:47:03.489328  7239 layer_factory.hpp:77] Creating layer Scale13
I0129 22:47:03.489418  7239 net.cpp:122] Setting up Scale13
I0129 22:47:03.489423  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.489425  7239 net.cpp:137] Memory required for data: 1342570624
I0129 22:47:03.489429  7239 layer_factory.hpp:77] Creating layer ReLU12
I0129 22:47:03.489436  7239 net.cpp:84] Creating Layer ReLU12
I0129 22:47:03.489439  7239 net.cpp:406] ReLU12 <- Convolution13
I0129 22:47:03.489442  7239 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I0129 22:47:03.489867  7239 net.cpp:122] Setting up ReLU12
I0129 22:47:03.489878  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.489882  7239 net.cpp:137] Memory required for data: 1353056384
I0129 22:47:03.489884  7239 layer_factory.hpp:77] Creating layer Convolution14
I0129 22:47:03.489892  7239 net.cpp:84] Creating Layer Convolution14
I0129 22:47:03.489898  7239 net.cpp:406] Convolution14 <- Convolution13
I0129 22:47:03.489903  7239 net.cpp:380] Convolution14 -> Convolution14
I0129 22:47:03.498764  7239 net.cpp:122] Setting up Convolution14
I0129 22:47:03.498776  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.498780  7239 net.cpp:137] Memory required for data: 1363542144
I0129 22:47:03.498785  7239 layer_factory.hpp:77] Creating layer BatchNorm14
I0129 22:47:03.498800  7239 net.cpp:84] Creating Layer BatchNorm14
I0129 22:47:03.498803  7239 net.cpp:406] BatchNorm14 <- Convolution14
I0129 22:47:03.498808  7239 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0129 22:47:03.498965  7239 net.cpp:122] Setting up BatchNorm14
I0129 22:47:03.498970  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.498972  7239 net.cpp:137] Memory required for data: 1374027904
I0129 22:47:03.498978  7239 layer_factory.hpp:77] Creating layer Scale14
I0129 22:47:03.498984  7239 net.cpp:84] Creating Layer Scale14
I0129 22:47:03.498988  7239 net.cpp:406] Scale14 <- Convolution14
I0129 22:47:03.498991  7239 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0129 22:47:03.499024  7239 layer_factory.hpp:77] Creating layer Scale14
I0129 22:47:03.499112  7239 net.cpp:122] Setting up Scale14
I0129 22:47:03.499119  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.499122  7239 net.cpp:137] Memory required for data: 1384513664
I0129 22:47:03.499127  7239 layer_factory.hpp:77] Creating layer Eltwise6
I0129 22:47:03.499131  7239 net.cpp:84] Creating Layer Eltwise6
I0129 22:47:03.499133  7239 net.cpp:406] Eltwise6 <- Convolution12
I0129 22:47:03.499136  7239 net.cpp:406] Eltwise6 <- Convolution14
I0129 22:47:03.499140  7239 net.cpp:380] Eltwise6 -> Eltwise6
I0129 22:47:03.499156  7239 net.cpp:122] Setting up Eltwise6
I0129 22:47:03.499161  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.499163  7239 net.cpp:137] Memory required for data: 1394999424
I0129 22:47:03.499166  7239 layer_factory.hpp:77] Creating layer ReLU13
I0129 22:47:03.499169  7239 net.cpp:84] Creating Layer ReLU13
I0129 22:47:03.499172  7239 net.cpp:406] ReLU13 <- Eltwise6
I0129 22:47:03.499187  7239 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I0129 22:47:03.499332  7239 net.cpp:122] Setting up ReLU13
I0129 22:47:03.499339  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.499341  7239 net.cpp:137] Memory required for data: 1405485184
I0129 22:47:03.499344  7239 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0129 22:47:03.499349  7239 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I0129 22:47:03.499351  7239 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I0129 22:47:03.499356  7239 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0129 22:47:03.499362  7239 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0129 22:47:03.499395  7239 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I0129 22:47:03.499400  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.499403  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.499405  7239 net.cpp:137] Memory required for data: 1426456704
I0129 22:47:03.499408  7239 layer_factory.hpp:77] Creating layer Convolution15
I0129 22:47:03.499416  7239 net.cpp:84] Creating Layer Convolution15
I0129 22:47:03.499419  7239 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0129 22:47:03.499424  7239 net.cpp:380] Convolution15 -> Convolution15
I0129 22:47:03.508317  7239 net.cpp:122] Setting up Convolution15
I0129 22:47:03.508329  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.508332  7239 net.cpp:137] Memory required for data: 1436942464
I0129 22:47:03.508337  7239 layer_factory.hpp:77] Creating layer BatchNorm15
I0129 22:47:03.508344  7239 net.cpp:84] Creating Layer BatchNorm15
I0129 22:47:03.508347  7239 net.cpp:406] BatchNorm15 <- Convolution15
I0129 22:47:03.508353  7239 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0129 22:47:03.508512  7239 net.cpp:122] Setting up BatchNorm15
I0129 22:47:03.508518  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.508520  7239 net.cpp:137] Memory required for data: 1447428224
I0129 22:47:03.508525  7239 layer_factory.hpp:77] Creating layer Scale15
I0129 22:47:03.508530  7239 net.cpp:84] Creating Layer Scale15
I0129 22:47:03.508533  7239 net.cpp:406] Scale15 <- Convolution15
I0129 22:47:03.508538  7239 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0129 22:47:03.508569  7239 layer_factory.hpp:77] Creating layer Scale15
I0129 22:47:03.508657  7239 net.cpp:122] Setting up Scale15
I0129 22:47:03.508663  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.508666  7239 net.cpp:137] Memory required for data: 1457913984
I0129 22:47:03.508669  7239 layer_factory.hpp:77] Creating layer ReLU14
I0129 22:47:03.508673  7239 net.cpp:84] Creating Layer ReLU14
I0129 22:47:03.508677  7239 net.cpp:406] ReLU14 <- Convolution15
I0129 22:47:03.508682  7239 net.cpp:367] ReLU14 -> Convolution15 (in-place)
I0129 22:47:03.508827  7239 net.cpp:122] Setting up ReLU14
I0129 22:47:03.508834  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.508838  7239 net.cpp:137] Memory required for data: 1468399744
I0129 22:47:03.508841  7239 layer_factory.hpp:77] Creating layer Convolution16
I0129 22:47:03.508849  7239 net.cpp:84] Creating Layer Convolution16
I0129 22:47:03.508852  7239 net.cpp:406] Convolution16 <- Convolution15
I0129 22:47:03.508857  7239 net.cpp:380] Convolution16 -> Convolution16
I0129 22:47:03.517838  7239 net.cpp:122] Setting up Convolution16
I0129 22:47:03.517851  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.517855  7239 net.cpp:137] Memory required for data: 1478885504
I0129 22:47:03.517861  7239 layer_factory.hpp:77] Creating layer BatchNorm16
I0129 22:47:03.517868  7239 net.cpp:84] Creating Layer BatchNorm16
I0129 22:47:03.517871  7239 net.cpp:406] BatchNorm16 <- Convolution16
I0129 22:47:03.517876  7239 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0129 22:47:03.518038  7239 net.cpp:122] Setting up BatchNorm16
I0129 22:47:03.518044  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.518048  7239 net.cpp:137] Memory required for data: 1489371264
I0129 22:47:03.518062  7239 layer_factory.hpp:77] Creating layer Scale16
I0129 22:47:03.518069  7239 net.cpp:84] Creating Layer Scale16
I0129 22:47:03.518071  7239 net.cpp:406] Scale16 <- Convolution16
I0129 22:47:03.518075  7239 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0129 22:47:03.518112  7239 layer_factory.hpp:77] Creating layer Scale16
I0129 22:47:03.518203  7239 net.cpp:122] Setting up Scale16
I0129 22:47:03.518208  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.518210  7239 net.cpp:137] Memory required for data: 1499857024
I0129 22:47:03.518214  7239 layer_factory.hpp:77] Creating layer Eltwise7
I0129 22:47:03.518221  7239 net.cpp:84] Creating Layer Eltwise7
I0129 22:47:03.518225  7239 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0129 22:47:03.518229  7239 net.cpp:406] Eltwise7 <- Convolution16
I0129 22:47:03.518231  7239 net.cpp:380] Eltwise7 -> Eltwise7
I0129 22:47:03.518249  7239 net.cpp:122] Setting up Eltwise7
I0129 22:47:03.518254  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.518255  7239 net.cpp:137] Memory required for data: 1510342784
I0129 22:47:03.518257  7239 layer_factory.hpp:77] Creating layer ReLU15
I0129 22:47:03.518262  7239 net.cpp:84] Creating Layer ReLU15
I0129 22:47:03.518265  7239 net.cpp:406] ReLU15 <- Eltwise7
I0129 22:47:03.518268  7239 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I0129 22:47:03.518702  7239 net.cpp:122] Setting up ReLU15
I0129 22:47:03.518713  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.518718  7239 net.cpp:137] Memory required for data: 1520828544
I0129 22:47:03.518723  7239 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0129 22:47:03.518729  7239 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I0129 22:47:03.518733  7239 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I0129 22:47:03.518738  7239 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0129 22:47:03.518744  7239 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0129 22:47:03.518781  7239 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I0129 22:47:03.518787  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.518790  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.518792  7239 net.cpp:137] Memory required for data: 1541800064
I0129 22:47:03.518795  7239 layer_factory.hpp:77] Creating layer Convolution17
I0129 22:47:03.518803  7239 net.cpp:84] Creating Layer Convolution17
I0129 22:47:03.518806  7239 net.cpp:406] Convolution17 <- Eltwise7_ReLU15_0_split_0
I0129 22:47:03.518811  7239 net.cpp:380] Convolution17 -> Convolution17
I0129 22:47:03.527667  7239 net.cpp:122] Setting up Convolution17
I0129 22:47:03.527679  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.527683  7239 net.cpp:137] Memory required for data: 1552285824
I0129 22:47:03.527688  7239 layer_factory.hpp:77] Creating layer BatchNorm17
I0129 22:47:03.527694  7239 net.cpp:84] Creating Layer BatchNorm17
I0129 22:47:03.527699  7239 net.cpp:406] BatchNorm17 <- Convolution17
I0129 22:47:03.527704  7239 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0129 22:47:03.527863  7239 net.cpp:122] Setting up BatchNorm17
I0129 22:47:03.527868  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.527871  7239 net.cpp:137] Memory required for data: 1562771584
I0129 22:47:03.527876  7239 layer_factory.hpp:77] Creating layer Scale17
I0129 22:47:03.527884  7239 net.cpp:84] Creating Layer Scale17
I0129 22:47:03.527886  7239 net.cpp:406] Scale17 <- Convolution17
I0129 22:47:03.527890  7239 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0129 22:47:03.527925  7239 layer_factory.hpp:77] Creating layer Scale17
I0129 22:47:03.528015  7239 net.cpp:122] Setting up Scale17
I0129 22:47:03.528020  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.528023  7239 net.cpp:137] Memory required for data: 1573257344
I0129 22:47:03.528028  7239 layer_factory.hpp:77] Creating layer ReLU16
I0129 22:47:03.528033  7239 net.cpp:84] Creating Layer ReLU16
I0129 22:47:03.528044  7239 net.cpp:406] ReLU16 <- Convolution17
I0129 22:47:03.528049  7239 net.cpp:367] ReLU16 -> Convolution17 (in-place)
I0129 22:47:03.528188  7239 net.cpp:122] Setting up ReLU16
I0129 22:47:03.528197  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.528198  7239 net.cpp:137] Memory required for data: 1583743104
I0129 22:47:03.528201  7239 layer_factory.hpp:77] Creating layer Convolution18
I0129 22:47:03.528208  7239 net.cpp:84] Creating Layer Convolution18
I0129 22:47:03.528213  7239 net.cpp:406] Convolution18 <- Convolution17
I0129 22:47:03.528218  7239 net.cpp:380] Convolution18 -> Convolution18
I0129 22:47:03.537065  7239 net.cpp:122] Setting up Convolution18
I0129 22:47:03.537077  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.537081  7239 net.cpp:137] Memory required for data: 1594228864
I0129 22:47:03.537087  7239 layer_factory.hpp:77] Creating layer BatchNorm18
I0129 22:47:03.537093  7239 net.cpp:84] Creating Layer BatchNorm18
I0129 22:47:03.537097  7239 net.cpp:406] BatchNorm18 <- Convolution18
I0129 22:47:03.537102  7239 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0129 22:47:03.537263  7239 net.cpp:122] Setting up BatchNorm18
I0129 22:47:03.537269  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.537272  7239 net.cpp:137] Memory required for data: 1604714624
I0129 22:47:03.537277  7239 layer_factory.hpp:77] Creating layer Scale18
I0129 22:47:03.537283  7239 net.cpp:84] Creating Layer Scale18
I0129 22:47:03.537287  7239 net.cpp:406] Scale18 <- Convolution18
I0129 22:47:03.537291  7239 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0129 22:47:03.537324  7239 layer_factory.hpp:77] Creating layer Scale18
I0129 22:47:03.537413  7239 net.cpp:122] Setting up Scale18
I0129 22:47:03.537420  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.537421  7239 net.cpp:137] Memory required for data: 1615200384
I0129 22:47:03.537425  7239 layer_factory.hpp:77] Creating layer Eltwise8
I0129 22:47:03.537431  7239 net.cpp:84] Creating Layer Eltwise8
I0129 22:47:03.537436  7239 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0129 22:47:03.537438  7239 net.cpp:406] Eltwise8 <- Convolution18
I0129 22:47:03.537442  7239 net.cpp:380] Eltwise8 -> Eltwise8
I0129 22:47:03.537458  7239 net.cpp:122] Setting up Eltwise8
I0129 22:47:03.537463  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.537466  7239 net.cpp:137] Memory required for data: 1625686144
I0129 22:47:03.537467  7239 layer_factory.hpp:77] Creating layer ReLU17
I0129 22:47:03.537472  7239 net.cpp:84] Creating Layer ReLU17
I0129 22:47:03.537474  7239 net.cpp:406] ReLU17 <- Eltwise8
I0129 22:47:03.537479  7239 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I0129 22:47:03.537622  7239 net.cpp:122] Setting up ReLU17
I0129 22:47:03.537631  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.537633  7239 net.cpp:137] Memory required for data: 1636171904
I0129 22:47:03.537636  7239 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0129 22:47:03.537639  7239 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I0129 22:47:03.537642  7239 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I0129 22:47:03.537647  7239 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0129 22:47:03.537652  7239 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0129 22:47:03.537686  7239 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I0129 22:47:03.537691  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.537694  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.537698  7239 net.cpp:137] Memory required for data: 1657143424
I0129 22:47:03.537699  7239 layer_factory.hpp:77] Creating layer Convolution19
I0129 22:47:03.537706  7239 net.cpp:84] Creating Layer Convolution19
I0129 22:47:03.537710  7239 net.cpp:406] Convolution19 <- Eltwise8_ReLU17_0_split_0
I0129 22:47:03.537715  7239 net.cpp:380] Convolution19 -> Convolution19
I0129 22:47:03.546545  7239 net.cpp:122] Setting up Convolution19
I0129 22:47:03.546566  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.546571  7239 net.cpp:137] Memory required for data: 1667629184
I0129 22:47:03.546576  7239 layer_factory.hpp:77] Creating layer BatchNorm19
I0129 22:47:03.546582  7239 net.cpp:84] Creating Layer BatchNorm19
I0129 22:47:03.546586  7239 net.cpp:406] BatchNorm19 <- Convolution19
I0129 22:47:03.546591  7239 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0129 22:47:03.546763  7239 net.cpp:122] Setting up BatchNorm19
I0129 22:47:03.546771  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.546773  7239 net.cpp:137] Memory required for data: 1678114944
I0129 22:47:03.546792  7239 layer_factory.hpp:77] Creating layer Scale19
I0129 22:47:03.546799  7239 net.cpp:84] Creating Layer Scale19
I0129 22:47:03.546802  7239 net.cpp:406] Scale19 <- Convolution19
I0129 22:47:03.546806  7239 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0129 22:47:03.546841  7239 layer_factory.hpp:77] Creating layer Scale19
I0129 22:47:03.546931  7239 net.cpp:122] Setting up Scale19
I0129 22:47:03.546937  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.546939  7239 net.cpp:137] Memory required for data: 1688600704
I0129 22:47:03.546943  7239 layer_factory.hpp:77] Creating layer ReLU18
I0129 22:47:03.546948  7239 net.cpp:84] Creating Layer ReLU18
I0129 22:47:03.546952  7239 net.cpp:406] ReLU18 <- Convolution19
I0129 22:47:03.546955  7239 net.cpp:367] ReLU18 -> Convolution19 (in-place)
I0129 22:47:03.547439  7239 net.cpp:122] Setting up ReLU18
I0129 22:47:03.547451  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.547454  7239 net.cpp:137] Memory required for data: 1699086464
I0129 22:47:03.547456  7239 layer_factory.hpp:77] Creating layer Convolution20
I0129 22:47:03.547466  7239 net.cpp:84] Creating Layer Convolution20
I0129 22:47:03.547469  7239 net.cpp:406] Convolution20 <- Convolution19
I0129 22:47:03.547477  7239 net.cpp:380] Convolution20 -> Convolution20
I0129 22:47:03.556355  7239 net.cpp:122] Setting up Convolution20
I0129 22:47:03.556370  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.556372  7239 net.cpp:137] Memory required for data: 1709572224
I0129 22:47:03.556377  7239 layer_factory.hpp:77] Creating layer BatchNorm20
I0129 22:47:03.556385  7239 net.cpp:84] Creating Layer BatchNorm20
I0129 22:47:03.556390  7239 net.cpp:406] BatchNorm20 <- Convolution20
I0129 22:47:03.556393  7239 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0129 22:47:03.556560  7239 net.cpp:122] Setting up BatchNorm20
I0129 22:47:03.556565  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.556567  7239 net.cpp:137] Memory required for data: 1720057984
I0129 22:47:03.556573  7239 layer_factory.hpp:77] Creating layer Scale20
I0129 22:47:03.556579  7239 net.cpp:84] Creating Layer Scale20
I0129 22:47:03.556582  7239 net.cpp:406] Scale20 <- Convolution20
I0129 22:47:03.556586  7239 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0129 22:47:03.556622  7239 layer_factory.hpp:77] Creating layer Scale20
I0129 22:47:03.556713  7239 net.cpp:122] Setting up Scale20
I0129 22:47:03.556720  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.556721  7239 net.cpp:137] Memory required for data: 1730543744
I0129 22:47:03.556726  7239 layer_factory.hpp:77] Creating layer Eltwise9
I0129 22:47:03.556730  7239 net.cpp:84] Creating Layer Eltwise9
I0129 22:47:03.556735  7239 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0129 22:47:03.556738  7239 net.cpp:406] Eltwise9 <- Convolution20
I0129 22:47:03.556742  7239 net.cpp:380] Eltwise9 -> Eltwise9
I0129 22:47:03.556759  7239 net.cpp:122] Setting up Eltwise9
I0129 22:47:03.556764  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.556766  7239 net.cpp:137] Memory required for data: 1741029504
I0129 22:47:03.556768  7239 layer_factory.hpp:77] Creating layer ReLU19
I0129 22:47:03.556772  7239 net.cpp:84] Creating Layer ReLU19
I0129 22:47:03.556774  7239 net.cpp:406] ReLU19 <- Eltwise9
I0129 22:47:03.556779  7239 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I0129 22:47:03.556931  7239 net.cpp:122] Setting up ReLU19
I0129 22:47:03.556939  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.556941  7239 net.cpp:137] Memory required for data: 1751515264
I0129 22:47:03.556946  7239 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0129 22:47:03.556951  7239 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I0129 22:47:03.556953  7239 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I0129 22:47:03.556959  7239 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0129 22:47:03.556965  7239 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0129 22:47:03.557000  7239 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I0129 22:47:03.557005  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.557008  7239 net.cpp:129] Top shape: 32 320 16 16 (2621440)
I0129 22:47:03.557011  7239 net.cpp:137] Memory required for data: 1772486784
I0129 22:47:03.557013  7239 layer_factory.hpp:77] Creating layer Convolution23
I0129 22:47:03.557021  7239 net.cpp:84] Creating Layer Convolution23
I0129 22:47:03.557024  7239 net.cpp:406] Convolution23 <- Eltwise9_ReLU19_0_split_0
I0129 22:47:03.557030  7239 net.cpp:380] Convolution23 -> Convolution23
I0129 22:47:03.560184  7239 net.cpp:122] Setting up Convolution23
I0129 22:47:03.560195  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.560199  7239 net.cpp:137] Memory required for data: 1777729664
I0129 22:47:03.560204  7239 layer_factory.hpp:77] Creating layer BatchNorm23
I0129 22:47:03.560211  7239 net.cpp:84] Creating Layer BatchNorm23
I0129 22:47:03.560215  7239 net.cpp:406] BatchNorm23 <- Convolution23
I0129 22:47:03.560221  7239 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0129 22:47:03.560381  7239 net.cpp:122] Setting up BatchNorm23
I0129 22:47:03.560387  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.560389  7239 net.cpp:137] Memory required for data: 1782972544
I0129 22:47:03.560395  7239 layer_factory.hpp:77] Creating layer Scale23
I0129 22:47:03.560401  7239 net.cpp:84] Creating Layer Scale23
I0129 22:47:03.560405  7239 net.cpp:406] Scale23 <- Convolution23
I0129 22:47:03.560407  7239 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0129 22:47:03.560436  7239 layer_factory.hpp:77] Creating layer Scale23
I0129 22:47:03.560529  7239 net.cpp:122] Setting up Scale23
I0129 22:47:03.560535  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.560537  7239 net.cpp:137] Memory required for data: 1788215424
I0129 22:47:03.560541  7239 layer_factory.hpp:77] Creating layer Convolution24
I0129 22:47:03.560550  7239 net.cpp:84] Creating Layer Convolution24
I0129 22:47:03.560554  7239 net.cpp:406] Convolution24 <- Eltwise9_ReLU19_0_split_1
I0129 22:47:03.560560  7239 net.cpp:380] Convolution24 -> Convolution24
I0129 22:47:03.576489  7239 net.cpp:122] Setting up Convolution24
I0129 22:47:03.576503  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.576506  7239 net.cpp:137] Memory required for data: 1793458304
I0129 22:47:03.576511  7239 layer_factory.hpp:77] Creating layer BatchNorm24
I0129 22:47:03.576517  7239 net.cpp:84] Creating Layer BatchNorm24
I0129 22:47:03.576521  7239 net.cpp:406] BatchNorm24 <- Convolution24
I0129 22:47:03.576527  7239 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0129 22:47:03.576687  7239 net.cpp:122] Setting up BatchNorm24
I0129 22:47:03.576694  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.576696  7239 net.cpp:137] Memory required for data: 1798701184
I0129 22:47:03.576701  7239 layer_factory.hpp:77] Creating layer Scale24
I0129 22:47:03.576706  7239 net.cpp:84] Creating Layer Scale24
I0129 22:47:03.576709  7239 net.cpp:406] Scale24 <- Convolution24
I0129 22:47:03.576714  7239 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0129 22:47:03.576745  7239 layer_factory.hpp:77] Creating layer Scale24
I0129 22:47:03.576835  7239 net.cpp:122] Setting up Scale24
I0129 22:47:03.576844  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.576858  7239 net.cpp:137] Memory required for data: 1803944064
I0129 22:47:03.576863  7239 layer_factory.hpp:77] Creating layer ReLU22
I0129 22:47:03.576866  7239 net.cpp:84] Creating Layer ReLU22
I0129 22:47:03.576869  7239 net.cpp:406] ReLU22 <- Convolution24
I0129 22:47:03.576874  7239 net.cpp:367] ReLU22 -> Convolution24 (in-place)
I0129 22:47:03.577013  7239 net.cpp:122] Setting up ReLU22
I0129 22:47:03.577020  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.577023  7239 net.cpp:137] Memory required for data: 1809186944
I0129 22:47:03.577025  7239 layer_factory.hpp:77] Creating layer Convolution25
I0129 22:47:03.577034  7239 net.cpp:84] Creating Layer Convolution25
I0129 22:47:03.577038  7239 net.cpp:406] Convolution25 <- Convolution24
I0129 22:47:03.577042  7239 net.cpp:380] Convolution25 -> Convolution25
I0129 22:47:03.608245  7239 net.cpp:122] Setting up Convolution25
I0129 22:47:03.608270  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.608273  7239 net.cpp:137] Memory required for data: 1814429824
I0129 22:47:03.608281  7239 layer_factory.hpp:77] Creating layer BatchNorm25
I0129 22:47:03.608292  7239 net.cpp:84] Creating Layer BatchNorm25
I0129 22:47:03.608297  7239 net.cpp:406] BatchNorm25 <- Convolution25
I0129 22:47:03.608304  7239 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0129 22:47:03.608471  7239 net.cpp:122] Setting up BatchNorm25
I0129 22:47:03.608479  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.608480  7239 net.cpp:137] Memory required for data: 1819672704
I0129 22:47:03.608485  7239 layer_factory.hpp:77] Creating layer Scale25
I0129 22:47:03.608492  7239 net.cpp:84] Creating Layer Scale25
I0129 22:47:03.608496  7239 net.cpp:406] Scale25 <- Convolution25
I0129 22:47:03.608500  7239 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0129 22:47:03.608533  7239 layer_factory.hpp:77] Creating layer Scale25
I0129 22:47:03.608629  7239 net.cpp:122] Setting up Scale25
I0129 22:47:03.608635  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.608638  7239 net.cpp:137] Memory required for data: 1824915584
I0129 22:47:03.608641  7239 layer_factory.hpp:77] Creating layer Eltwise11
I0129 22:47:03.608647  7239 net.cpp:84] Creating Layer Eltwise11
I0129 22:47:03.608651  7239 net.cpp:406] Eltwise11 <- Convolution23
I0129 22:47:03.608654  7239 net.cpp:406] Eltwise11 <- Convolution25
I0129 22:47:03.608659  7239 net.cpp:380] Eltwise11 -> Eltwise11
I0129 22:47:03.608681  7239 net.cpp:122] Setting up Eltwise11
I0129 22:47:03.608686  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.608688  7239 net.cpp:137] Memory required for data: 1830158464
I0129 22:47:03.608691  7239 layer_factory.hpp:77] Creating layer ReLU23
I0129 22:47:03.608695  7239 net.cpp:84] Creating Layer ReLU23
I0129 22:47:03.608698  7239 net.cpp:406] ReLU23 <- Eltwise11
I0129 22:47:03.608701  7239 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I0129 22:47:03.608840  7239 net.cpp:122] Setting up ReLU23
I0129 22:47:03.608847  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.608850  7239 net.cpp:137] Memory required for data: 1835401344
I0129 22:47:03.608852  7239 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0129 22:47:03.608858  7239 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I0129 22:47:03.608861  7239 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I0129 22:47:03.608866  7239 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0129 22:47:03.608872  7239 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0129 22:47:03.608906  7239 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I0129 22:47:03.608912  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.608916  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.608918  7239 net.cpp:137] Memory required for data: 1845887104
I0129 22:47:03.608920  7239 layer_factory.hpp:77] Creating layer Convolution26
I0129 22:47:03.608929  7239 net.cpp:84] Creating Layer Convolution26
I0129 22:47:03.608932  7239 net.cpp:406] Convolution26 <- Eltwise11_ReLU23_0_split_0
I0129 22:47:03.608952  7239 net.cpp:380] Convolution26 -> Convolution26
I0129 22:47:03.640107  7239 net.cpp:122] Setting up Convolution26
I0129 22:47:03.640132  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.640136  7239 net.cpp:137] Memory required for data: 1851129984
I0129 22:47:03.640143  7239 layer_factory.hpp:77] Creating layer BatchNorm26
I0129 22:47:03.640152  7239 net.cpp:84] Creating Layer BatchNorm26
I0129 22:47:03.640156  7239 net.cpp:406] BatchNorm26 <- Convolution26
I0129 22:47:03.640163  7239 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0129 22:47:03.640336  7239 net.cpp:122] Setting up BatchNorm26
I0129 22:47:03.640341  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.640343  7239 net.cpp:137] Memory required for data: 1856372864
I0129 22:47:03.640349  7239 layer_factory.hpp:77] Creating layer Scale26
I0129 22:47:03.640357  7239 net.cpp:84] Creating Layer Scale26
I0129 22:47:03.640359  7239 net.cpp:406] Scale26 <- Convolution26
I0129 22:47:03.640362  7239 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0129 22:47:03.640399  7239 layer_factory.hpp:77] Creating layer Scale26
I0129 22:47:03.640492  7239 net.cpp:122] Setting up Scale26
I0129 22:47:03.640498  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.640501  7239 net.cpp:137] Memory required for data: 1861615744
I0129 22:47:03.640506  7239 layer_factory.hpp:77] Creating layer ReLU24
I0129 22:47:03.640511  7239 net.cpp:84] Creating Layer ReLU24
I0129 22:47:03.640513  7239 net.cpp:406] ReLU24 <- Convolution26
I0129 22:47:03.640517  7239 net.cpp:367] ReLU24 -> Convolution26 (in-place)
I0129 22:47:03.640658  7239 net.cpp:122] Setting up ReLU24
I0129 22:47:03.640664  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.640667  7239 net.cpp:137] Memory required for data: 1866858624
I0129 22:47:03.640669  7239 layer_factory.hpp:77] Creating layer Convolution27
I0129 22:47:03.640679  7239 net.cpp:84] Creating Layer Convolution27
I0129 22:47:03.640682  7239 net.cpp:406] Convolution27 <- Convolution26
I0129 22:47:03.640688  7239 net.cpp:380] Convolution27 -> Convolution27
I0129 22:47:03.671751  7239 net.cpp:122] Setting up Convolution27
I0129 22:47:03.671775  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.671778  7239 net.cpp:137] Memory required for data: 1872101504
I0129 22:47:03.671785  7239 layer_factory.hpp:77] Creating layer BatchNorm27
I0129 22:47:03.671794  7239 net.cpp:84] Creating Layer BatchNorm27
I0129 22:47:03.671800  7239 net.cpp:406] BatchNorm27 <- Convolution27
I0129 22:47:03.671805  7239 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0129 22:47:03.671980  7239 net.cpp:122] Setting up BatchNorm27
I0129 22:47:03.671988  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.671989  7239 net.cpp:137] Memory required for data: 1877344384
I0129 22:47:03.671995  7239 layer_factory.hpp:77] Creating layer Scale27
I0129 22:47:03.672001  7239 net.cpp:84] Creating Layer Scale27
I0129 22:47:03.672004  7239 net.cpp:406] Scale27 <- Convolution27
I0129 22:47:03.672008  7239 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0129 22:47:03.672045  7239 layer_factory.hpp:77] Creating layer Scale27
I0129 22:47:03.672137  7239 net.cpp:122] Setting up Scale27
I0129 22:47:03.672143  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.672147  7239 net.cpp:137] Memory required for data: 1882587264
I0129 22:47:03.672149  7239 layer_factory.hpp:77] Creating layer Eltwise12
I0129 22:47:03.672157  7239 net.cpp:84] Creating Layer Eltwise12
I0129 22:47:03.672160  7239 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0129 22:47:03.672164  7239 net.cpp:406] Eltwise12 <- Convolution27
I0129 22:47:03.672168  7239 net.cpp:380] Eltwise12 -> Eltwise12
I0129 22:47:03.672189  7239 net.cpp:122] Setting up Eltwise12
I0129 22:47:03.672195  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.672199  7239 net.cpp:137] Memory required for data: 1887830144
I0129 22:47:03.672200  7239 layer_factory.hpp:77] Creating layer ReLU25
I0129 22:47:03.672217  7239 net.cpp:84] Creating Layer ReLU25
I0129 22:47:03.672221  7239 net.cpp:406] ReLU25 <- Eltwise12
I0129 22:47:03.672225  7239 net.cpp:367] ReLU25 -> Eltwise12 (in-place)
I0129 22:47:03.672366  7239 net.cpp:122] Setting up ReLU25
I0129 22:47:03.672374  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.672375  7239 net.cpp:137] Memory required for data: 1893073024
I0129 22:47:03.672379  7239 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0129 22:47:03.672385  7239 net.cpp:84] Creating Layer Eltwise12_ReLU25_0_split
I0129 22:47:03.672389  7239 net.cpp:406] Eltwise12_ReLU25_0_split <- Eltwise12
I0129 22:47:03.672392  7239 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0129 22:47:03.672397  7239 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0129 22:47:03.672432  7239 net.cpp:122] Setting up Eltwise12_ReLU25_0_split
I0129 22:47:03.672437  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.672441  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.672442  7239 net.cpp:137] Memory required for data: 1903558784
I0129 22:47:03.672444  7239 layer_factory.hpp:77] Creating layer Convolution28
I0129 22:47:03.672452  7239 net.cpp:84] Creating Layer Convolution28
I0129 22:47:03.672456  7239 net.cpp:406] Convolution28 <- Eltwise12_ReLU25_0_split_0
I0129 22:47:03.672461  7239 net.cpp:380] Convolution28 -> Convolution28
I0129 22:47:03.702847  7239 net.cpp:122] Setting up Convolution28
I0129 22:47:03.702867  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.702869  7239 net.cpp:137] Memory required for data: 1908801664
I0129 22:47:03.702878  7239 layer_factory.hpp:77] Creating layer BatchNorm28
I0129 22:47:03.702888  7239 net.cpp:84] Creating Layer BatchNorm28
I0129 22:47:03.702893  7239 net.cpp:406] BatchNorm28 <- Convolution28
I0129 22:47:03.702898  7239 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0129 22:47:03.703063  7239 net.cpp:122] Setting up BatchNorm28
I0129 22:47:03.703069  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.703071  7239 net.cpp:137] Memory required for data: 1914044544
I0129 22:47:03.703076  7239 layer_factory.hpp:77] Creating layer Scale28
I0129 22:47:03.703083  7239 net.cpp:84] Creating Layer Scale28
I0129 22:47:03.703086  7239 net.cpp:406] Scale28 <- Convolution28
I0129 22:47:03.703089  7239 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0129 22:47:03.703126  7239 layer_factory.hpp:77] Creating layer Scale28
I0129 22:47:03.703225  7239 net.cpp:122] Setting up Scale28
I0129 22:47:03.703232  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.703233  7239 net.cpp:137] Memory required for data: 1919287424
I0129 22:47:03.703236  7239 layer_factory.hpp:77] Creating layer ReLU26
I0129 22:47:03.703243  7239 net.cpp:84] Creating Layer ReLU26
I0129 22:47:03.703245  7239 net.cpp:406] ReLU26 <- Convolution28
I0129 22:47:03.703249  7239 net.cpp:367] ReLU26 -> Convolution28 (in-place)
I0129 22:47:03.703702  7239 net.cpp:122] Setting up ReLU26
I0129 22:47:03.703716  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.703719  7239 net.cpp:137] Memory required for data: 1924530304
I0129 22:47:03.703722  7239 layer_factory.hpp:77] Creating layer Convolution29
I0129 22:47:03.703730  7239 net.cpp:84] Creating Layer Convolution29
I0129 22:47:03.703735  7239 net.cpp:406] Convolution29 <- Convolution28
I0129 22:47:03.703740  7239 net.cpp:380] Convolution29 -> Convolution29
I0129 22:47:03.734148  7239 net.cpp:122] Setting up Convolution29
I0129 22:47:03.734169  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.734174  7239 net.cpp:137] Memory required for data: 1929773184
I0129 22:47:03.734181  7239 layer_factory.hpp:77] Creating layer BatchNorm29
I0129 22:47:03.734190  7239 net.cpp:84] Creating Layer BatchNorm29
I0129 22:47:03.734194  7239 net.cpp:406] BatchNorm29 <- Convolution29
I0129 22:47:03.734200  7239 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0129 22:47:03.734369  7239 net.cpp:122] Setting up BatchNorm29
I0129 22:47:03.734385  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.734387  7239 net.cpp:137] Memory required for data: 1935016064
I0129 22:47:03.734393  7239 layer_factory.hpp:77] Creating layer Scale29
I0129 22:47:03.734412  7239 net.cpp:84] Creating Layer Scale29
I0129 22:47:03.734416  7239 net.cpp:406] Scale29 <- Convolution29
I0129 22:47:03.734419  7239 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0129 22:47:03.734458  7239 layer_factory.hpp:77] Creating layer Scale29
I0129 22:47:03.734553  7239 net.cpp:122] Setting up Scale29
I0129 22:47:03.734560  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.734561  7239 net.cpp:137] Memory required for data: 1940258944
I0129 22:47:03.734566  7239 layer_factory.hpp:77] Creating layer Eltwise13
I0129 22:47:03.734573  7239 net.cpp:84] Creating Layer Eltwise13
I0129 22:47:03.734577  7239 net.cpp:406] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0129 22:47:03.734580  7239 net.cpp:406] Eltwise13 <- Convolution29
I0129 22:47:03.734585  7239 net.cpp:380] Eltwise13 -> Eltwise13
I0129 22:47:03.734613  7239 net.cpp:122] Setting up Eltwise13
I0129 22:47:03.734618  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.734621  7239 net.cpp:137] Memory required for data: 1945501824
I0129 22:47:03.734623  7239 layer_factory.hpp:77] Creating layer ReLU27
I0129 22:47:03.734629  7239 net.cpp:84] Creating Layer ReLU27
I0129 22:47:03.734632  7239 net.cpp:406] ReLU27 <- Eltwise13
I0129 22:47:03.734637  7239 net.cpp:367] ReLU27 -> Eltwise13 (in-place)
I0129 22:47:03.735373  7239 net.cpp:122] Setting up ReLU27
I0129 22:47:03.735385  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.735388  7239 net.cpp:137] Memory required for data: 1950744704
I0129 22:47:03.735391  7239 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0129 22:47:03.735396  7239 net.cpp:84] Creating Layer Eltwise13_ReLU27_0_split
I0129 22:47:03.735399  7239 net.cpp:406] Eltwise13_ReLU27_0_split <- Eltwise13
I0129 22:47:03.735404  7239 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0129 22:47:03.735409  7239 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0129 22:47:03.735447  7239 net.cpp:122] Setting up Eltwise13_ReLU27_0_split
I0129 22:47:03.735452  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.735455  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.735457  7239 net.cpp:137] Memory required for data: 1961230464
I0129 22:47:03.735460  7239 layer_factory.hpp:77] Creating layer Convolution30
I0129 22:47:03.735469  7239 net.cpp:84] Creating Layer Convolution30
I0129 22:47:03.735472  7239 net.cpp:406] Convolution30 <- Eltwise13_ReLU27_0_split_0
I0129 22:47:03.735477  7239 net.cpp:380] Convolution30 -> Convolution30
I0129 22:47:03.770496  7239 net.cpp:122] Setting up Convolution30
I0129 22:47:03.770519  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.770520  7239 net.cpp:137] Memory required for data: 1966473344
I0129 22:47:03.770529  7239 layer_factory.hpp:77] Creating layer BatchNorm30
I0129 22:47:03.770539  7239 net.cpp:84] Creating Layer BatchNorm30
I0129 22:47:03.770543  7239 net.cpp:406] BatchNorm30 <- Convolution30
I0129 22:47:03.770550  7239 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0129 22:47:03.770717  7239 net.cpp:122] Setting up BatchNorm30
I0129 22:47:03.770730  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.770732  7239 net.cpp:137] Memory required for data: 1971716224
I0129 22:47:03.770737  7239 layer_factory.hpp:77] Creating layer Scale30
I0129 22:47:03.770745  7239 net.cpp:84] Creating Layer Scale30
I0129 22:47:03.770748  7239 net.cpp:406] Scale30 <- Convolution30
I0129 22:47:03.770752  7239 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0129 22:47:03.770789  7239 layer_factory.hpp:77] Creating layer Scale30
I0129 22:47:03.770884  7239 net.cpp:122] Setting up Scale30
I0129 22:47:03.770890  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.770893  7239 net.cpp:137] Memory required for data: 1976959104
I0129 22:47:03.770912  7239 layer_factory.hpp:77] Creating layer ReLU28
I0129 22:47:03.770918  7239 net.cpp:84] Creating Layer ReLU28
I0129 22:47:03.770922  7239 net.cpp:406] ReLU28 <- Convolution30
I0129 22:47:03.770927  7239 net.cpp:367] ReLU28 -> Convolution30 (in-place)
I0129 22:47:03.771070  7239 net.cpp:122] Setting up ReLU28
I0129 22:47:03.771077  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.771080  7239 net.cpp:137] Memory required for data: 1982201984
I0129 22:47:03.771083  7239 layer_factory.hpp:77] Creating layer Convolution31
I0129 22:47:03.771091  7239 net.cpp:84] Creating Layer Convolution31
I0129 22:47:03.771095  7239 net.cpp:406] Convolution31 <- Convolution30
I0129 22:47:03.771101  7239 net.cpp:380] Convolution31 -> Convolution31
I0129 22:47:03.801573  7239 net.cpp:122] Setting up Convolution31
I0129 22:47:03.801596  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.801599  7239 net.cpp:137] Memory required for data: 1987444864
I0129 22:47:03.801607  7239 layer_factory.hpp:77] Creating layer BatchNorm31
I0129 22:47:03.801616  7239 net.cpp:84] Creating Layer BatchNorm31
I0129 22:47:03.801621  7239 net.cpp:406] BatchNorm31 <- Convolution31
I0129 22:47:03.801626  7239 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0129 22:47:03.801795  7239 net.cpp:122] Setting up BatchNorm31
I0129 22:47:03.801801  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.801803  7239 net.cpp:137] Memory required for data: 1992687744
I0129 22:47:03.801808  7239 layer_factory.hpp:77] Creating layer Scale31
I0129 22:47:03.801815  7239 net.cpp:84] Creating Layer Scale31
I0129 22:47:03.801816  7239 net.cpp:406] Scale31 <- Convolution31
I0129 22:47:03.801820  7239 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0129 22:47:03.801863  7239 layer_factory.hpp:77] Creating layer Scale31
I0129 22:47:03.801961  7239 net.cpp:122] Setting up Scale31
I0129 22:47:03.801967  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.801970  7239 net.cpp:137] Memory required for data: 1997930624
I0129 22:47:03.801973  7239 layer_factory.hpp:77] Creating layer Eltwise14
I0129 22:47:03.801980  7239 net.cpp:84] Creating Layer Eltwise14
I0129 22:47:03.801982  7239 net.cpp:406] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0129 22:47:03.801985  7239 net.cpp:406] Eltwise14 <- Convolution31
I0129 22:47:03.801990  7239 net.cpp:380] Eltwise14 -> Eltwise14
I0129 22:47:03.802011  7239 net.cpp:122] Setting up Eltwise14
I0129 22:47:03.802016  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.802018  7239 net.cpp:137] Memory required for data: 2003173504
I0129 22:47:03.802021  7239 layer_factory.hpp:77] Creating layer ReLU29
I0129 22:47:03.802026  7239 net.cpp:84] Creating Layer ReLU29
I0129 22:47:03.802027  7239 net.cpp:406] ReLU29 <- Eltwise14
I0129 22:47:03.802031  7239 net.cpp:367] ReLU29 -> Eltwise14 (in-place)
I0129 22:47:03.802170  7239 net.cpp:122] Setting up ReLU29
I0129 22:47:03.802178  7239 net.cpp:129] Top shape: 32 640 8 8 (1310720)
I0129 22:47:03.802181  7239 net.cpp:137] Memory required for data: 2008416384
I0129 22:47:03.802182  7239 layer_factory.hpp:77] Creating layer Pooling1
I0129 22:47:03.802188  7239 net.cpp:84] Creating Layer Pooling1
I0129 22:47:03.802191  7239 net.cpp:406] Pooling1 <- Eltwise14
I0129 22:47:03.802196  7239 net.cpp:380] Pooling1 -> Pooling1
I0129 22:47:03.802358  7239 net.cpp:122] Setting up Pooling1
I0129 22:47:03.802366  7239 net.cpp:129] Top shape: 32 640 1 1 (20480)
I0129 22:47:03.802368  7239 net.cpp:137] Memory required for data: 2008498304
I0129 22:47:03.802371  7239 layer_factory.hpp:77] Creating layer InnerProduct1
I0129 22:47:03.802376  7239 net.cpp:84] Creating Layer InnerProduct1
I0129 22:47:03.802379  7239 net.cpp:406] InnerProduct1 <- Pooling1
I0129 22:47:03.802383  7239 net.cpp:380] InnerProduct1 -> InnerProduct1
I0129 22:47:03.802536  7239 net.cpp:122] Setting up InnerProduct1
I0129 22:47:03.802542  7239 net.cpp:129] Top shape: 32 10 (320)
I0129 22:47:03.802544  7239 net.cpp:137] Memory required for data: 2008499584
I0129 22:47:03.802563  7239 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0129 22:47:03.802569  7239 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0129 22:47:03.802572  7239 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0129 22:47:03.802575  7239 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0129 22:47:03.802580  7239 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0129 22:47:03.802588  7239 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0129 22:47:03.803136  7239 net.cpp:122] Setting up SoftmaxWithLoss1
I0129 22:47:03.803148  7239 net.cpp:129] Top shape: (1)
I0129 22:47:03.803150  7239 net.cpp:132]     with loss weight 1
I0129 22:47:03.803169  7239 net.cpp:137] Memory required for data: 2008499588
I0129 22:47:03.803171  7239 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0129 22:47:03.803177  7239 net.cpp:198] InnerProduct1 needs backward computation.
I0129 22:47:03.803180  7239 net.cpp:198] Pooling1 needs backward computation.
I0129 22:47:03.803182  7239 net.cpp:198] ReLU29 needs backward computation.
I0129 22:47:03.803184  7239 net.cpp:198] Eltwise14 needs backward computation.
I0129 22:47:03.803187  7239 net.cpp:198] Scale31 needs backward computation.
I0129 22:47:03.803190  7239 net.cpp:198] BatchNorm31 needs backward computation.
I0129 22:47:03.803192  7239 net.cpp:198] Convolution31 needs backward computation.
I0129 22:47:03.803195  7239 net.cpp:198] ReLU28 needs backward computation.
I0129 22:47:03.803197  7239 net.cpp:198] Scale30 needs backward computation.
I0129 22:47:03.803200  7239 net.cpp:198] BatchNorm30 needs backward computation.
I0129 22:47:03.803202  7239 net.cpp:198] Convolution30 needs backward computation.
I0129 22:47:03.803205  7239 net.cpp:198] Eltwise13_ReLU27_0_split needs backward computation.
I0129 22:47:03.803208  7239 net.cpp:198] ReLU27 needs backward computation.
I0129 22:47:03.803211  7239 net.cpp:198] Eltwise13 needs backward computation.
I0129 22:47:03.803215  7239 net.cpp:198] Scale29 needs backward computation.
I0129 22:47:03.803216  7239 net.cpp:198] BatchNorm29 needs backward computation.
I0129 22:47:03.803220  7239 net.cpp:198] Convolution29 needs backward computation.
I0129 22:47:03.803222  7239 net.cpp:198] ReLU26 needs backward computation.
I0129 22:47:03.803225  7239 net.cpp:198] Scale28 needs backward computation.
I0129 22:47:03.803226  7239 net.cpp:198] BatchNorm28 needs backward computation.
I0129 22:47:03.803228  7239 net.cpp:198] Convolution28 needs backward computation.
I0129 22:47:03.803232  7239 net.cpp:198] Eltwise12_ReLU25_0_split needs backward computation.
I0129 22:47:03.803236  7239 net.cpp:198] ReLU25 needs backward computation.
I0129 22:47:03.803238  7239 net.cpp:198] Eltwise12 needs backward computation.
I0129 22:47:03.803241  7239 net.cpp:198] Scale27 needs backward computation.
I0129 22:47:03.803244  7239 net.cpp:198] BatchNorm27 needs backward computation.
I0129 22:47:03.803246  7239 net.cpp:198] Convolution27 needs backward computation.
I0129 22:47:03.803249  7239 net.cpp:198] ReLU24 needs backward computation.
I0129 22:47:03.803251  7239 net.cpp:198] Scale26 needs backward computation.
I0129 22:47:03.803254  7239 net.cpp:198] BatchNorm26 needs backward computation.
I0129 22:47:03.803256  7239 net.cpp:198] Convolution26 needs backward computation.
I0129 22:47:03.803258  7239 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I0129 22:47:03.803261  7239 net.cpp:198] ReLU23 needs backward computation.
I0129 22:47:03.803266  7239 net.cpp:198] Eltwise11 needs backward computation.
I0129 22:47:03.803268  7239 net.cpp:198] Scale25 needs backward computation.
I0129 22:47:03.803270  7239 net.cpp:198] BatchNorm25 needs backward computation.
I0129 22:47:03.803272  7239 net.cpp:198] Convolution25 needs backward computation.
I0129 22:47:03.803275  7239 net.cpp:198] ReLU22 needs backward computation.
I0129 22:47:03.803278  7239 net.cpp:198] Scale24 needs backward computation.
I0129 22:47:03.803280  7239 net.cpp:198] BatchNorm24 needs backward computation.
I0129 22:47:03.803283  7239 net.cpp:198] Convolution24 needs backward computation.
I0129 22:47:03.803295  7239 net.cpp:198] Scale23 needs backward computation.
I0129 22:47:03.803297  7239 net.cpp:198] BatchNorm23 needs backward computation.
I0129 22:47:03.803300  7239 net.cpp:198] Convolution23 needs backward computation.
I0129 22:47:03.803303  7239 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I0129 22:47:03.803305  7239 net.cpp:198] ReLU19 needs backward computation.
I0129 22:47:03.803308  7239 net.cpp:198] Eltwise9 needs backward computation.
I0129 22:47:03.803311  7239 net.cpp:198] Scale20 needs backward computation.
I0129 22:47:03.803314  7239 net.cpp:198] BatchNorm20 needs backward computation.
I0129 22:47:03.803316  7239 net.cpp:198] Convolution20 needs backward computation.
I0129 22:47:03.803319  7239 net.cpp:198] ReLU18 needs backward computation.
I0129 22:47:03.803321  7239 net.cpp:198] Scale19 needs backward computation.
I0129 22:47:03.803323  7239 net.cpp:198] BatchNorm19 needs backward computation.
I0129 22:47:03.803326  7239 net.cpp:198] Convolution19 needs backward computation.
I0129 22:47:03.803329  7239 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I0129 22:47:03.803331  7239 net.cpp:198] ReLU17 needs backward computation.
I0129 22:47:03.803334  7239 net.cpp:198] Eltwise8 needs backward computation.
I0129 22:47:03.803339  7239 net.cpp:198] Scale18 needs backward computation.
I0129 22:47:03.803341  7239 net.cpp:198] BatchNorm18 needs backward computation.
I0129 22:47:03.803344  7239 net.cpp:198] Convolution18 needs backward computation.
I0129 22:47:03.803346  7239 net.cpp:198] ReLU16 needs backward computation.
I0129 22:47:03.803349  7239 net.cpp:198] Scale17 needs backward computation.
I0129 22:47:03.803351  7239 net.cpp:198] BatchNorm17 needs backward computation.
I0129 22:47:03.803354  7239 net.cpp:198] Convolution17 needs backward computation.
I0129 22:47:03.803356  7239 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I0129 22:47:03.803359  7239 net.cpp:198] ReLU15 needs backward computation.
I0129 22:47:03.803362  7239 net.cpp:198] Eltwise7 needs backward computation.
I0129 22:47:03.803364  7239 net.cpp:198] Scale16 needs backward computation.
I0129 22:47:03.803367  7239 net.cpp:198] BatchNorm16 needs backward computation.
I0129 22:47:03.803370  7239 net.cpp:198] Convolution16 needs backward computation.
I0129 22:47:03.803372  7239 net.cpp:198] ReLU14 needs backward computation.
I0129 22:47:03.803375  7239 net.cpp:198] Scale15 needs backward computation.
I0129 22:47:03.803377  7239 net.cpp:198] BatchNorm15 needs backward computation.
I0129 22:47:03.803380  7239 net.cpp:198] Convolution15 needs backward computation.
I0129 22:47:03.803383  7239 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I0129 22:47:03.803386  7239 net.cpp:198] ReLU13 needs backward computation.
I0129 22:47:03.803388  7239 net.cpp:198] Eltwise6 needs backward computation.
I0129 22:47:03.803391  7239 net.cpp:198] Scale14 needs backward computation.
I0129 22:47:03.803395  7239 net.cpp:198] BatchNorm14 needs backward computation.
I0129 22:47:03.803396  7239 net.cpp:198] Convolution14 needs backward computation.
I0129 22:47:03.803398  7239 net.cpp:198] ReLU12 needs backward computation.
I0129 22:47:03.803401  7239 net.cpp:198] Scale13 needs backward computation.
I0129 22:47:03.803405  7239 net.cpp:198] BatchNorm13 needs backward computation.
I0129 22:47:03.803406  7239 net.cpp:198] Convolution13 needs backward computation.
I0129 22:47:03.803409  7239 net.cpp:198] Scale12 needs backward computation.
I0129 22:47:03.803412  7239 net.cpp:198] BatchNorm12 needs backward computation.
I0129 22:47:03.803414  7239 net.cpp:198] Convolution12 needs backward computation.
I0129 22:47:03.803417  7239 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I0129 22:47:03.803419  7239 net.cpp:198] ReLU11 needs backward computation.
I0129 22:47:03.803422  7239 net.cpp:198] Eltwise5 needs backward computation.
I0129 22:47:03.803426  7239 net.cpp:198] Scale11 needs backward computation.
I0129 22:47:03.803427  7239 net.cpp:198] BatchNorm11 needs backward computation.
I0129 22:47:03.803434  7239 net.cpp:198] Convolution11 needs backward computation.
I0129 22:47:03.803437  7239 net.cpp:198] ReLU10 needs backward computation.
I0129 22:47:03.803439  7239 net.cpp:198] Scale10 needs backward computation.
I0129 22:47:03.803442  7239 net.cpp:198] BatchNorm10 needs backward computation.
I0129 22:47:03.803444  7239 net.cpp:198] Convolution10 needs backward computation.
I0129 22:47:03.803447  7239 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I0129 22:47:03.803450  7239 net.cpp:198] ReLU9 needs backward computation.
I0129 22:47:03.803453  7239 net.cpp:198] Eltwise4 needs backward computation.
I0129 22:47:03.803457  7239 net.cpp:198] Scale9 needs backward computation.
I0129 22:47:03.803459  7239 net.cpp:198] BatchNorm9 needs backward computation.
I0129 22:47:03.803462  7239 net.cpp:198] Convolution9 needs backward computation.
I0129 22:47:03.803464  7239 net.cpp:198] ReLU8 needs backward computation.
I0129 22:47:03.803467  7239 net.cpp:198] Scale8 needs backward computation.
I0129 22:47:03.803469  7239 net.cpp:198] BatchNorm8 needs backward computation.
I0129 22:47:03.803472  7239 net.cpp:198] Convolution8 needs backward computation.
I0129 22:47:03.803475  7239 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I0129 22:47:03.803478  7239 net.cpp:198] ReLU7 needs backward computation.
I0129 22:47:03.803481  7239 net.cpp:198] Eltwise3 needs backward computation.
I0129 22:47:03.803484  7239 net.cpp:198] Scale7 needs backward computation.
I0129 22:47:03.803488  7239 net.cpp:198] BatchNorm7 needs backward computation.
I0129 22:47:03.803489  7239 net.cpp:198] Convolution7 needs backward computation.
I0129 22:47:03.803493  7239 net.cpp:198] ReLU6 needs backward computation.
I0129 22:47:03.803494  7239 net.cpp:198] Scale6 needs backward computation.
I0129 22:47:03.803496  7239 net.cpp:198] BatchNorm6 needs backward computation.
I0129 22:47:03.803498  7239 net.cpp:198] Convolution6 needs backward computation.
I0129 22:47:03.803503  7239 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I0129 22:47:03.803505  7239 net.cpp:198] ReLU5 needs backward computation.
I0129 22:47:03.803508  7239 net.cpp:198] Eltwise2 needs backward computation.
I0129 22:47:03.803510  7239 net.cpp:198] Scale5 needs backward computation.
I0129 22:47:03.803514  7239 net.cpp:198] BatchNorm5 needs backward computation.
I0129 22:47:03.803515  7239 net.cpp:198] Convolution5 needs backward computation.
I0129 22:47:03.803519  7239 net.cpp:198] ReLU4 needs backward computation.
I0129 22:47:03.803520  7239 net.cpp:198] Scale4 needs backward computation.
I0129 22:47:03.803524  7239 net.cpp:198] BatchNorm4 needs backward computation.
I0129 22:47:03.803525  7239 net.cpp:198] Convolution4 needs backward computation.
I0129 22:47:03.803529  7239 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I0129 22:47:03.803531  7239 net.cpp:198] ReLU3 needs backward computation.
I0129 22:47:03.803534  7239 net.cpp:198] Eltwise1 needs backward computation.
I0129 22:47:03.803537  7239 net.cpp:198] Scale3 needs backward computation.
I0129 22:47:03.803539  7239 net.cpp:198] BatchNorm3 needs backward computation.
I0129 22:47:03.803541  7239 net.cpp:198] Convolution3 needs backward computation.
I0129 22:47:03.803544  7239 net.cpp:198] ReLU2 needs backward computation.
I0129 22:47:03.803547  7239 net.cpp:198] Scale2 needs backward computation.
I0129 22:47:03.803550  7239 net.cpp:198] BatchNorm2 needs backward computation.
I0129 22:47:03.803551  7239 net.cpp:198] Convolution2 needs backward computation.
I0129 22:47:03.803555  7239 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I0129 22:47:03.803557  7239 net.cpp:198] ReLU1 needs backward computation.
I0129 22:47:03.803560  7239 net.cpp:198] Scale1 needs backward computation.
I0129 22:47:03.803562  7239 net.cpp:198] BatchNorm1 needs backward computation.
I0129 22:47:03.803565  7239 net.cpp:198] Convolution1 needs backward computation.
I0129 22:47:03.803568  7239 net.cpp:200] Data1 does not need backward computation.
I0129 22:47:03.803575  7239 net.cpp:242] This network produces output SoftmaxWithLoss1
I0129 22:47:03.803632  7239 net.cpp:255] Network initialization done.
I0129 22:47:03.804399  7239 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/bao/WRN-28.prototxt
I0129 22:47:03.804409  7239 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0129 22:47:03.804412  7239 solver.cpp:172] Creating test net (#0) specified by net file: examples/bao/WRN-28.prototxt
I0129 22:47:03.804483  7239 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0129 22:47:03.804950  7239 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
    mean_file: "data/cifar10/pad4_mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_pad4_test_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution29"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution31"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise14"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0129 22:47:03.805239  7239 layer_factory.hpp:77] Creating layer Data1
I0129 22:47:03.805286  7239 db_lmdb.cpp:35] Opened lmdb data/cifar10/cifar10_pad4_test_lmdb
I0129 22:47:03.805299  7239 net.cpp:84] Creating Layer Data1
I0129 22:47:03.805305  7239 net.cpp:380] Data1 -> Data1
I0129 22:47:03.805316  7239 net.cpp:380] Data1 -> Data2
I0129 22:47:03.805321  7239 data_transformer.cpp:25] Loading mean file from: data/cifar10/pad4_mean.binaryproto
I0129 22:47:03.805465  7239 data_layer.cpp:45] output data size: 50,3,32,32
I0129 22:47:03.806929  7239 net.cpp:122] Setting up Data1
I0129 22:47:03.806941  7239 net.cpp:129] Top shape: 50 3 32 32 (153600)
I0129 22:47:03.806944  7239 net.cpp:129] Top shape: 50 (50)
I0129 22:47:03.806946  7239 net.cpp:137] Memory required for data: 614600
I0129 22:47:03.806949  7239 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0129 22:47:03.806955  7239 net.cpp:84] Creating Layer Data2_Data1_1_split
I0129 22:47:03.806958  7239 net.cpp:406] Data2_Data1_1_split <- Data2
I0129 22:47:03.806963  7239 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0129 22:47:03.806969  7239 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0129 22:47:03.807011  7239 net.cpp:122] Setting up Data2_Data1_1_split
I0129 22:47:03.807016  7239 net.cpp:129] Top shape: 50 (50)
I0129 22:47:03.807018  7239 net.cpp:129] Top shape: 50 (50)
I0129 22:47:03.807021  7239 net.cpp:137] Memory required for data: 615000
I0129 22:47:03.807024  7239 layer_factory.hpp:77] Creating layer Convolution1
I0129 22:47:03.807031  7239 net.cpp:84] Creating Layer Convolution1
I0129 22:47:03.807034  7239 net.cpp:406] Convolution1 <- Data1
I0129 22:47:03.807039  7239 net.cpp:380] Convolution1 -> Convolution1
I0129 22:47:03.808020  7239 net.cpp:122] Setting up Convolution1
I0129 22:47:03.808032  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.808033  7239 net.cpp:137] Memory required for data: 33383000
I0129 22:47:03.808042  7239 layer_factory.hpp:77] Creating layer BatchNorm1
I0129 22:47:03.808048  7239 net.cpp:84] Creating Layer BatchNorm1
I0129 22:47:03.808050  7239 net.cpp:406] BatchNorm1 <- Convolution1
I0129 22:47:03.808054  7239 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0129 22:47:03.808219  7239 net.cpp:122] Setting up BatchNorm1
I0129 22:47:03.808224  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.808226  7239 net.cpp:137] Memory required for data: 66151000
I0129 22:47:03.808233  7239 layer_factory.hpp:77] Creating layer Scale1
I0129 22:47:03.808240  7239 net.cpp:84] Creating Layer Scale1
I0129 22:47:03.808243  7239 net.cpp:406] Scale1 <- Convolution1
I0129 22:47:03.808245  7239 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0129 22:47:03.808279  7239 layer_factory.hpp:77] Creating layer Scale1
I0129 22:47:03.808373  7239 net.cpp:122] Setting up Scale1
I0129 22:47:03.808378  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.808380  7239 net.cpp:137] Memory required for data: 98919000
I0129 22:47:03.808384  7239 layer_factory.hpp:77] Creating layer ReLU1
I0129 22:47:03.808390  7239 net.cpp:84] Creating Layer ReLU1
I0129 22:47:03.808393  7239 net.cpp:406] ReLU1 <- Convolution1
I0129 22:47:03.808396  7239 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I0129 22:47:03.809054  7239 net.cpp:122] Setting up ReLU1
I0129 22:47:03.809065  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.809068  7239 net.cpp:137] Memory required for data: 131687000
I0129 22:47:03.809070  7239 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0129 22:47:03.809077  7239 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I0129 22:47:03.809080  7239 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I0129 22:47:03.809084  7239 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0129 22:47:03.809089  7239 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0129 22:47:03.809165  7239 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I0129 22:47:03.809171  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.809175  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.809190  7239 net.cpp:137] Memory required for data: 197223000
I0129 22:47:03.809191  7239 layer_factory.hpp:77] Creating layer Convolution2
I0129 22:47:03.809200  7239 net.cpp:84] Creating Layer Convolution2
I0129 22:47:03.809211  7239 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I0129 22:47:03.809218  7239 net.cpp:380] Convolution2 -> Convolution2
I0129 22:47:03.812995  7239 net.cpp:122] Setting up Convolution2
I0129 22:47:03.813009  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.813011  7239 net.cpp:137] Memory required for data: 229991000
I0129 22:47:03.813019  7239 layer_factory.hpp:77] Creating layer BatchNorm2
I0129 22:47:03.813025  7239 net.cpp:84] Creating Layer BatchNorm2
I0129 22:47:03.813030  7239 net.cpp:406] BatchNorm2 <- Convolution2
I0129 22:47:03.813036  7239 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0129 22:47:03.813275  7239 net.cpp:122] Setting up BatchNorm2
I0129 22:47:03.813282  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.813284  7239 net.cpp:137] Memory required for data: 262759000
I0129 22:47:03.813290  7239 layer_factory.hpp:77] Creating layer Scale2
I0129 22:47:03.813302  7239 net.cpp:84] Creating Layer Scale2
I0129 22:47:03.813303  7239 net.cpp:406] Scale2 <- Convolution2
I0129 22:47:03.813308  7239 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0129 22:47:03.813343  7239 layer_factory.hpp:77] Creating layer Scale2
I0129 22:47:03.813436  7239 net.cpp:122] Setting up Scale2
I0129 22:47:03.813443  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.813446  7239 net.cpp:137] Memory required for data: 295527000
I0129 22:47:03.813450  7239 layer_factory.hpp:77] Creating layer ReLU2
I0129 22:47:03.813454  7239 net.cpp:84] Creating Layer ReLU2
I0129 22:47:03.813457  7239 net.cpp:406] ReLU2 <- Convolution2
I0129 22:47:03.813460  7239 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I0129 22:47:03.813608  7239 net.cpp:122] Setting up ReLU2
I0129 22:47:03.813616  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.813618  7239 net.cpp:137] Memory required for data: 328295000
I0129 22:47:03.813621  7239 layer_factory.hpp:77] Creating layer Convolution3
I0129 22:47:03.813630  7239 net.cpp:84] Creating Layer Convolution3
I0129 22:47:03.813633  7239 net.cpp:406] Convolution3 <- Convolution2
I0129 22:47:03.813637  7239 net.cpp:380] Convolution3 -> Convolution3
I0129 22:47:03.816939  7239 net.cpp:122] Setting up Convolution3
I0129 22:47:03.816951  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.816953  7239 net.cpp:137] Memory required for data: 361063000
I0129 22:47:03.816959  7239 layer_factory.hpp:77] Creating layer BatchNorm3
I0129 22:47:03.816965  7239 net.cpp:84] Creating Layer BatchNorm3
I0129 22:47:03.816968  7239 net.cpp:406] BatchNorm3 <- Convolution3
I0129 22:47:03.816972  7239 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0129 22:47:03.817145  7239 net.cpp:122] Setting up BatchNorm3
I0129 22:47:03.817152  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.817154  7239 net.cpp:137] Memory required for data: 393831000
I0129 22:47:03.817162  7239 layer_factory.hpp:77] Creating layer Scale3
I0129 22:47:03.817167  7239 net.cpp:84] Creating Layer Scale3
I0129 22:47:03.817170  7239 net.cpp:406] Scale3 <- Convolution3
I0129 22:47:03.817174  7239 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0129 22:47:03.817209  7239 layer_factory.hpp:77] Creating layer Scale3
I0129 22:47:03.817304  7239 net.cpp:122] Setting up Scale3
I0129 22:47:03.817312  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.817313  7239 net.cpp:137] Memory required for data: 426599000
I0129 22:47:03.817317  7239 layer_factory.hpp:77] Creating layer Eltwise1
I0129 22:47:03.817322  7239 net.cpp:84] Creating Layer Eltwise1
I0129 22:47:03.817324  7239 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0129 22:47:03.817327  7239 net.cpp:406] Eltwise1 <- Convolution3
I0129 22:47:03.817332  7239 net.cpp:380] Eltwise1 -> Eltwise1
I0129 22:47:03.817350  7239 net.cpp:122] Setting up Eltwise1
I0129 22:47:03.817358  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.817359  7239 net.cpp:137] Memory required for data: 459367000
I0129 22:47:03.817361  7239 layer_factory.hpp:77] Creating layer ReLU3
I0129 22:47:03.817374  7239 net.cpp:84] Creating Layer ReLU3
I0129 22:47:03.817378  7239 net.cpp:406] ReLU3 <- Eltwise1
I0129 22:47:03.817381  7239 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I0129 22:47:03.817539  7239 net.cpp:122] Setting up ReLU3
I0129 22:47:03.817546  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.817549  7239 net.cpp:137] Memory required for data: 492135000
I0129 22:47:03.817553  7239 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0129 22:47:03.817559  7239 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I0129 22:47:03.817562  7239 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I0129 22:47:03.817566  7239 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0129 22:47:03.817571  7239 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0129 22:47:03.817605  7239 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I0129 22:47:03.817610  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.817615  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.817616  7239 net.cpp:137] Memory required for data: 557671000
I0129 22:47:03.817618  7239 layer_factory.hpp:77] Creating layer Convolution4
I0129 22:47:03.817625  7239 net.cpp:84] Creating Layer Convolution4
I0129 22:47:03.817627  7239 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0129 22:47:03.817631  7239 net.cpp:380] Convolution4 -> Convolution4
I0129 22:47:03.821280  7239 net.cpp:122] Setting up Convolution4
I0129 22:47:03.821295  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.821298  7239 net.cpp:137] Memory required for data: 590439000
I0129 22:47:03.821303  7239 layer_factory.hpp:77] Creating layer BatchNorm4
I0129 22:47:03.821308  7239 net.cpp:84] Creating Layer BatchNorm4
I0129 22:47:03.821311  7239 net.cpp:406] BatchNorm4 <- Convolution4
I0129 22:47:03.821316  7239 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0129 22:47:03.821491  7239 net.cpp:122] Setting up BatchNorm4
I0129 22:47:03.821496  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.821498  7239 net.cpp:137] Memory required for data: 623207000
I0129 22:47:03.821504  7239 layer_factory.hpp:77] Creating layer Scale4
I0129 22:47:03.821508  7239 net.cpp:84] Creating Layer Scale4
I0129 22:47:03.821511  7239 net.cpp:406] Scale4 <- Convolution4
I0129 22:47:03.821513  7239 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0129 22:47:03.821547  7239 layer_factory.hpp:77] Creating layer Scale4
I0129 22:47:03.821645  7239 net.cpp:122] Setting up Scale4
I0129 22:47:03.821651  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.821653  7239 net.cpp:137] Memory required for data: 655975000
I0129 22:47:03.821657  7239 layer_factory.hpp:77] Creating layer ReLU4
I0129 22:47:03.821662  7239 net.cpp:84] Creating Layer ReLU4
I0129 22:47:03.821665  7239 net.cpp:406] ReLU4 <- Convolution4
I0129 22:47:03.821668  7239 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I0129 22:47:03.821810  7239 net.cpp:122] Setting up ReLU4
I0129 22:47:03.821817  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.821820  7239 net.cpp:137] Memory required for data: 688743000
I0129 22:47:03.821822  7239 layer_factory.hpp:77] Creating layer Convolution5
I0129 22:47:03.821830  7239 net.cpp:84] Creating Layer Convolution5
I0129 22:47:03.821833  7239 net.cpp:406] Convolution5 <- Convolution4
I0129 22:47:03.821837  7239 net.cpp:380] Convolution5 -> Convolution5
I0129 22:47:03.824731  7239 net.cpp:122] Setting up Convolution5
I0129 22:47:03.824743  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.824746  7239 net.cpp:137] Memory required for data: 721511000
I0129 22:47:03.824751  7239 layer_factory.hpp:77] Creating layer BatchNorm5
I0129 22:47:03.824757  7239 net.cpp:84] Creating Layer BatchNorm5
I0129 22:47:03.824760  7239 net.cpp:406] BatchNorm5 <- Convolution5
I0129 22:47:03.824764  7239 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0129 22:47:03.824937  7239 net.cpp:122] Setting up BatchNorm5
I0129 22:47:03.824944  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.824955  7239 net.cpp:137] Memory required for data: 754279000
I0129 22:47:03.824964  7239 layer_factory.hpp:77] Creating layer Scale5
I0129 22:47:03.824970  7239 net.cpp:84] Creating Layer Scale5
I0129 22:47:03.824973  7239 net.cpp:406] Scale5 <- Convolution5
I0129 22:47:03.824978  7239 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0129 22:47:03.825014  7239 layer_factory.hpp:77] Creating layer Scale5
I0129 22:47:03.825114  7239 net.cpp:122] Setting up Scale5
I0129 22:47:03.825119  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.825121  7239 net.cpp:137] Memory required for data: 787047000
I0129 22:47:03.825125  7239 layer_factory.hpp:77] Creating layer Eltwise2
I0129 22:47:03.825130  7239 net.cpp:84] Creating Layer Eltwise2
I0129 22:47:03.825134  7239 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0129 22:47:03.825136  7239 net.cpp:406] Eltwise2 <- Convolution5
I0129 22:47:03.825140  7239 net.cpp:380] Eltwise2 -> Eltwise2
I0129 22:47:03.825161  7239 net.cpp:122] Setting up Eltwise2
I0129 22:47:03.825166  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.825168  7239 net.cpp:137] Memory required for data: 819815000
I0129 22:47:03.825170  7239 layer_factory.hpp:77] Creating layer ReLU5
I0129 22:47:03.825175  7239 net.cpp:84] Creating Layer ReLU5
I0129 22:47:03.825177  7239 net.cpp:406] ReLU5 <- Eltwise2
I0129 22:47:03.825181  7239 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I0129 22:47:03.825325  7239 net.cpp:122] Setting up ReLU5
I0129 22:47:03.825332  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.825335  7239 net.cpp:137] Memory required for data: 852583000
I0129 22:47:03.825337  7239 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0129 22:47:03.825341  7239 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I0129 22:47:03.825343  7239 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I0129 22:47:03.825348  7239 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0129 22:47:03.825356  7239 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0129 22:47:03.825393  7239 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I0129 22:47:03.825398  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.825402  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.825403  7239 net.cpp:137] Memory required for data: 918119000
I0129 22:47:03.825405  7239 layer_factory.hpp:77] Creating layer Convolution6
I0129 22:47:03.825413  7239 net.cpp:84] Creating Layer Convolution6
I0129 22:47:03.825417  7239 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0129 22:47:03.825422  7239 net.cpp:380] Convolution6 -> Convolution6
I0129 22:47:03.829048  7239 net.cpp:122] Setting up Convolution6
I0129 22:47:03.829061  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.829063  7239 net.cpp:137] Memory required for data: 950887000
I0129 22:47:03.829069  7239 layer_factory.hpp:77] Creating layer BatchNorm6
I0129 22:47:03.829077  7239 net.cpp:84] Creating Layer BatchNorm6
I0129 22:47:03.829080  7239 net.cpp:406] BatchNorm6 <- Convolution6
I0129 22:47:03.829085  7239 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0129 22:47:03.829262  7239 net.cpp:122] Setting up BatchNorm6
I0129 22:47:03.829267  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.829269  7239 net.cpp:137] Memory required for data: 983655000
I0129 22:47:03.829274  7239 layer_factory.hpp:77] Creating layer Scale6
I0129 22:47:03.829280  7239 net.cpp:84] Creating Layer Scale6
I0129 22:47:03.829282  7239 net.cpp:406] Scale6 <- Convolution6
I0129 22:47:03.829286  7239 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0129 22:47:03.829320  7239 layer_factory.hpp:77] Creating layer Scale6
I0129 22:47:03.829418  7239 net.cpp:122] Setting up Scale6
I0129 22:47:03.829424  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.829427  7239 net.cpp:137] Memory required for data: 1016423000
I0129 22:47:03.829430  7239 layer_factory.hpp:77] Creating layer ReLU6
I0129 22:47:03.829437  7239 net.cpp:84] Creating Layer ReLU6
I0129 22:47:03.829448  7239 net.cpp:406] ReLU6 <- Convolution6
I0129 22:47:03.829452  7239 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I0129 22:47:03.829918  7239 net.cpp:122] Setting up ReLU6
I0129 22:47:03.829931  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.829932  7239 net.cpp:137] Memory required for data: 1049191000
I0129 22:47:03.829936  7239 layer_factory.hpp:77] Creating layer Convolution7
I0129 22:47:03.829943  7239 net.cpp:84] Creating Layer Convolution7
I0129 22:47:03.829948  7239 net.cpp:406] Convolution7 <- Convolution6
I0129 22:47:03.829954  7239 net.cpp:380] Convolution7 -> Convolution7
I0129 22:47:03.832855  7239 net.cpp:122] Setting up Convolution7
I0129 22:47:03.832868  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.832872  7239 net.cpp:137] Memory required for data: 1081959000
I0129 22:47:03.832877  7239 layer_factory.hpp:77] Creating layer BatchNorm7
I0129 22:47:03.832886  7239 net.cpp:84] Creating Layer BatchNorm7
I0129 22:47:03.832890  7239 net.cpp:406] BatchNorm7 <- Convolution7
I0129 22:47:03.832895  7239 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0129 22:47:03.833070  7239 net.cpp:122] Setting up BatchNorm7
I0129 22:47:03.833077  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.833079  7239 net.cpp:137] Memory required for data: 1114727000
I0129 22:47:03.833086  7239 layer_factory.hpp:77] Creating layer Scale7
I0129 22:47:03.833089  7239 net.cpp:84] Creating Layer Scale7
I0129 22:47:03.833091  7239 net.cpp:406] Scale7 <- Convolution7
I0129 22:47:03.833096  7239 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0129 22:47:03.833129  7239 layer_factory.hpp:77] Creating layer Scale7
I0129 22:47:03.833227  7239 net.cpp:122] Setting up Scale7
I0129 22:47:03.833235  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.833236  7239 net.cpp:137] Memory required for data: 1147495000
I0129 22:47:03.833241  7239 layer_factory.hpp:77] Creating layer Eltwise3
I0129 22:47:03.833245  7239 net.cpp:84] Creating Layer Eltwise3
I0129 22:47:03.833247  7239 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0129 22:47:03.833250  7239 net.cpp:406] Eltwise3 <- Convolution7
I0129 22:47:03.833254  7239 net.cpp:380] Eltwise3 -> Eltwise3
I0129 22:47:03.833276  7239 net.cpp:122] Setting up Eltwise3
I0129 22:47:03.833281  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.833282  7239 net.cpp:137] Memory required for data: 1180263000
I0129 22:47:03.833286  7239 layer_factory.hpp:77] Creating layer ReLU7
I0129 22:47:03.833289  7239 net.cpp:84] Creating Layer ReLU7
I0129 22:47:03.833292  7239 net.cpp:406] ReLU7 <- Eltwise3
I0129 22:47:03.833295  7239 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I0129 22:47:03.833443  7239 net.cpp:122] Setting up ReLU7
I0129 22:47:03.833451  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.833453  7239 net.cpp:137] Memory required for data: 1213031000
I0129 22:47:03.833456  7239 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0129 22:47:03.833461  7239 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I0129 22:47:03.833462  7239 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I0129 22:47:03.833467  7239 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0129 22:47:03.833472  7239 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0129 22:47:03.833516  7239 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I0129 22:47:03.833521  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.833524  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.833526  7239 net.cpp:137] Memory required for data: 1278567000
I0129 22:47:03.833529  7239 layer_factory.hpp:77] Creating layer Convolution8
I0129 22:47:03.833537  7239 net.cpp:84] Creating Layer Convolution8
I0129 22:47:03.833539  7239 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0129 22:47:03.833544  7239 net.cpp:380] Convolution8 -> Convolution8
I0129 22:47:03.837265  7239 net.cpp:122] Setting up Convolution8
I0129 22:47:03.837276  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.837288  7239 net.cpp:137] Memory required for data: 1311335000
I0129 22:47:03.837294  7239 layer_factory.hpp:77] Creating layer BatchNorm8
I0129 22:47:03.837302  7239 net.cpp:84] Creating Layer BatchNorm8
I0129 22:47:03.837306  7239 net.cpp:406] BatchNorm8 <- Convolution8
I0129 22:47:03.837309  7239 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0129 22:47:03.837491  7239 net.cpp:122] Setting up BatchNorm8
I0129 22:47:03.837498  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.837501  7239 net.cpp:137] Memory required for data: 1344103000
I0129 22:47:03.837505  7239 layer_factory.hpp:77] Creating layer Scale8
I0129 22:47:03.837510  7239 net.cpp:84] Creating Layer Scale8
I0129 22:47:03.837513  7239 net.cpp:406] Scale8 <- Convolution8
I0129 22:47:03.837517  7239 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0129 22:47:03.837551  7239 layer_factory.hpp:77] Creating layer Scale8
I0129 22:47:03.837652  7239 net.cpp:122] Setting up Scale8
I0129 22:47:03.837659  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.837661  7239 net.cpp:137] Memory required for data: 1376871000
I0129 22:47:03.837666  7239 layer_factory.hpp:77] Creating layer ReLU8
I0129 22:47:03.837669  7239 net.cpp:84] Creating Layer ReLU8
I0129 22:47:03.837671  7239 net.cpp:406] ReLU8 <- Convolution8
I0129 22:47:03.837677  7239 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I0129 22:47:03.837824  7239 net.cpp:122] Setting up ReLU8
I0129 22:47:03.837831  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.837833  7239 net.cpp:137] Memory required for data: 1409639000
I0129 22:47:03.837836  7239 layer_factory.hpp:77] Creating layer Convolution9
I0129 22:47:03.837843  7239 net.cpp:84] Creating Layer Convolution9
I0129 22:47:03.837846  7239 net.cpp:406] Convolution9 <- Convolution8
I0129 22:47:03.837851  7239 net.cpp:380] Convolution9 -> Convolution9
I0129 22:47:03.840762  7239 net.cpp:122] Setting up Convolution9
I0129 22:47:03.840775  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.840777  7239 net.cpp:137] Memory required for data: 1442407000
I0129 22:47:03.840782  7239 layer_factory.hpp:77] Creating layer BatchNorm9
I0129 22:47:03.840788  7239 net.cpp:84] Creating Layer BatchNorm9
I0129 22:47:03.840791  7239 net.cpp:406] BatchNorm9 <- Convolution9
I0129 22:47:03.840796  7239 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0129 22:47:03.840977  7239 net.cpp:122] Setting up BatchNorm9
I0129 22:47:03.840983  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.840986  7239 net.cpp:137] Memory required for data: 1475175000
I0129 22:47:03.840991  7239 layer_factory.hpp:77] Creating layer Scale9
I0129 22:47:03.840996  7239 net.cpp:84] Creating Layer Scale9
I0129 22:47:03.840999  7239 net.cpp:406] Scale9 <- Convolution9
I0129 22:47:03.841002  7239 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0129 22:47:03.841038  7239 layer_factory.hpp:77] Creating layer Scale9
I0129 22:47:03.841140  7239 net.cpp:122] Setting up Scale9
I0129 22:47:03.841145  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.841147  7239 net.cpp:137] Memory required for data: 1507943000
I0129 22:47:03.841151  7239 layer_factory.hpp:77] Creating layer Eltwise4
I0129 22:47:03.841157  7239 net.cpp:84] Creating Layer Eltwise4
I0129 22:47:03.841161  7239 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0129 22:47:03.841163  7239 net.cpp:406] Eltwise4 <- Convolution9
I0129 22:47:03.841166  7239 net.cpp:380] Eltwise4 -> Eltwise4
I0129 22:47:03.841188  7239 net.cpp:122] Setting up Eltwise4
I0129 22:47:03.841193  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.841195  7239 net.cpp:137] Memory required for data: 1540711000
I0129 22:47:03.841197  7239 layer_factory.hpp:77] Creating layer ReLU9
I0129 22:47:03.841202  7239 net.cpp:84] Creating Layer ReLU9
I0129 22:47:03.841204  7239 net.cpp:406] ReLU9 <- Eltwise4
I0129 22:47:03.841209  7239 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I0129 22:47:03.841356  7239 net.cpp:122] Setting up ReLU9
I0129 22:47:03.841372  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.841374  7239 net.cpp:137] Memory required for data: 1573479000
I0129 22:47:03.841377  7239 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0129 22:47:03.841382  7239 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I0129 22:47:03.841385  7239 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I0129 22:47:03.841389  7239 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0129 22:47:03.841394  7239 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0129 22:47:03.841433  7239 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I0129 22:47:03.841439  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.841441  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.841444  7239 net.cpp:137] Memory required for data: 1639015000
I0129 22:47:03.841445  7239 layer_factory.hpp:77] Creating layer Convolution10
I0129 22:47:03.841452  7239 net.cpp:84] Creating Layer Convolution10
I0129 22:47:03.841455  7239 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0129 22:47:03.841460  7239 net.cpp:380] Convolution10 -> Convolution10
I0129 22:47:03.845109  7239 net.cpp:122] Setting up Convolution10
I0129 22:47:03.845121  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.845124  7239 net.cpp:137] Memory required for data: 1671783000
I0129 22:47:03.845139  7239 layer_factory.hpp:77] Creating layer BatchNorm10
I0129 22:47:03.845145  7239 net.cpp:84] Creating Layer BatchNorm10
I0129 22:47:03.845149  7239 net.cpp:406] BatchNorm10 <- Convolution10
I0129 22:47:03.845154  7239 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0129 22:47:03.845333  7239 net.cpp:122] Setting up BatchNorm10
I0129 22:47:03.845338  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.845341  7239 net.cpp:137] Memory required for data: 1704551000
I0129 22:47:03.845346  7239 layer_factory.hpp:77] Creating layer Scale10
I0129 22:47:03.845350  7239 net.cpp:84] Creating Layer Scale10
I0129 22:47:03.845353  7239 net.cpp:406] Scale10 <- Convolution10
I0129 22:47:03.845356  7239 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0129 22:47:03.845391  7239 layer_factory.hpp:77] Creating layer Scale10
I0129 22:47:03.845492  7239 net.cpp:122] Setting up Scale10
I0129 22:47:03.845499  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.845501  7239 net.cpp:137] Memory required for data: 1737319000
I0129 22:47:03.845505  7239 layer_factory.hpp:77] Creating layer ReLU10
I0129 22:47:03.845510  7239 net.cpp:84] Creating Layer ReLU10
I0129 22:47:03.845513  7239 net.cpp:406] ReLU10 <- Convolution10
I0129 22:47:03.845516  7239 net.cpp:367] ReLU10 -> Convolution10 (in-place)
I0129 22:47:03.845664  7239 net.cpp:122] Setting up ReLU10
I0129 22:47:03.845671  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.845674  7239 net.cpp:137] Memory required for data: 1770087000
I0129 22:47:03.845676  7239 layer_factory.hpp:77] Creating layer Convolution11
I0129 22:47:03.845683  7239 net.cpp:84] Creating Layer Convolution11
I0129 22:47:03.845686  7239 net.cpp:406] Convolution11 <- Convolution10
I0129 22:47:03.845691  7239 net.cpp:380] Convolution11 -> Convolution11
I0129 22:47:03.848618  7239 net.cpp:122] Setting up Convolution11
I0129 22:47:03.848630  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.848632  7239 net.cpp:137] Memory required for data: 1802855000
I0129 22:47:03.848637  7239 layer_factory.hpp:77] Creating layer BatchNorm11
I0129 22:47:03.848642  7239 net.cpp:84] Creating Layer BatchNorm11
I0129 22:47:03.848645  7239 net.cpp:406] BatchNorm11 <- Convolution11
I0129 22:47:03.848650  7239 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0129 22:47:03.848831  7239 net.cpp:122] Setting up BatchNorm11
I0129 22:47:03.848837  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.848839  7239 net.cpp:137] Memory required for data: 1835623000
I0129 22:47:03.848845  7239 layer_factory.hpp:77] Creating layer Scale11
I0129 22:47:03.848860  7239 net.cpp:84] Creating Layer Scale11
I0129 22:47:03.848862  7239 net.cpp:406] Scale11 <- Convolution11
I0129 22:47:03.848867  7239 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0129 22:47:03.848906  7239 layer_factory.hpp:77] Creating layer Scale11
I0129 22:47:03.849009  7239 net.cpp:122] Setting up Scale11
I0129 22:47:03.849014  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.849016  7239 net.cpp:137] Memory required for data: 1868391000
I0129 22:47:03.849020  7239 layer_factory.hpp:77] Creating layer Eltwise5
I0129 22:47:03.849025  7239 net.cpp:84] Creating Layer Eltwise5
I0129 22:47:03.849028  7239 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0129 22:47:03.849031  7239 net.cpp:406] Eltwise5 <- Convolution11
I0129 22:47:03.849035  7239 net.cpp:380] Eltwise5 -> Eltwise5
I0129 22:47:03.849056  7239 net.cpp:122] Setting up Eltwise5
I0129 22:47:03.849062  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.849066  7239 net.cpp:137] Memory required for data: 1901159000
I0129 22:47:03.849067  7239 layer_factory.hpp:77] Creating layer ReLU11
I0129 22:47:03.849071  7239 net.cpp:84] Creating Layer ReLU11
I0129 22:47:03.849073  7239 net.cpp:406] ReLU11 <- Eltwise5
I0129 22:47:03.849077  7239 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I0129 22:47:03.849225  7239 net.cpp:122] Setting up ReLU11
I0129 22:47:03.849233  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.849236  7239 net.cpp:137] Memory required for data: 1933927000
I0129 22:47:03.849237  7239 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0129 22:47:03.849243  7239 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I0129 22:47:03.849246  7239 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I0129 22:47:03.849251  7239 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0129 22:47:03.849256  7239 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0129 22:47:03.849292  7239 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I0129 22:47:03.849298  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.849300  7239 net.cpp:129] Top shape: 50 160 32 32 (8192000)
I0129 22:47:03.849303  7239 net.cpp:137] Memory required for data: 1999463000
I0129 22:47:03.849304  7239 layer_factory.hpp:77] Creating layer Convolution12
I0129 22:47:03.849311  7239 net.cpp:84] Creating Layer Convolution12
I0129 22:47:03.849314  7239 net.cpp:406] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0129 22:47:03.849319  7239 net.cpp:380] Convolution12 -> Convolution12
I0129 22:47:03.850692  7239 net.cpp:122] Setting up Convolution12
I0129 22:47:03.850703  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.850706  7239 net.cpp:137] Memory required for data: 2015847000
I0129 22:47:03.850710  7239 layer_factory.hpp:77] Creating layer BatchNorm12
I0129 22:47:03.850718  7239 net.cpp:84] Creating Layer BatchNorm12
I0129 22:47:03.850726  7239 net.cpp:406] BatchNorm12 <- Convolution12
I0129 22:47:03.850731  7239 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0129 22:47:03.850915  7239 net.cpp:122] Setting up BatchNorm12
I0129 22:47:03.850921  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.850924  7239 net.cpp:137] Memory required for data: 2032231000
I0129 22:47:03.850929  7239 layer_factory.hpp:77] Creating layer Scale12
I0129 22:47:03.850934  7239 net.cpp:84] Creating Layer Scale12
I0129 22:47:03.850937  7239 net.cpp:406] Scale12 <- Convolution12
I0129 22:47:03.850940  7239 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0129 22:47:03.850980  7239 layer_factory.hpp:77] Creating layer Scale12
I0129 22:47:03.851084  7239 net.cpp:122] Setting up Scale12
I0129 22:47:03.851090  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.851092  7239 net.cpp:137] Memory required for data: 2048615000
I0129 22:47:03.851097  7239 layer_factory.hpp:77] Creating layer Convolution13
I0129 22:47:03.851104  7239 net.cpp:84] Creating Layer Convolution13
I0129 22:47:03.851107  7239 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_1
I0129 22:47:03.851122  7239 net.cpp:380] Convolution13 -> Convolution13
I0129 22:47:03.856076  7239 net.cpp:122] Setting up Convolution13
I0129 22:47:03.856088  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.856091  7239 net.cpp:137] Memory required for data: 2064999000
I0129 22:47:03.856096  7239 layer_factory.hpp:77] Creating layer BatchNorm13
I0129 22:47:03.856103  7239 net.cpp:84] Creating Layer BatchNorm13
I0129 22:47:03.856106  7239 net.cpp:406] BatchNorm13 <- Convolution13
I0129 22:47:03.856109  7239 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0129 22:47:03.856287  7239 net.cpp:122] Setting up BatchNorm13
I0129 22:47:03.856293  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.856295  7239 net.cpp:137] Memory required for data: 2081383000
I0129 22:47:03.856300  7239 layer_factory.hpp:77] Creating layer Scale13
I0129 22:47:03.856305  7239 net.cpp:84] Creating Layer Scale13
I0129 22:47:03.856308  7239 net.cpp:406] Scale13 <- Convolution13
I0129 22:47:03.856312  7239 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0129 22:47:03.856349  7239 layer_factory.hpp:77] Creating layer Scale13
I0129 22:47:03.856454  7239 net.cpp:122] Setting up Scale13
I0129 22:47:03.856461  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.856463  7239 net.cpp:137] Memory required for data: 2097767000
I0129 22:47:03.856467  7239 layer_factory.hpp:77] Creating layer ReLU12
I0129 22:47:03.856470  7239 net.cpp:84] Creating Layer ReLU12
I0129 22:47:03.856473  7239 net.cpp:406] ReLU12 <- Convolution13
I0129 22:47:03.856477  7239 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I0129 22:47:03.856947  7239 net.cpp:122] Setting up ReLU12
I0129 22:47:03.856959  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.856962  7239 net.cpp:137] Memory required for data: 2114151000
I0129 22:47:03.856966  7239 layer_factory.hpp:77] Creating layer Convolution14
I0129 22:47:03.856977  7239 net.cpp:84] Creating Layer Convolution14
I0129 22:47:03.856981  7239 net.cpp:406] Convolution14 <- Convolution13
I0129 22:47:03.856986  7239 net.cpp:380] Convolution14 -> Convolution14
I0129 22:47:03.865483  7239 net.cpp:122] Setting up Convolution14
I0129 22:47:03.865495  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.865497  7239 net.cpp:137] Memory required for data: 2130535000
I0129 22:47:03.865504  7239 layer_factory.hpp:77] Creating layer BatchNorm14
I0129 22:47:03.865509  7239 net.cpp:84] Creating Layer BatchNorm14
I0129 22:47:03.865512  7239 net.cpp:406] BatchNorm14 <- Convolution14
I0129 22:47:03.865516  7239 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0129 22:47:03.865701  7239 net.cpp:122] Setting up BatchNorm14
I0129 22:47:03.865708  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.865710  7239 net.cpp:137] Memory required for data: 2146919000
I0129 22:47:03.865715  7239 layer_factory.hpp:77] Creating layer Scale14
I0129 22:47:03.865720  7239 net.cpp:84] Creating Layer Scale14
I0129 22:47:03.865722  7239 net.cpp:406] Scale14 <- Convolution14
I0129 22:47:03.865726  7239 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0129 22:47:03.865764  7239 layer_factory.hpp:77] Creating layer Scale14
I0129 22:47:03.865871  7239 net.cpp:122] Setting up Scale14
I0129 22:47:03.865877  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.865880  7239 net.cpp:137] Memory required for data: 2163303000
I0129 22:47:03.865882  7239 layer_factory.hpp:77] Creating layer Eltwise6
I0129 22:47:03.865887  7239 net.cpp:84] Creating Layer Eltwise6
I0129 22:47:03.865890  7239 net.cpp:406] Eltwise6 <- Convolution12
I0129 22:47:03.865892  7239 net.cpp:406] Eltwise6 <- Convolution14
I0129 22:47:03.865897  7239 net.cpp:380] Eltwise6 -> Eltwise6
I0129 22:47:03.865916  7239 net.cpp:122] Setting up Eltwise6
I0129 22:47:03.865921  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.865923  7239 net.cpp:137] Memory required for data: 2179687000
I0129 22:47:03.865926  7239 layer_factory.hpp:77] Creating layer ReLU13
I0129 22:47:03.865931  7239 net.cpp:84] Creating Layer ReLU13
I0129 22:47:03.865941  7239 net.cpp:406] ReLU13 <- Eltwise6
I0129 22:47:03.865944  7239 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I0129 22:47:03.866427  7239 net.cpp:122] Setting up ReLU13
I0129 22:47:03.866438  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.866441  7239 net.cpp:137] Memory required for data: 2196071000
I0129 22:47:03.866443  7239 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0129 22:47:03.866448  7239 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I0129 22:47:03.866452  7239 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I0129 22:47:03.866456  7239 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0129 22:47:03.866461  7239 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0129 22:47:03.866503  7239 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I0129 22:47:03.866508  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.866510  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.866513  7239 net.cpp:137] Memory required for data: 2228839000
I0129 22:47:03.866514  7239 layer_factory.hpp:77] Creating layer Convolution15
I0129 22:47:03.866523  7239 net.cpp:84] Creating Layer Convolution15
I0129 22:47:03.866526  7239 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0129 22:47:03.866530  7239 net.cpp:380] Convolution15 -> Convolution15
I0129 22:47:03.875496  7239 net.cpp:122] Setting up Convolution15
I0129 22:47:03.875511  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.875514  7239 net.cpp:137] Memory required for data: 2245223000
I0129 22:47:03.875519  7239 layer_factory.hpp:77] Creating layer BatchNorm15
I0129 22:47:03.875524  7239 net.cpp:84] Creating Layer BatchNorm15
I0129 22:47:03.875527  7239 net.cpp:406] BatchNorm15 <- Convolution15
I0129 22:47:03.875532  7239 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0129 22:47:03.875723  7239 net.cpp:122] Setting up BatchNorm15
I0129 22:47:03.875730  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.875732  7239 net.cpp:137] Memory required for data: 2261607000
I0129 22:47:03.875737  7239 layer_factory.hpp:77] Creating layer Scale15
I0129 22:47:03.875741  7239 net.cpp:84] Creating Layer Scale15
I0129 22:47:03.875744  7239 net.cpp:406] Scale15 <- Convolution15
I0129 22:47:03.875747  7239 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0129 22:47:03.875787  7239 layer_factory.hpp:77] Creating layer Scale15
I0129 22:47:03.875895  7239 net.cpp:122] Setting up Scale15
I0129 22:47:03.875900  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.875903  7239 net.cpp:137] Memory required for data: 2277991000
I0129 22:47:03.875907  7239 layer_factory.hpp:77] Creating layer ReLU14
I0129 22:47:03.875911  7239 net.cpp:84] Creating Layer ReLU14
I0129 22:47:03.875913  7239 net.cpp:406] ReLU14 <- Convolution15
I0129 22:47:03.875917  7239 net.cpp:367] ReLU14 -> Convolution15 (in-place)
I0129 22:47:03.876071  7239 net.cpp:122] Setting up ReLU14
I0129 22:47:03.876078  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.876080  7239 net.cpp:137] Memory required for data: 2294375000
I0129 22:47:03.876083  7239 layer_factory.hpp:77] Creating layer Convolution16
I0129 22:47:03.876091  7239 net.cpp:84] Creating Layer Convolution16
I0129 22:47:03.876094  7239 net.cpp:406] Convolution16 <- Convolution15
I0129 22:47:03.876098  7239 net.cpp:380] Convolution16 -> Convolution16
I0129 22:47:03.884925  7239 net.cpp:122] Setting up Convolution16
I0129 22:47:03.884938  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.884940  7239 net.cpp:137] Memory required for data: 2310759000
I0129 22:47:03.884945  7239 layer_factory.hpp:77] Creating layer BatchNorm16
I0129 22:47:03.884953  7239 net.cpp:84] Creating Layer BatchNorm16
I0129 22:47:03.884955  7239 net.cpp:406] BatchNorm16 <- Convolution16
I0129 22:47:03.884959  7239 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0129 22:47:03.885149  7239 net.cpp:122] Setting up BatchNorm16
I0129 22:47:03.885157  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.885169  7239 net.cpp:137] Memory required for data: 2327143000
I0129 22:47:03.885174  7239 layer_factory.hpp:77] Creating layer Scale16
I0129 22:47:03.885179  7239 net.cpp:84] Creating Layer Scale16
I0129 22:47:03.885182  7239 net.cpp:406] Scale16 <- Convolution16
I0129 22:47:03.885185  7239 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0129 22:47:03.885228  7239 layer_factory.hpp:77] Creating layer Scale16
I0129 22:47:03.885334  7239 net.cpp:122] Setting up Scale16
I0129 22:47:03.885341  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.885344  7239 net.cpp:137] Memory required for data: 2343527000
I0129 22:47:03.885347  7239 layer_factory.hpp:77] Creating layer Eltwise7
I0129 22:47:03.885352  7239 net.cpp:84] Creating Layer Eltwise7
I0129 22:47:03.885356  7239 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0129 22:47:03.885360  7239 net.cpp:406] Eltwise7 <- Convolution16
I0129 22:47:03.885363  7239 net.cpp:380] Eltwise7 -> Eltwise7
I0129 22:47:03.885381  7239 net.cpp:122] Setting up Eltwise7
I0129 22:47:03.885386  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.885388  7239 net.cpp:137] Memory required for data: 2359911000
I0129 22:47:03.885390  7239 layer_factory.hpp:77] Creating layer ReLU15
I0129 22:47:03.885396  7239 net.cpp:84] Creating Layer ReLU15
I0129 22:47:03.885398  7239 net.cpp:406] ReLU15 <- Eltwise7
I0129 22:47:03.885401  7239 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I0129 22:47:03.885555  7239 net.cpp:122] Setting up ReLU15
I0129 22:47:03.885563  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.885566  7239 net.cpp:137] Memory required for data: 2376295000
I0129 22:47:03.885568  7239 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0129 22:47:03.885572  7239 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I0129 22:47:03.885574  7239 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I0129 22:47:03.885579  7239 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0129 22:47:03.885584  7239 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0129 22:47:03.885622  7239 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I0129 22:47:03.885627  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.885632  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.885633  7239 net.cpp:137] Memory required for data: 2409063000
I0129 22:47:03.885635  7239 layer_factory.hpp:77] Creating layer Convolution17
I0129 22:47:03.885643  7239 net.cpp:84] Creating Layer Convolution17
I0129 22:47:03.885646  7239 net.cpp:406] Convolution17 <- Eltwise7_ReLU15_0_split_0
I0129 22:47:03.885651  7239 net.cpp:380] Convolution17 -> Convolution17
I0129 22:47:03.894489  7239 net.cpp:122] Setting up Convolution17
I0129 22:47:03.894501  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.894505  7239 net.cpp:137] Memory required for data: 2425447000
I0129 22:47:03.894510  7239 layer_factory.hpp:77] Creating layer BatchNorm17
I0129 22:47:03.894515  7239 net.cpp:84] Creating Layer BatchNorm17
I0129 22:47:03.894517  7239 net.cpp:406] BatchNorm17 <- Convolution17
I0129 22:47:03.894523  7239 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0129 22:47:03.894716  7239 net.cpp:122] Setting up BatchNorm17
I0129 22:47:03.894729  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.894732  7239 net.cpp:137] Memory required for data: 2441831000
I0129 22:47:03.894738  7239 layer_factory.hpp:77] Creating layer Scale17
I0129 22:47:03.894742  7239 net.cpp:84] Creating Layer Scale17
I0129 22:47:03.894745  7239 net.cpp:406] Scale17 <- Convolution17
I0129 22:47:03.894748  7239 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0129 22:47:03.894790  7239 layer_factory.hpp:77] Creating layer Scale17
I0129 22:47:03.894896  7239 net.cpp:122] Setting up Scale17
I0129 22:47:03.894903  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.894906  7239 net.cpp:137] Memory required for data: 2458215000
I0129 22:47:03.894910  7239 layer_factory.hpp:77] Creating layer ReLU16
I0129 22:47:03.894922  7239 net.cpp:84] Creating Layer ReLU16
I0129 22:47:03.894925  7239 net.cpp:406] ReLU16 <- Convolution17
I0129 22:47:03.894928  7239 net.cpp:367] ReLU16 -> Convolution17 (in-place)
I0129 22:47:03.895084  7239 net.cpp:122] Setting up ReLU16
I0129 22:47:03.895092  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.895094  7239 net.cpp:137] Memory required for data: 2474599000
I0129 22:47:03.895097  7239 layer_factory.hpp:77] Creating layer Convolution18
I0129 22:47:03.895105  7239 net.cpp:84] Creating Layer Convolution18
I0129 22:47:03.895108  7239 net.cpp:406] Convolution18 <- Convolution17
I0129 22:47:03.895113  7239 net.cpp:380] Convolution18 -> Convolution18
I0129 22:47:03.903947  7239 net.cpp:122] Setting up Convolution18
I0129 22:47:03.903959  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.903964  7239 net.cpp:137] Memory required for data: 2490983000
I0129 22:47:03.903969  7239 layer_factory.hpp:77] Creating layer BatchNorm18
I0129 22:47:03.903973  7239 net.cpp:84] Creating Layer BatchNorm18
I0129 22:47:03.903977  7239 net.cpp:406] BatchNorm18 <- Convolution18
I0129 22:47:03.903982  7239 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0129 22:47:03.904176  7239 net.cpp:122] Setting up BatchNorm18
I0129 22:47:03.904182  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.904186  7239 net.cpp:137] Memory required for data: 2507367000
I0129 22:47:03.904191  7239 layer_factory.hpp:77] Creating layer Scale18
I0129 22:47:03.904194  7239 net.cpp:84] Creating Layer Scale18
I0129 22:47:03.904196  7239 net.cpp:406] Scale18 <- Convolution18
I0129 22:47:03.904201  7239 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0129 22:47:03.904239  7239 layer_factory.hpp:77] Creating layer Scale18
I0129 22:47:03.904345  7239 net.cpp:122] Setting up Scale18
I0129 22:47:03.904351  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.904355  7239 net.cpp:137] Memory required for data: 2523751000
I0129 22:47:03.904358  7239 layer_factory.hpp:77] Creating layer Eltwise8
I0129 22:47:03.904363  7239 net.cpp:84] Creating Layer Eltwise8
I0129 22:47:03.904366  7239 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0129 22:47:03.904369  7239 net.cpp:406] Eltwise8 <- Convolution18
I0129 22:47:03.904373  7239 net.cpp:380] Eltwise8 -> Eltwise8
I0129 22:47:03.904393  7239 net.cpp:122] Setting up Eltwise8
I0129 22:47:03.904398  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.904400  7239 net.cpp:137] Memory required for data: 2540135000
I0129 22:47:03.904402  7239 layer_factory.hpp:77] Creating layer ReLU17
I0129 22:47:03.904407  7239 net.cpp:84] Creating Layer ReLU17
I0129 22:47:03.904408  7239 net.cpp:406] ReLU17 <- Eltwise8
I0129 22:47:03.904413  7239 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I0129 22:47:03.904567  7239 net.cpp:122] Setting up ReLU17
I0129 22:47:03.904574  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.904577  7239 net.cpp:137] Memory required for data: 2556519000
I0129 22:47:03.904580  7239 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0129 22:47:03.904584  7239 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I0129 22:47:03.904587  7239 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I0129 22:47:03.904590  7239 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0129 22:47:03.904597  7239 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0129 22:47:03.904635  7239 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I0129 22:47:03.904640  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.904644  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.904645  7239 net.cpp:137] Memory required for data: 2589287000
I0129 22:47:03.904647  7239 layer_factory.hpp:77] Creating layer Convolution19
I0129 22:47:03.904656  7239 net.cpp:84] Creating Layer Convolution19
I0129 22:47:03.904660  7239 net.cpp:406] Convolution19 <- Eltwise8_ReLU17_0_split_0
I0129 22:47:03.904665  7239 net.cpp:380] Convolution19 -> Convolution19
I0129 22:47:03.913887  7239 net.cpp:122] Setting up Convolution19
I0129 22:47:03.913900  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.913903  7239 net.cpp:137] Memory required for data: 2605671000
I0129 22:47:03.913908  7239 layer_factory.hpp:77] Creating layer BatchNorm19
I0129 22:47:03.913914  7239 net.cpp:84] Creating Layer BatchNorm19
I0129 22:47:03.913918  7239 net.cpp:406] BatchNorm19 <- Convolution19
I0129 22:47:03.913923  7239 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0129 22:47:03.914115  7239 net.cpp:122] Setting up BatchNorm19
I0129 22:47:03.914122  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.914124  7239 net.cpp:137] Memory required for data: 2622055000
I0129 22:47:03.914144  7239 layer_factory.hpp:77] Creating layer Scale19
I0129 22:47:03.914151  7239 net.cpp:84] Creating Layer Scale19
I0129 22:47:03.914153  7239 net.cpp:406] Scale19 <- Convolution19
I0129 22:47:03.914156  7239 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0129 22:47:03.914199  7239 layer_factory.hpp:77] Creating layer Scale19
I0129 22:47:03.914309  7239 net.cpp:122] Setting up Scale19
I0129 22:47:03.914315  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.914317  7239 net.cpp:137] Memory required for data: 2638439000
I0129 22:47:03.914321  7239 layer_factory.hpp:77] Creating layer ReLU18
I0129 22:47:03.914326  7239 net.cpp:84] Creating Layer ReLU18
I0129 22:47:03.914328  7239 net.cpp:406] ReLU18 <- Convolution19
I0129 22:47:03.914331  7239 net.cpp:367] ReLU18 -> Convolution19 (in-place)
I0129 22:47:03.914832  7239 net.cpp:122] Setting up ReLU18
I0129 22:47:03.914844  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.914847  7239 net.cpp:137] Memory required for data: 2654823000
I0129 22:47:03.914850  7239 layer_factory.hpp:77] Creating layer Convolution20
I0129 22:47:03.914858  7239 net.cpp:84] Creating Layer Convolution20
I0129 22:47:03.914861  7239 net.cpp:406] Convolution20 <- Convolution19
I0129 22:47:03.914866  7239 net.cpp:380] Convolution20 -> Convolution20
I0129 22:47:03.923390  7239 net.cpp:122] Setting up Convolution20
I0129 22:47:03.923403  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.923408  7239 net.cpp:137] Memory required for data: 2671207000
I0129 22:47:03.923413  7239 layer_factory.hpp:77] Creating layer BatchNorm20
I0129 22:47:03.923418  7239 net.cpp:84] Creating Layer BatchNorm20
I0129 22:47:03.923420  7239 net.cpp:406] BatchNorm20 <- Convolution20
I0129 22:47:03.923425  7239 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0129 22:47:03.923621  7239 net.cpp:122] Setting up BatchNorm20
I0129 22:47:03.923629  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.923630  7239 net.cpp:137] Memory required for data: 2687591000
I0129 22:47:03.923636  7239 layer_factory.hpp:77] Creating layer Scale20
I0129 22:47:03.923640  7239 net.cpp:84] Creating Layer Scale20
I0129 22:47:03.923642  7239 net.cpp:406] Scale20 <- Convolution20
I0129 22:47:03.923645  7239 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0129 22:47:03.923686  7239 layer_factory.hpp:77] Creating layer Scale20
I0129 22:47:03.923795  7239 net.cpp:122] Setting up Scale20
I0129 22:47:03.923804  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.923805  7239 net.cpp:137] Memory required for data: 2703975000
I0129 22:47:03.923810  7239 layer_factory.hpp:77] Creating layer Eltwise9
I0129 22:47:03.923815  7239 net.cpp:84] Creating Layer Eltwise9
I0129 22:47:03.923816  7239 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0129 22:47:03.923820  7239 net.cpp:406] Eltwise9 <- Convolution20
I0129 22:47:03.923823  7239 net.cpp:380] Eltwise9 -> Eltwise9
I0129 22:47:03.923843  7239 net.cpp:122] Setting up Eltwise9
I0129 22:47:03.923848  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.923851  7239 net.cpp:137] Memory required for data: 2720359000
I0129 22:47:03.923853  7239 layer_factory.hpp:77] Creating layer ReLU19
I0129 22:47:03.923857  7239 net.cpp:84] Creating Layer ReLU19
I0129 22:47:03.923859  7239 net.cpp:406] ReLU19 <- Eltwise9
I0129 22:47:03.923873  7239 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I0129 22:47:03.924372  7239 net.cpp:122] Setting up ReLU19
I0129 22:47:03.924383  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.924386  7239 net.cpp:137] Memory required for data: 2736743000
I0129 22:47:03.924388  7239 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0129 22:47:03.924394  7239 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I0129 22:47:03.924397  7239 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I0129 22:47:03.924403  7239 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0129 22:47:03.924409  7239 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0129 22:47:03.924451  7239 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I0129 22:47:03.924458  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.924460  7239 net.cpp:129] Top shape: 50 320 16 16 (4096000)
I0129 22:47:03.924463  7239 net.cpp:137] Memory required for data: 2769511000
I0129 22:47:03.924465  7239 layer_factory.hpp:77] Creating layer Convolution23
I0129 22:47:03.924473  7239 net.cpp:84] Creating Layer Convolution23
I0129 22:47:03.924475  7239 net.cpp:406] Convolution23 <- Eltwise9_ReLU19_0_split_0
I0129 22:47:03.924479  7239 net.cpp:380] Convolution23 -> Convolution23
I0129 22:47:03.927001  7239 net.cpp:122] Setting up Convolution23
I0129 22:47:03.927014  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.927016  7239 net.cpp:137] Memory required for data: 2777703000
I0129 22:47:03.927021  7239 layer_factory.hpp:77] Creating layer BatchNorm23
I0129 22:47:03.927027  7239 net.cpp:84] Creating Layer BatchNorm23
I0129 22:47:03.927031  7239 net.cpp:406] BatchNorm23 <- Convolution23
I0129 22:47:03.927034  7239 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0129 22:47:03.927222  7239 net.cpp:122] Setting up BatchNorm23
I0129 22:47:03.927229  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.927232  7239 net.cpp:137] Memory required for data: 2785895000
I0129 22:47:03.927237  7239 layer_factory.hpp:77] Creating layer Scale23
I0129 22:47:03.927242  7239 net.cpp:84] Creating Layer Scale23
I0129 22:47:03.927244  7239 net.cpp:406] Scale23 <- Convolution23
I0129 22:47:03.927248  7239 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0129 22:47:03.927284  7239 layer_factory.hpp:77] Creating layer Scale23
I0129 22:47:03.927395  7239 net.cpp:122] Setting up Scale23
I0129 22:47:03.927402  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.927403  7239 net.cpp:137] Memory required for data: 2794087000
I0129 22:47:03.927407  7239 layer_factory.hpp:77] Creating layer Convolution24
I0129 22:47:03.927415  7239 net.cpp:84] Creating Layer Convolution24
I0129 22:47:03.927418  7239 net.cpp:406] Convolution24 <- Eltwise9_ReLU19_0_split_1
I0129 22:47:03.927423  7239 net.cpp:380] Convolution24 -> Convolution24
I0129 22:47:03.942824  7239 net.cpp:122] Setting up Convolution24
I0129 22:47:03.942840  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.942843  7239 net.cpp:137] Memory required for data: 2802279000
I0129 22:47:03.942848  7239 layer_factory.hpp:77] Creating layer BatchNorm24
I0129 22:47:03.942855  7239 net.cpp:84] Creating Layer BatchNorm24
I0129 22:47:03.942858  7239 net.cpp:406] BatchNorm24 <- Convolution24
I0129 22:47:03.942863  7239 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0129 22:47:03.943054  7239 net.cpp:122] Setting up BatchNorm24
I0129 22:47:03.943060  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.943063  7239 net.cpp:137] Memory required for data: 2810471000
I0129 22:47:03.943068  7239 layer_factory.hpp:77] Creating layer Scale24
I0129 22:47:03.943073  7239 net.cpp:84] Creating Layer Scale24
I0129 22:47:03.943075  7239 net.cpp:406] Scale24 <- Convolution24
I0129 22:47:03.943078  7239 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0129 22:47:03.943116  7239 layer_factory.hpp:77] Creating layer Scale24
I0129 22:47:03.943228  7239 net.cpp:122] Setting up Scale24
I0129 22:47:03.943245  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.943248  7239 net.cpp:137] Memory required for data: 2818663000
I0129 22:47:03.943253  7239 layer_factory.hpp:77] Creating layer ReLU22
I0129 22:47:03.943256  7239 net.cpp:84] Creating Layer ReLU22
I0129 22:47:03.943259  7239 net.cpp:406] ReLU22 <- Convolution24
I0129 22:47:03.943264  7239 net.cpp:367] ReLU22 -> Convolution24 (in-place)
I0129 22:47:03.943768  7239 net.cpp:122] Setting up ReLU22
I0129 22:47:03.943779  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.943783  7239 net.cpp:137] Memory required for data: 2826855000
I0129 22:47:03.943785  7239 layer_factory.hpp:77] Creating layer Convolution25
I0129 22:47:03.943794  7239 net.cpp:84] Creating Layer Convolution25
I0129 22:47:03.943797  7239 net.cpp:406] Convolution25 <- Convolution24
I0129 22:47:03.943802  7239 net.cpp:380] Convolution25 -> Convolution25
I0129 22:47:03.974581  7239 net.cpp:122] Setting up Convolution25
I0129 22:47:03.974606  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.974608  7239 net.cpp:137] Memory required for data: 2835047000
I0129 22:47:03.974617  7239 layer_factory.hpp:77] Creating layer BatchNorm25
I0129 22:47:03.974624  7239 net.cpp:84] Creating Layer BatchNorm25
I0129 22:47:03.974628  7239 net.cpp:406] BatchNorm25 <- Convolution25
I0129 22:47:03.974635  7239 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0129 22:47:03.974843  7239 net.cpp:122] Setting up BatchNorm25
I0129 22:47:03.974849  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.974851  7239 net.cpp:137] Memory required for data: 2843239000
I0129 22:47:03.974856  7239 layer_factory.hpp:77] Creating layer Scale25
I0129 22:47:03.974864  7239 net.cpp:84] Creating Layer Scale25
I0129 22:47:03.974865  7239 net.cpp:406] Scale25 <- Convolution25
I0129 22:47:03.974869  7239 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0129 22:47:03.974910  7239 layer_factory.hpp:77] Creating layer Scale25
I0129 22:47:03.975024  7239 net.cpp:122] Setting up Scale25
I0129 22:47:03.975030  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.975033  7239 net.cpp:137] Memory required for data: 2851431000
I0129 22:47:03.975036  7239 layer_factory.hpp:77] Creating layer Eltwise11
I0129 22:47:03.975044  7239 net.cpp:84] Creating Layer Eltwise11
I0129 22:47:03.975045  7239 net.cpp:406] Eltwise11 <- Convolution23
I0129 22:47:03.975049  7239 net.cpp:406] Eltwise11 <- Convolution25
I0129 22:47:03.975054  7239 net.cpp:380] Eltwise11 -> Eltwise11
I0129 22:47:03.975077  7239 net.cpp:122] Setting up Eltwise11
I0129 22:47:03.975083  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.975085  7239 net.cpp:137] Memory required for data: 2859623000
I0129 22:47:03.975087  7239 layer_factory.hpp:77] Creating layer ReLU23
I0129 22:47:03.975092  7239 net.cpp:84] Creating Layer ReLU23
I0129 22:47:03.975095  7239 net.cpp:406] ReLU23 <- Eltwise11
I0129 22:47:03.975100  7239 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I0129 22:47:03.975246  7239 net.cpp:122] Setting up ReLU23
I0129 22:47:03.975253  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.975256  7239 net.cpp:137] Memory required for data: 2867815000
I0129 22:47:03.975258  7239 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0129 22:47:03.975263  7239 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I0129 22:47:03.975266  7239 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I0129 22:47:03.975271  7239 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0129 22:47:03.975276  7239 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0129 22:47:03.975317  7239 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I0129 22:47:03.975322  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.975324  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:03.975327  7239 net.cpp:137] Memory required for data: 2884199000
I0129 22:47:03.975329  7239 layer_factory.hpp:77] Creating layer Convolution26
I0129 22:47:03.975338  7239 net.cpp:84] Creating Layer Convolution26
I0129 22:47:03.975354  7239 net.cpp:406] Convolution26 <- Eltwise11_ReLU23_0_split_0
I0129 22:47:03.975363  7239 net.cpp:380] Convolution26 -> Convolution26
I0129 22:47:04.006058  7239 net.cpp:122] Setting up Convolution26
I0129 22:47:04.006080  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.006083  7239 net.cpp:137] Memory required for data: 2892391000
I0129 22:47:04.006093  7239 layer_factory.hpp:77] Creating layer BatchNorm26
I0129 22:47:04.006101  7239 net.cpp:84] Creating Layer BatchNorm26
I0129 22:47:04.006104  7239 net.cpp:406] BatchNorm26 <- Convolution26
I0129 22:47:04.006111  7239 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0129 22:47:04.006319  7239 net.cpp:122] Setting up BatchNorm26
I0129 22:47:04.006325  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.006327  7239 net.cpp:137] Memory required for data: 2900583000
I0129 22:47:04.006332  7239 layer_factory.hpp:77] Creating layer Scale26
I0129 22:47:04.006338  7239 net.cpp:84] Creating Layer Scale26
I0129 22:47:04.006341  7239 net.cpp:406] Scale26 <- Convolution26
I0129 22:47:04.006345  7239 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0129 22:47:04.006388  7239 layer_factory.hpp:77] Creating layer Scale26
I0129 22:47:04.006501  7239 net.cpp:122] Setting up Scale26
I0129 22:47:04.006510  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.006511  7239 net.cpp:137] Memory required for data: 2908775000
I0129 22:47:04.006515  7239 layer_factory.hpp:77] Creating layer ReLU24
I0129 22:47:04.006520  7239 net.cpp:84] Creating Layer ReLU24
I0129 22:47:04.006523  7239 net.cpp:406] ReLU24 <- Convolution26
I0129 22:47:04.006526  7239 net.cpp:367] ReLU24 -> Convolution26 (in-place)
I0129 22:47:04.006676  7239 net.cpp:122] Setting up ReLU24
I0129 22:47:04.006685  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.006686  7239 net.cpp:137] Memory required for data: 2916967000
I0129 22:47:04.006688  7239 layer_factory.hpp:77] Creating layer Convolution27
I0129 22:47:04.006700  7239 net.cpp:84] Creating Layer Convolution27
I0129 22:47:04.006702  7239 net.cpp:406] Convolution27 <- Convolution26
I0129 22:47:04.006707  7239 net.cpp:380] Convolution27 -> Convolution27
I0129 22:47:04.037240  7239 net.cpp:122] Setting up Convolution27
I0129 22:47:04.037262  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.037266  7239 net.cpp:137] Memory required for data: 2925159000
I0129 22:47:04.037273  7239 layer_factory.hpp:77] Creating layer BatchNorm27
I0129 22:47:04.037283  7239 net.cpp:84] Creating Layer BatchNorm27
I0129 22:47:04.037286  7239 net.cpp:406] BatchNorm27 <- Convolution27
I0129 22:47:04.037293  7239 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0129 22:47:04.037492  7239 net.cpp:122] Setting up BatchNorm27
I0129 22:47:04.037498  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.037500  7239 net.cpp:137] Memory required for data: 2933351000
I0129 22:47:04.037506  7239 layer_factory.hpp:77] Creating layer Scale27
I0129 22:47:04.037513  7239 net.cpp:84] Creating Layer Scale27
I0129 22:47:04.037515  7239 net.cpp:406] Scale27 <- Convolution27
I0129 22:47:04.037518  7239 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0129 22:47:04.037560  7239 layer_factory.hpp:77] Creating layer Scale27
I0129 22:47:04.037673  7239 net.cpp:122] Setting up Scale27
I0129 22:47:04.037679  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.037681  7239 net.cpp:137] Memory required for data: 2941543000
I0129 22:47:04.037686  7239 layer_factory.hpp:77] Creating layer Eltwise12
I0129 22:47:04.037691  7239 net.cpp:84] Creating Layer Eltwise12
I0129 22:47:04.037694  7239 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0129 22:47:04.037698  7239 net.cpp:406] Eltwise12 <- Convolution27
I0129 22:47:04.037703  7239 net.cpp:380] Eltwise12 -> Eltwise12
I0129 22:47:04.037729  7239 net.cpp:122] Setting up Eltwise12
I0129 22:47:04.037734  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.037735  7239 net.cpp:137] Memory required for data: 2949735000
I0129 22:47:04.037752  7239 layer_factory.hpp:77] Creating layer ReLU25
I0129 22:47:04.037756  7239 net.cpp:84] Creating Layer ReLU25
I0129 22:47:04.037760  7239 net.cpp:406] ReLU25 <- Eltwise12
I0129 22:47:04.037762  7239 net.cpp:367] ReLU25 -> Eltwise12 (in-place)
I0129 22:47:04.037917  7239 net.cpp:122] Setting up ReLU25
I0129 22:47:04.037925  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.037927  7239 net.cpp:137] Memory required for data: 2957927000
I0129 22:47:04.037930  7239 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0129 22:47:04.037936  7239 net.cpp:84] Creating Layer Eltwise12_ReLU25_0_split
I0129 22:47:04.037938  7239 net.cpp:406] Eltwise12_ReLU25_0_split <- Eltwise12
I0129 22:47:04.037943  7239 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0129 22:47:04.037948  7239 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0129 22:47:04.037988  7239 net.cpp:122] Setting up Eltwise12_ReLU25_0_split
I0129 22:47:04.037994  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.037997  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.037999  7239 net.cpp:137] Memory required for data: 2974311000
I0129 22:47:04.038002  7239 layer_factory.hpp:77] Creating layer Convolution28
I0129 22:47:04.038009  7239 net.cpp:84] Creating Layer Convolution28
I0129 22:47:04.038012  7239 net.cpp:406] Convolution28 <- Eltwise12_ReLU25_0_split_0
I0129 22:47:04.038017  7239 net.cpp:380] Convolution28 -> Convolution28
I0129 22:47:04.068598  7239 net.cpp:122] Setting up Convolution28
I0129 22:47:04.068620  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.068624  7239 net.cpp:137] Memory required for data: 2982503000
I0129 22:47:04.068631  7239 layer_factory.hpp:77] Creating layer BatchNorm28
I0129 22:47:04.068640  7239 net.cpp:84] Creating Layer BatchNorm28
I0129 22:47:04.068645  7239 net.cpp:406] BatchNorm28 <- Convolution28
I0129 22:47:04.068650  7239 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0129 22:47:04.068851  7239 net.cpp:122] Setting up BatchNorm28
I0129 22:47:04.068858  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.068861  7239 net.cpp:137] Memory required for data: 2990695000
I0129 22:47:04.068866  7239 layer_factory.hpp:77] Creating layer Scale28
I0129 22:47:04.068871  7239 net.cpp:84] Creating Layer Scale28
I0129 22:47:04.068873  7239 net.cpp:406] Scale28 <- Convolution28
I0129 22:47:04.068876  7239 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0129 22:47:04.068919  7239 layer_factory.hpp:77] Creating layer Scale28
I0129 22:47:04.069036  7239 net.cpp:122] Setting up Scale28
I0129 22:47:04.069042  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.069046  7239 net.cpp:137] Memory required for data: 2998887000
I0129 22:47:04.069049  7239 layer_factory.hpp:77] Creating layer ReLU26
I0129 22:47:04.069053  7239 net.cpp:84] Creating Layer ReLU26
I0129 22:47:04.069056  7239 net.cpp:406] ReLU26 <- Convolution28
I0129 22:47:04.069061  7239 net.cpp:367] ReLU26 -> Convolution28 (in-place)
I0129 22:47:04.069211  7239 net.cpp:122] Setting up ReLU26
I0129 22:47:04.069218  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.069221  7239 net.cpp:137] Memory required for data: 3007079000
I0129 22:47:04.069223  7239 layer_factory.hpp:77] Creating layer Convolution29
I0129 22:47:04.069232  7239 net.cpp:84] Creating Layer Convolution29
I0129 22:47:04.069236  7239 net.cpp:406] Convolution29 <- Convolution28
I0129 22:47:04.069241  7239 net.cpp:380] Convolution29 -> Convolution29
I0129 22:47:04.099825  7239 net.cpp:122] Setting up Convolution29
I0129 22:47:04.099850  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.099853  7239 net.cpp:137] Memory required for data: 3015271000
I0129 22:47:04.099861  7239 layer_factory.hpp:77] Creating layer BatchNorm29
I0129 22:47:04.099884  7239 net.cpp:84] Creating Layer BatchNorm29
I0129 22:47:04.099889  7239 net.cpp:406] BatchNorm29 <- Convolution29
I0129 22:47:04.099895  7239 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0129 22:47:04.100112  7239 net.cpp:122] Setting up BatchNorm29
I0129 22:47:04.100119  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.100121  7239 net.cpp:137] Memory required for data: 3023463000
I0129 22:47:04.100127  7239 layer_factory.hpp:77] Creating layer Scale29
I0129 22:47:04.100134  7239 net.cpp:84] Creating Layer Scale29
I0129 22:47:04.100137  7239 net.cpp:406] Scale29 <- Convolution29
I0129 22:47:04.100142  7239 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0129 22:47:04.100185  7239 layer_factory.hpp:77] Creating layer Scale29
I0129 22:47:04.100301  7239 net.cpp:122] Setting up Scale29
I0129 22:47:04.100306  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.100308  7239 net.cpp:137] Memory required for data: 3031655000
I0129 22:47:04.100312  7239 layer_factory.hpp:77] Creating layer Eltwise13
I0129 22:47:04.100319  7239 net.cpp:84] Creating Layer Eltwise13
I0129 22:47:04.100322  7239 net.cpp:406] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0129 22:47:04.100325  7239 net.cpp:406] Eltwise13 <- Convolution29
I0129 22:47:04.100329  7239 net.cpp:380] Eltwise13 -> Eltwise13
I0129 22:47:04.100355  7239 net.cpp:122] Setting up Eltwise13
I0129 22:47:04.100360  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.100363  7239 net.cpp:137] Memory required for data: 3039847000
I0129 22:47:04.100364  7239 layer_factory.hpp:77] Creating layer ReLU27
I0129 22:47:04.100369  7239 net.cpp:84] Creating Layer ReLU27
I0129 22:47:04.100371  7239 net.cpp:406] ReLU27 <- Eltwise13
I0129 22:47:04.100376  7239 net.cpp:367] ReLU27 -> Eltwise13 (in-place)
I0129 22:47:04.100883  7239 net.cpp:122] Setting up ReLU27
I0129 22:47:04.100893  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.100895  7239 net.cpp:137] Memory required for data: 3048039000
I0129 22:47:04.100899  7239 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0129 22:47:04.100904  7239 net.cpp:84] Creating Layer Eltwise13_ReLU27_0_split
I0129 22:47:04.100908  7239 net.cpp:406] Eltwise13_ReLU27_0_split <- Eltwise13
I0129 22:47:04.100914  7239 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0129 22:47:04.100919  7239 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0129 22:47:04.100962  7239 net.cpp:122] Setting up Eltwise13_ReLU27_0_split
I0129 22:47:04.100968  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.100971  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.100973  7239 net.cpp:137] Memory required for data: 3064423000
I0129 22:47:04.100975  7239 layer_factory.hpp:77] Creating layer Convolution30
I0129 22:47:04.100985  7239 net.cpp:84] Creating Layer Convolution30
I0129 22:47:04.100986  7239 net.cpp:406] Convolution30 <- Eltwise13_ReLU27_0_split_0
I0129 22:47:04.100992  7239 net.cpp:380] Convolution30 -> Convolution30
I0129 22:47:04.131161  7239 net.cpp:122] Setting up Convolution30
I0129 22:47:04.131184  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.131187  7239 net.cpp:137] Memory required for data: 3072615000
I0129 22:47:04.131194  7239 layer_factory.hpp:77] Creating layer BatchNorm30
I0129 22:47:04.131202  7239 net.cpp:84] Creating Layer BatchNorm30
I0129 22:47:04.131206  7239 net.cpp:406] BatchNorm30 <- Convolution30
I0129 22:47:04.131212  7239 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0129 22:47:04.131415  7239 net.cpp:122] Setting up BatchNorm30
I0129 22:47:04.131422  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.131424  7239 net.cpp:137] Memory required for data: 3080807000
I0129 22:47:04.131429  7239 layer_factory.hpp:77] Creating layer Scale30
I0129 22:47:04.131434  7239 net.cpp:84] Creating Layer Scale30
I0129 22:47:04.131436  7239 net.cpp:406] Scale30 <- Convolution30
I0129 22:47:04.131440  7239 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0129 22:47:04.131485  7239 layer_factory.hpp:77] Creating layer Scale30
I0129 22:47:04.131600  7239 net.cpp:122] Setting up Scale30
I0129 22:47:04.131608  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.131623  7239 net.cpp:137] Memory required for data: 3088999000
I0129 22:47:04.131628  7239 layer_factory.hpp:77] Creating layer ReLU28
I0129 22:47:04.131633  7239 net.cpp:84] Creating Layer ReLU28
I0129 22:47:04.131636  7239 net.cpp:406] ReLU28 <- Convolution30
I0129 22:47:04.131640  7239 net.cpp:367] ReLU28 -> Convolution30 (in-place)
I0129 22:47:04.132263  7239 net.cpp:122] Setting up ReLU28
I0129 22:47:04.132274  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.132277  7239 net.cpp:137] Memory required for data: 3097191000
I0129 22:47:04.132279  7239 layer_factory.hpp:77] Creating layer Convolution31
I0129 22:47:04.132289  7239 net.cpp:84] Creating Layer Convolution31
I0129 22:47:04.132292  7239 net.cpp:406] Convolution31 <- Convolution30
I0129 22:47:04.132298  7239 net.cpp:380] Convolution31 -> Convolution31
I0129 22:47:04.162950  7239 net.cpp:122] Setting up Convolution31
I0129 22:47:04.162971  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.162974  7239 net.cpp:137] Memory required for data: 3105383000
I0129 22:47:04.162982  7239 layer_factory.hpp:77] Creating layer BatchNorm31
I0129 22:47:04.162992  7239 net.cpp:84] Creating Layer BatchNorm31
I0129 22:47:04.162995  7239 net.cpp:406] BatchNorm31 <- Convolution31
I0129 22:47:04.163002  7239 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0129 22:47:04.163206  7239 net.cpp:122] Setting up BatchNorm31
I0129 22:47:04.163213  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.163215  7239 net.cpp:137] Memory required for data: 3113575000
I0129 22:47:04.163221  7239 layer_factory.hpp:77] Creating layer Scale31
I0129 22:47:04.163226  7239 net.cpp:84] Creating Layer Scale31
I0129 22:47:04.163229  7239 net.cpp:406] Scale31 <- Convolution31
I0129 22:47:04.163233  7239 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0129 22:47:04.163278  7239 layer_factory.hpp:77] Creating layer Scale31
I0129 22:47:04.163396  7239 net.cpp:122] Setting up Scale31
I0129 22:47:04.163403  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.163405  7239 net.cpp:137] Memory required for data: 3121767000
I0129 22:47:04.163410  7239 layer_factory.hpp:77] Creating layer Eltwise14
I0129 22:47:04.163415  7239 net.cpp:84] Creating Layer Eltwise14
I0129 22:47:04.163419  7239 net.cpp:406] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0129 22:47:04.163422  7239 net.cpp:406] Eltwise14 <- Convolution31
I0129 22:47:04.163426  7239 net.cpp:380] Eltwise14 -> Eltwise14
I0129 22:47:04.163450  7239 net.cpp:122] Setting up Eltwise14
I0129 22:47:04.163456  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.163458  7239 net.cpp:137] Memory required for data: 3129959000
I0129 22:47:04.163460  7239 layer_factory.hpp:77] Creating layer ReLU29
I0129 22:47:04.163466  7239 net.cpp:84] Creating Layer ReLU29
I0129 22:47:04.163470  7239 net.cpp:406] ReLU29 <- Eltwise14
I0129 22:47:04.163472  7239 net.cpp:367] ReLU29 -> Eltwise14 (in-place)
I0129 22:47:04.163622  7239 net.cpp:122] Setting up ReLU29
I0129 22:47:04.163631  7239 net.cpp:129] Top shape: 50 640 8 8 (2048000)
I0129 22:47:04.163633  7239 net.cpp:137] Memory required for data: 3138151000
I0129 22:47:04.163636  7239 layer_factory.hpp:77] Creating layer Pooling1
I0129 22:47:04.163640  7239 net.cpp:84] Creating Layer Pooling1
I0129 22:47:04.163643  7239 net.cpp:406] Pooling1 <- Eltwise14
I0129 22:47:04.163647  7239 net.cpp:380] Pooling1 -> Pooling1
I0129 22:47:04.163815  7239 net.cpp:122] Setting up Pooling1
I0129 22:47:04.163823  7239 net.cpp:129] Top shape: 50 640 1 1 (32000)
I0129 22:47:04.163826  7239 net.cpp:137] Memory required for data: 3138279000
I0129 22:47:04.163828  7239 layer_factory.hpp:77] Creating layer InnerProduct1
I0129 22:47:04.163835  7239 net.cpp:84] Creating Layer InnerProduct1
I0129 22:47:04.163837  7239 net.cpp:406] InnerProduct1 <- Pooling1
I0129 22:47:04.163841  7239 net.cpp:380] InnerProduct1 -> InnerProduct1
I0129 22:47:04.164024  7239 net.cpp:122] Setting up InnerProduct1
I0129 22:47:04.164031  7239 net.cpp:129] Top shape: 50 10 (500)
I0129 22:47:04.164047  7239 net.cpp:137] Memory required for data: 3138281000
I0129 22:47:04.164052  7239 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0129 22:47:04.164057  7239 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0129 22:47:04.164059  7239 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0129 22:47:04.164063  7239 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0129 22:47:04.164068  7239 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0129 22:47:04.164109  7239 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0129 22:47:04.164115  7239 net.cpp:129] Top shape: 50 10 (500)
I0129 22:47:04.164117  7239 net.cpp:129] Top shape: 50 10 (500)
I0129 22:47:04.164119  7239 net.cpp:137] Memory required for data: 3138285000
I0129 22:47:04.164122  7239 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0129 22:47:04.164127  7239 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0129 22:47:04.164129  7239 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0129 22:47:04.164132  7239 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0129 22:47:04.164137  7239 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0129 22:47:04.164144  7239 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0129 22:47:04.164377  7239 net.cpp:122] Setting up SoftmaxWithLoss1
I0129 22:47:04.164384  7239 net.cpp:129] Top shape: (1)
I0129 22:47:04.164387  7239 net.cpp:132]     with loss weight 1
I0129 22:47:04.164396  7239 net.cpp:137] Memory required for data: 3138285004
I0129 22:47:04.164397  7239 layer_factory.hpp:77] Creating layer Accuracy1
I0129 22:47:04.164403  7239 net.cpp:84] Creating Layer Accuracy1
I0129 22:47:04.164407  7239 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0129 22:47:04.164410  7239 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0129 22:47:04.164415  7239 net.cpp:380] Accuracy1 -> Accuracy1
I0129 22:47:04.164422  7239 net.cpp:122] Setting up Accuracy1
I0129 22:47:04.164424  7239 net.cpp:129] Top shape: (1)
I0129 22:47:04.164427  7239 net.cpp:137] Memory required for data: 3138285008
I0129 22:47:04.164428  7239 net.cpp:200] Accuracy1 does not need backward computation.
I0129 22:47:04.164432  7239 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0129 22:47:04.164435  7239 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0129 22:47:04.164438  7239 net.cpp:198] InnerProduct1 needs backward computation.
I0129 22:47:04.164439  7239 net.cpp:198] Pooling1 needs backward computation.
I0129 22:47:04.164441  7239 net.cpp:198] ReLU29 needs backward computation.
I0129 22:47:04.164444  7239 net.cpp:198] Eltwise14 needs backward computation.
I0129 22:47:04.164448  7239 net.cpp:198] Scale31 needs backward computation.
I0129 22:47:04.164449  7239 net.cpp:198] BatchNorm31 needs backward computation.
I0129 22:47:04.164451  7239 net.cpp:198] Convolution31 needs backward computation.
I0129 22:47:04.164453  7239 net.cpp:198] ReLU28 needs backward computation.
I0129 22:47:04.164456  7239 net.cpp:198] Scale30 needs backward computation.
I0129 22:47:04.164458  7239 net.cpp:198] BatchNorm30 needs backward computation.
I0129 22:47:04.164460  7239 net.cpp:198] Convolution30 needs backward computation.
I0129 22:47:04.164463  7239 net.cpp:198] Eltwise13_ReLU27_0_split needs backward computation.
I0129 22:47:04.164466  7239 net.cpp:198] ReLU27 needs backward computation.
I0129 22:47:04.164469  7239 net.cpp:198] Eltwise13 needs backward computation.
I0129 22:47:04.164471  7239 net.cpp:198] Scale29 needs backward computation.
I0129 22:47:04.164474  7239 net.cpp:198] BatchNorm29 needs backward computation.
I0129 22:47:04.164476  7239 net.cpp:198] Convolution29 needs backward computation.
I0129 22:47:04.164479  7239 net.cpp:198] ReLU26 needs backward computation.
I0129 22:47:04.164481  7239 net.cpp:198] Scale28 needs backward computation.
I0129 22:47:04.164484  7239 net.cpp:198] BatchNorm28 needs backward computation.
I0129 22:47:04.164492  7239 net.cpp:198] Convolution28 needs backward computation.
I0129 22:47:04.164495  7239 net.cpp:198] Eltwise12_ReLU25_0_split needs backward computation.
I0129 22:47:04.164499  7239 net.cpp:198] ReLU25 needs backward computation.
I0129 22:47:04.164500  7239 net.cpp:198] Eltwise12 needs backward computation.
I0129 22:47:04.164505  7239 net.cpp:198] Scale27 needs backward computation.
I0129 22:47:04.164506  7239 net.cpp:198] BatchNorm27 needs backward computation.
I0129 22:47:04.164508  7239 net.cpp:198] Convolution27 needs backward computation.
I0129 22:47:04.164511  7239 net.cpp:198] ReLU24 needs backward computation.
I0129 22:47:04.164513  7239 net.cpp:198] Scale26 needs backward computation.
I0129 22:47:04.164515  7239 net.cpp:198] BatchNorm26 needs backward computation.
I0129 22:47:04.164517  7239 net.cpp:198] Convolution26 needs backward computation.
I0129 22:47:04.164520  7239 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I0129 22:47:04.164523  7239 net.cpp:198] ReLU23 needs backward computation.
I0129 22:47:04.164525  7239 net.cpp:198] Eltwise11 needs backward computation.
I0129 22:47:04.164528  7239 net.cpp:198] Scale25 needs backward computation.
I0129 22:47:04.164531  7239 net.cpp:198] BatchNorm25 needs backward computation.
I0129 22:47:04.164533  7239 net.cpp:198] Convolution25 needs backward computation.
I0129 22:47:04.164536  7239 net.cpp:198] ReLU22 needs backward computation.
I0129 22:47:04.164538  7239 net.cpp:198] Scale24 needs backward computation.
I0129 22:47:04.164541  7239 net.cpp:198] BatchNorm24 needs backward computation.
I0129 22:47:04.164543  7239 net.cpp:198] Convolution24 needs backward computation.
I0129 22:47:04.164546  7239 net.cpp:198] Scale23 needs backward computation.
I0129 22:47:04.164548  7239 net.cpp:198] BatchNorm23 needs backward computation.
I0129 22:47:04.164551  7239 net.cpp:198] Convolution23 needs backward computation.
I0129 22:47:04.164553  7239 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I0129 22:47:04.164557  7239 net.cpp:198] ReLU19 needs backward computation.
I0129 22:47:04.164559  7239 net.cpp:198] Eltwise9 needs backward computation.
I0129 22:47:04.164562  7239 net.cpp:198] Scale20 needs backward computation.
I0129 22:47:04.164566  7239 net.cpp:198] BatchNorm20 needs backward computation.
I0129 22:47:04.164567  7239 net.cpp:198] Convolution20 needs backward computation.
I0129 22:47:04.164569  7239 net.cpp:198] ReLU18 needs backward computation.
I0129 22:47:04.164572  7239 net.cpp:198] Scale19 needs backward computation.
I0129 22:47:04.164574  7239 net.cpp:198] BatchNorm19 needs backward computation.
I0129 22:47:04.164577  7239 net.cpp:198] Convolution19 needs backward computation.
I0129 22:47:04.164579  7239 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I0129 22:47:04.164582  7239 net.cpp:198] ReLU17 needs backward computation.
I0129 22:47:04.164584  7239 net.cpp:198] Eltwise8 needs backward computation.
I0129 22:47:04.164587  7239 net.cpp:198] Scale18 needs backward computation.
I0129 22:47:04.164589  7239 net.cpp:198] BatchNorm18 needs backward computation.
I0129 22:47:04.164592  7239 net.cpp:198] Convolution18 needs backward computation.
I0129 22:47:04.164594  7239 net.cpp:198] ReLU16 needs backward computation.
I0129 22:47:04.164597  7239 net.cpp:198] Scale17 needs backward computation.
I0129 22:47:04.164599  7239 net.cpp:198] BatchNorm17 needs backward computation.
I0129 22:47:04.164602  7239 net.cpp:198] Convolution17 needs backward computation.
I0129 22:47:04.164604  7239 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I0129 22:47:04.164608  7239 net.cpp:198] ReLU15 needs backward computation.
I0129 22:47:04.164609  7239 net.cpp:198] Eltwise7 needs backward computation.
I0129 22:47:04.164613  7239 net.cpp:198] Scale16 needs backward computation.
I0129 22:47:04.164614  7239 net.cpp:198] BatchNorm16 needs backward computation.
I0129 22:47:04.164616  7239 net.cpp:198] Convolution16 needs backward computation.
I0129 22:47:04.164619  7239 net.cpp:198] ReLU14 needs backward computation.
I0129 22:47:04.164625  7239 net.cpp:198] Scale15 needs backward computation.
I0129 22:47:04.164628  7239 net.cpp:198] BatchNorm15 needs backward computation.
I0129 22:47:04.164630  7239 net.cpp:198] Convolution15 needs backward computation.
I0129 22:47:04.164633  7239 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I0129 22:47:04.164635  7239 net.cpp:198] ReLU13 needs backward computation.
I0129 22:47:04.164638  7239 net.cpp:198] Eltwise6 needs backward computation.
I0129 22:47:04.164640  7239 net.cpp:198] Scale14 needs backward computation.
I0129 22:47:04.164643  7239 net.cpp:198] BatchNorm14 needs backward computation.
I0129 22:47:04.164645  7239 net.cpp:198] Convolution14 needs backward computation.
I0129 22:47:04.164647  7239 net.cpp:198] ReLU12 needs backward computation.
I0129 22:47:04.164651  7239 net.cpp:198] Scale13 needs backward computation.
I0129 22:47:04.164654  7239 net.cpp:198] BatchNorm13 needs backward computation.
I0129 22:47:04.164655  7239 net.cpp:198] Convolution13 needs backward computation.
I0129 22:47:04.164659  7239 net.cpp:198] Scale12 needs backward computation.
I0129 22:47:04.164660  7239 net.cpp:198] BatchNorm12 needs backward computation.
I0129 22:47:04.164662  7239 net.cpp:198] Convolution12 needs backward computation.
I0129 22:47:04.164665  7239 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I0129 22:47:04.164669  7239 net.cpp:198] ReLU11 needs backward computation.
I0129 22:47:04.164670  7239 net.cpp:198] Eltwise5 needs backward computation.
I0129 22:47:04.164674  7239 net.cpp:198] Scale11 needs backward computation.
I0129 22:47:04.164676  7239 net.cpp:198] BatchNorm11 needs backward computation.
I0129 22:47:04.164679  7239 net.cpp:198] Convolution11 needs backward computation.
I0129 22:47:04.164680  7239 net.cpp:198] ReLU10 needs backward computation.
I0129 22:47:04.164682  7239 net.cpp:198] Scale10 needs backward computation.
I0129 22:47:04.164685  7239 net.cpp:198] BatchNorm10 needs backward computation.
I0129 22:47:04.164687  7239 net.cpp:198] Convolution10 needs backward computation.
I0129 22:47:04.164690  7239 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I0129 22:47:04.164692  7239 net.cpp:198] ReLU9 needs backward computation.
I0129 22:47:04.164695  7239 net.cpp:198] Eltwise4 needs backward computation.
I0129 22:47:04.164698  7239 net.cpp:198] Scale9 needs backward computation.
I0129 22:47:04.164700  7239 net.cpp:198] BatchNorm9 needs backward computation.
I0129 22:47:04.164702  7239 net.cpp:198] Convolution9 needs backward computation.
I0129 22:47:04.164705  7239 net.cpp:198] ReLU8 needs backward computation.
I0129 22:47:04.164708  7239 net.cpp:198] Scale8 needs backward computation.
I0129 22:47:04.164710  7239 net.cpp:198] BatchNorm8 needs backward computation.
I0129 22:47:04.164712  7239 net.cpp:198] Convolution8 needs backward computation.
I0129 22:47:04.164716  7239 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I0129 22:47:04.164717  7239 net.cpp:198] ReLU7 needs backward computation.
I0129 22:47:04.164721  7239 net.cpp:198] Eltwise3 needs backward computation.
I0129 22:47:04.164723  7239 net.cpp:198] Scale7 needs backward computation.
I0129 22:47:04.164726  7239 net.cpp:198] BatchNorm7 needs backward computation.
I0129 22:47:04.164728  7239 net.cpp:198] Convolution7 needs backward computation.
I0129 22:47:04.164731  7239 net.cpp:198] ReLU6 needs backward computation.
I0129 22:47:04.164732  7239 net.cpp:198] Scale6 needs backward computation.
I0129 22:47:04.164736  7239 net.cpp:198] BatchNorm6 needs backward computation.
I0129 22:47:04.164737  7239 net.cpp:198] Convolution6 needs backward computation.
I0129 22:47:04.164741  7239 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I0129 22:47:04.164742  7239 net.cpp:198] ReLU5 needs backward computation.
I0129 22:47:04.164746  7239 net.cpp:198] Eltwise2 needs backward computation.
I0129 22:47:04.164748  7239 net.cpp:198] Scale5 needs backward computation.
I0129 22:47:04.164750  7239 net.cpp:198] BatchNorm5 needs backward computation.
I0129 22:47:04.164757  7239 net.cpp:198] Convolution5 needs backward computation.
I0129 22:47:04.164759  7239 net.cpp:198] ReLU4 needs backward computation.
I0129 22:47:04.164762  7239 net.cpp:198] Scale4 needs backward computation.
I0129 22:47:04.164763  7239 net.cpp:198] BatchNorm4 needs backward computation.
I0129 22:47:04.164767  7239 net.cpp:198] Convolution4 needs backward computation.
I0129 22:47:04.164769  7239 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I0129 22:47:04.164772  7239 net.cpp:198] ReLU3 needs backward computation.
I0129 22:47:04.164775  7239 net.cpp:198] Eltwise1 needs backward computation.
I0129 22:47:04.164778  7239 net.cpp:198] Scale3 needs backward computation.
I0129 22:47:04.164782  7239 net.cpp:198] BatchNorm3 needs backward computation.
I0129 22:47:04.164783  7239 net.cpp:198] Convolution3 needs backward computation.
I0129 22:47:04.164786  7239 net.cpp:198] ReLU2 needs backward computation.
I0129 22:47:04.164788  7239 net.cpp:198] Scale2 needs backward computation.
I0129 22:47:04.164791  7239 net.cpp:198] BatchNorm2 needs backward computation.
I0129 22:47:04.164793  7239 net.cpp:198] Convolution2 needs backward computation.
I0129 22:47:04.164796  7239 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I0129 22:47:04.164798  7239 net.cpp:198] ReLU1 needs backward computation.
I0129 22:47:04.164801  7239 net.cpp:198] Scale1 needs backward computation.
I0129 22:47:04.164803  7239 net.cpp:198] BatchNorm1 needs backward computation.
I0129 22:47:04.164805  7239 net.cpp:198] Convolution1 needs backward computation.
I0129 22:47:04.164808  7239 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0129 22:47:04.164811  7239 net.cpp:200] Data1 does not need backward computation.
I0129 22:47:04.164813  7239 net.cpp:242] This network produces output Accuracy1
I0129 22:47:04.164816  7239 net.cpp:242] This network produces output SoftmaxWithLoss1
I0129 22:47:04.164870  7239 net.cpp:255] Network initialization done.
I0129 22:47:04.165122  7239 solver.cpp:56] Solver scaffolding done.
I0129 22:47:04.172113  7239 caffe.cpp:248] Starting Optimization
I0129 22:47:05.154263  7265 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/bao/WRN-28.prototxt
I0129 22:47:05.154297  7265 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0129 22:47:05.257812  7267 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/bao/WRN-28.prototxt
I0129 22:47:05.257841  7267 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0129 22:47:05.369982  7266 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/bao/WRN-28.prototxt
I0129 22:47:05.370012  7266 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0129 22:47:06.698608  7265 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/bao/WRN-28.prototxt
I0129 22:47:06.698632  7265 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0129 22:47:06.698637  7265 solver.cpp:172] Creating test net (#0) specified by net file: examples/bao/WRN-28.prototxt
I0129 22:47:06.713639  7267 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/bao/WRN-28.prototxt
I0129 22:47:06.713659  7267 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0129 22:47:06.713663  7267 solver.cpp:172] Creating test net (#0) specified by net file: examples/bao/WRN-28.prototxt
I0129 22:47:06.735265  7266 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/bao/WRN-28.prototxt
I0129 22:47:06.735285  7266 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0129 22:47:06.735292  7266 solver.cpp:172] Creating test net (#0) specified by net file: examples/bao/WRN-28.prototxt
I0129 22:47:07.906199  7239 solver.cpp:272] Solving resnet_cifar10
I0129 22:47:07.906239  7239 solver.cpp:273] Learning Rate Policy: multistep
I0129 22:47:07.906620  7239 solver.cpp:330] Iteration 0, Testing net (#0)
I0129 22:47:24.169158  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:47:24.487660  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0129 22:47:24.487686  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3366 (* 1 = 87.3366 loss)
I0129 22:47:25.127684  7239 solver.cpp:218] Iteration 0 (-2.78606e-41 iter/s, 17.2045s/100 iters), loss = 3.08428
I0129 22:47:25.127727  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.08428 (* 1 = 3.08428 loss)
I0129 22:47:25.127737  7239 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0129 22:47:48.271855  7239 solver.cpp:218] Iteration 100 (4.32093 iter/s, 23.1432s/100 iters), loss = 2.1341
I0129 22:47:48.271942  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.1341 (* 1 = 2.1341 loss)
I0129 22:47:48.271950  7239 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0129 22:48:11.758039  7239 solver.cpp:218] Iteration 200 (4.25801 iter/s, 23.4852s/100 iters), loss = 1.97553
I0129 22:48:11.758065  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.97553 (* 1 = 1.97553 loss)
I0129 22:48:11.758072  7239 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0129 22:48:35.232875  7239 solver.cpp:218] Iteration 300 (4.26006 iter/s, 23.4739s/100 iters), loss = 1.85173
I0129 22:48:35.233610  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.85173 (* 1 = 1.85173 loss)
I0129 22:48:35.233618  7239 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0129 22:48:55.725037  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:48:58.750075  7239 solver.cpp:330] Iteration 400, Testing net (#0)
I0129 22:49:15.339068  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:49:15.672842  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1011
I0129 22:49:15.672863  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.44151 (* 1 = 3.44151 loss)
I0129 22:49:15.916893  7239 solver.cpp:218] Iteration 400 (2.45811 iter/s, 40.6817s/100 iters), loss = 1.75624
I0129 22:49:15.916915  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.75624 (* 1 = 1.75624 loss)
I0129 22:49:15.916930  7239 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0129 22:49:39.312263  7239 solver.cpp:218] Iteration 500 (4.27453 iter/s, 23.3944s/100 iters), loss = 1.61364
I0129 22:49:39.312290  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.61364 (* 1 = 1.61364 loss)
I0129 22:49:39.312297  7239 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0129 22:50:02.718005  7239 solver.cpp:218] Iteration 600 (4.27263 iter/s, 23.4048s/100 iters), loss = 1.60379
I0129 22:50:02.720643  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.60379 (* 1 = 1.60379 loss)
I0129 22:50:02.720656  7239 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0129 22:50:26.532786  7239 solver.cpp:218] Iteration 700 (4.19971 iter/s, 23.8112s/100 iters), loss = 1.53158
I0129 22:50:26.532812  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.53158 (* 1 = 1.53158 loss)
I0129 22:50:26.532819  7239 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0129 22:50:44.644383  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:50:49.807822  7239 solver.cpp:330] Iteration 800, Testing net (#0)
I0129 22:51:06.681702  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:51:07.017426  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1001
I0129 22:51:07.017453  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.31159 (* 1 = 3.31159 loss)
I0129 22:51:07.262511  7239 solver.cpp:218] Iteration 800 (2.45531 iter/s, 40.7281s/100 iters), loss = 1.14634
I0129 22:51:07.262532  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.14634 (* 1 = 1.14634 loss)
I0129 22:51:07.262545  7239 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0129 22:51:30.378075  7239 solver.cpp:218] Iteration 900 (4.32627 iter/s, 23.1146s/100 iters), loss = 1.3777
I0129 22:51:30.378159  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.3777 (* 1 = 1.3777 loss)
I0129 22:51:30.378168  7239 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0129 22:51:54.244607  7239 solver.cpp:218] Iteration 1000 (4.19015 iter/s, 23.8655s/100 iters), loss = 1.30322
I0129 22:51:54.244637  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.30322 (* 1 = 1.30322 loss)
I0129 22:51:54.244644  7239 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0129 22:52:17.620151  7239 solver.cpp:218] Iteration 1100 (4.27815 iter/s, 23.3746s/100 iters), loss = 1.50926
I0129 22:52:17.620223  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.50926 (* 1 = 1.50926 loss)
I0129 22:52:17.620232  7239 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0129 22:52:33.454150  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:52:40.941596  7239 solver.cpp:330] Iteration 1200, Testing net (#0)
I0129 22:52:57.795423  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:52:58.128950  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2056
I0129 22:52:58.128973  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.26031 (* 1 = 2.26031 loss)
I0129 22:52:58.370653  7239 solver.cpp:218] Iteration 1200 (2.45406 iter/s, 40.7488s/100 iters), loss = 1.07065
I0129 22:52:58.370676  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.07065 (* 1 = 1.07065 loss)
I0129 22:52:58.370685  7239 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0129 22:53:21.520525  7239 solver.cpp:218] Iteration 1300 (4.31986 iter/s, 23.1489s/100 iters), loss = 1.02469
I0129 22:53:21.520553  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.02469 (* 1 = 1.02469 loss)
I0129 22:53:21.520565  7239 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0129 22:53:44.922731  7239 solver.cpp:218] Iteration 1400 (4.27328 iter/s, 23.4012s/100 iters), loss = 1.06195
I0129 22:53:44.922803  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06195 (* 1 = 1.06195 loss)
I0129 22:53:44.922816  7239 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0129 22:54:08.444005  7239 solver.cpp:218] Iteration 1500 (4.25165 iter/s, 23.5203s/100 iters), loss = 1.09214
I0129 22:54:08.444032  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09214 (* 1 = 1.09214 loss)
I0129 22:54:08.444039  7239 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0129 22:54:22.167181  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:54:31.787639  7239 solver.cpp:330] Iteration 1600, Testing net (#0)
I0129 22:54:48.482205  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:54:48.814968  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1163
I0129 22:54:48.814990  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.25179 (* 1 = 2.25179 loss)
I0129 22:54:49.062322  7239 solver.cpp:218] Iteration 1600 (2.46204 iter/s, 40.6167s/100 iters), loss = 1.01281
I0129 22:54:49.062351  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01281 (* 1 = 1.01281 loss)
I0129 22:54:49.062361  7239 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0129 22:55:12.205991  7239 solver.cpp:218] Iteration 1700 (4.32102 iter/s, 23.1427s/100 iters), loss = 0.948479
I0129 22:55:12.206060  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.948479 (* 1 = 0.948479 loss)
I0129 22:55:12.206069  7239 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0129 22:55:35.958822  7239 solver.cpp:218] Iteration 1800 (4.21021 iter/s, 23.7518s/100 iters), loss = 0.717509
I0129 22:55:35.958847  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.717509 (* 1 = 0.717509 loss)
I0129 22:55:35.958854  7239 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0129 22:55:59.554397  7239 solver.cpp:218] Iteration 1900 (4.23826 iter/s, 23.5946s/100 iters), loss = 0.918322
I0129 22:55:59.554486  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.918322 (* 1 = 0.918322 loss)
I0129 22:55:59.554496  7239 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0129 22:56:11.098747  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:56:23.001667  7239 solver.cpp:330] Iteration 2000, Testing net (#0)
I0129 22:56:39.676779  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:56:40.011855  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1134
I0129 22:56:40.011881  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.31898 (* 1 = 2.31898 loss)
I0129 22:56:40.258779  7239 solver.cpp:218] Iteration 2000 (2.45684 iter/s, 40.7027s/100 iters), loss = 0.873264
I0129 22:56:40.258803  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.873264 (* 1 = 0.873264 loss)
I0129 22:56:40.258818  7239 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0129 22:57:03.631377  7239 solver.cpp:218] Iteration 2100 (4.27869 iter/s, 23.3716s/100 iters), loss = 0.651972
I0129 22:57:03.631404  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.651972 (* 1 = 0.651972 loss)
I0129 22:57:03.631412  7239 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0129 22:57:27.238072  7239 solver.cpp:218] Iteration 2200 (4.23626 iter/s, 23.6057s/100 iters), loss = 0.592892
I0129 22:57:27.238149  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.592892 (* 1 = 0.592892 loss)
I0129 22:57:27.238158  7239 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0129 22:57:50.756633  7239 solver.cpp:218] Iteration 2300 (4.25215 iter/s, 23.5175s/100 iters), loss = 1.27129
I0129 22:57:50.756657  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.27129 (* 1 = 1.27129 loss)
I0129 22:57:50.756664  7239 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0129 22:57:59.962509  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:58:14.083396  7239 solver.cpp:330] Iteration 2400, Testing net (#0)
I0129 22:58:30.875314  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 22:58:31.212075  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1021
I0129 22:58:31.212098  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.49893 (* 1 = 2.49893 loss)
I0129 22:58:31.458264  7239 solver.cpp:218] Iteration 2400 (2.457 iter/s, 40.7s/100 iters), loss = 0.490675
I0129 22:58:31.458292  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.490675 (* 1 = 0.490675 loss)
I0129 22:58:31.458303  7239 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0129 22:58:54.605736  7239 solver.cpp:218] Iteration 2500 (4.32031 iter/s, 23.1465s/100 iters), loss = 0.768844
I0129 22:58:54.605762  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.768844 (* 1 = 0.768844 loss)
I0129 22:58:54.605768  7239 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0129 22:59:18.103062  7239 solver.cpp:218] Iteration 2600 (4.25598 iter/s, 23.4964s/100 iters), loss = 0.70702
I0129 22:59:18.103132  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.70702 (* 1 = 0.70702 loss)
I0129 22:59:18.103139  7239 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0129 22:59:41.636170  7239 solver.cpp:218] Iteration 2700 (4.24952 iter/s, 23.5321s/100 iters), loss = 0.363372
I0129 22:59:41.636198  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363372 (* 1 = 0.363372 loss)
I0129 22:59:41.636204  7239 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0129 22:59:48.876590  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:00:05.323276  7239 solver.cpp:330] Iteration 2800, Testing net (#0)
I0129 23:00:21.945181  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:00:22.276064  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1018
I0129 23:00:22.276087  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.53279 (* 1 = 2.53279 loss)
I0129 23:00:22.524163  7239 solver.cpp:218] Iteration 2800 (2.44581 iter/s, 40.8863s/100 iters), loss = 0.601692
I0129 23:00:22.524199  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601692 (* 1 = 0.601692 loss)
I0129 23:00:22.524214  7239 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0129 23:00:45.918203  7239 solver.cpp:218] Iteration 2900 (4.27477 iter/s, 23.3931s/100 iters), loss = 0.62182
I0129 23:00:45.918233  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.62182 (* 1 = 0.62182 loss)
I0129 23:00:45.918243  7239 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0129 23:01:09.454285  7239 solver.cpp:218] Iteration 3000 (4.24897 iter/s, 23.5351s/100 iters), loss = 0.552554
I0129 23:01:09.454375  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.552554 (* 1 = 0.552554 loss)
I0129 23:01:09.454383  7239 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0129 23:01:33.118609  7239 solver.cpp:218] Iteration 3100 (4.22596 iter/s, 23.6633s/100 iters), loss = 0.277195
I0129 23:01:33.118638  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277195 (* 1 = 0.277195 loss)
I0129 23:01:33.118644  7239 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0129 23:01:38.058359  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:01:56.685322  7239 solver.cpp:330] Iteration 3200, Testing net (#0)
I0129 23:02:13.511917  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:02:13.842185  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0129 23:02:13.842207  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.47957 (* 1 = 2.47957 loss)
I0129 23:02:14.086774  7239 solver.cpp:218] Iteration 3200 (2.44102 iter/s, 40.9665s/100 iters), loss = 0.686794
I0129 23:02:14.086798  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.686794 (* 1 = 0.686794 loss)
I0129 23:02:14.086812  7239 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0129 23:02:37.291235  7239 solver.cpp:218] Iteration 3300 (4.3097 iter/s, 23.2035s/100 iters), loss = 0.476078
I0129 23:02:37.291308  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476078 (* 1 = 0.476078 loss)
I0129 23:02:37.291317  7239 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0129 23:03:00.697248  7239 solver.cpp:218] Iteration 3400 (4.27259 iter/s, 23.405s/100 iters), loss = 0.507805
I0129 23:03:00.697274  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.507805 (* 1 = 0.507805 loss)
I0129 23:03:00.697281  7239 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0129 23:03:24.399901  7239 solver.cpp:218] Iteration 3500 (4.21911 iter/s, 23.7017s/100 iters), loss = 0.626368
I0129 23:03:24.399962  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.626369 (* 1 = 0.626369 loss)
I0129 23:03:24.399971  7239 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0129 23:03:27.051416  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:03:47.881284  7239 solver.cpp:330] Iteration 3600, Testing net (#0)
I0129 23:04:04.527645  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:04:04.862448  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0129 23:04:04.862470  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.44795 (* 1 = 2.44795 loss)
I0129 23:04:05.109644  7239 solver.cpp:218] Iteration 3600 (2.45652 iter/s, 40.708s/100 iters), loss = 0.352135
I0129 23:04:05.109668  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352135 (* 1 = 0.352135 loss)
I0129 23:04:05.109679  7239 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0129 23:04:28.432065  7239 solver.cpp:218] Iteration 3700 (4.2879 iter/s, 23.3215s/100 iters), loss = 0.474373
I0129 23:04:28.432094  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474373 (* 1 = 0.474373 loss)
I0129 23:04:28.432101  7239 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0129 23:04:51.890071  7239 solver.cpp:218] Iteration 3800 (4.26311 iter/s, 23.457s/100 iters), loss = 0.397379
I0129 23:04:51.892623  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397379 (* 1 = 0.397379 loss)
I0129 23:04:51.892632  7239 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0129 23:05:15.526332  7239 solver.cpp:218] Iteration 3900 (4.23141 iter/s, 23.6328s/100 iters), loss = 0.617047
I0129 23:05:15.526363  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.617048 (* 1 = 0.617048 loss)
I0129 23:05:15.526373  7239 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0129 23:05:16.014418  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:05:39.300940  7239 solver.cpp:330] Iteration 4000, Testing net (#0)
I0129 23:05:55.577622  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:05:55.908020  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1204
I0129 23:05:55.908042  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.66205 (* 1 = 2.66205 loss)
I0129 23:05:56.151764  7239 solver.cpp:218] Iteration 4000 (2.46161 iter/s, 40.6238s/100 iters), loss = 0.262675
I0129 23:05:56.151788  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262675 (* 1 = 0.262675 loss)
I0129 23:05:56.151798  7239 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0129 23:06:19.363818  7239 solver.cpp:218] Iteration 4100 (4.30829 iter/s, 23.2111s/100 iters), loss = 0.332573
I0129 23:06:19.363886  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332574 (* 1 = 0.332574 loss)
I0129 23:06:19.363894  7239 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0129 23:06:42.810704  7239 solver.cpp:218] Iteration 4200 (4.26514 iter/s, 23.4459s/100 iters), loss = 0.34957
I0129 23:06:42.810741  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349571 (* 1 = 0.349571 loss)
I0129 23:06:42.810750  7239 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0129 23:07:04.530872  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:07:06.424540  7239 solver.cpp:218] Iteration 4300 (4.23498 iter/s, 23.6128s/100 iters), loss = 0.381859
I0129 23:07:06.424568  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38186 (* 1 = 0.38186 loss)
I0129 23:07:06.424576  7239 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0129 23:07:29.816866  7239 solver.cpp:330] Iteration 4400, Testing net (#0)
I0129 23:07:46.557961  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:07:46.892067  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0129 23:07:46.892088  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.50247 (* 1 = 2.50247 loss)
I0129 23:07:47.137622  7239 solver.cpp:218] Iteration 4400 (2.45631 iter/s, 40.7114s/100 iters), loss = 0.351884
I0129 23:07:47.137645  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351884 (* 1 = 0.351884 loss)
I0129 23:07:47.137660  7239 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0129 23:08:10.299950  7239 solver.cpp:218] Iteration 4500 (4.31753 iter/s, 23.1614s/100 iters), loss = 0.482982
I0129 23:08:10.299978  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.482982 (* 1 = 0.482982 loss)
I0129 23:08:10.299984  7239 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0129 23:08:33.642341  7239 solver.cpp:218] Iteration 4600 (4.28423 iter/s, 23.3414s/100 iters), loss = 0.614501
I0129 23:08:33.642998  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.614501 (* 1 = 0.614501 loss)
I0129 23:08:33.643007  7239 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0129 23:08:53.457290  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:08:57.404227  7239 solver.cpp:218] Iteration 4700 (4.20871 iter/s, 23.7603s/100 iters), loss = 0.155842
I0129 23:08:57.404263  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155842 (* 1 = 0.155842 loss)
I0129 23:08:57.404271  7239 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0129 23:09:20.772732  7239 solver.cpp:330] Iteration 4800, Testing net (#0)
I0129 23:09:37.538089  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:09:37.880846  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0129 23:09:37.880868  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.46972 (* 1 = 2.46972 loss)
I0129 23:09:38.124346  7239 solver.cpp:218] Iteration 4800 (2.45589 iter/s, 40.7185s/100 iters), loss = 0.279966
I0129 23:09:38.124370  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279966 (* 1 = 0.279966 loss)
I0129 23:09:38.124385  7239 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0129 23:10:01.445370  7239 solver.cpp:218] Iteration 4900 (4.28815 iter/s, 23.3201s/100 iters), loss = 0.340884
I0129 23:10:01.446434  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340884 (* 1 = 0.340884 loss)
I0129 23:10:01.446442  7239 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0129 23:10:24.839206  7239 solver.cpp:218] Iteration 5000 (4.275 iter/s, 23.3918s/100 iters), loss = 0.319815
I0129 23:10:24.839232  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319815 (* 1 = 0.319815 loss)
I0129 23:10:24.839239  7239 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0129 23:10:42.297086  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:10:48.413434  7239 solver.cpp:218] Iteration 5100 (4.2421 iter/s, 23.5732s/100 iters), loss = 0.213927
I0129 23:10:48.413460  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213928 (* 1 = 0.213928 loss)
I0129 23:10:48.413466  7239 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0129 23:11:11.536010  7239 solver.cpp:330] Iteration 5200, Testing net (#0)
I0129 23:11:28.236893  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:11:28.570204  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0129 23:11:28.570227  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.54452 (* 1 = 2.54452 loss)
I0129 23:11:28.817366  7239 solver.cpp:218] Iteration 5200 (2.47511 iter/s, 40.4023s/100 iters), loss = 0.614944
I0129 23:11:28.817389  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.614944 (* 1 = 0.614944 loss)
I0129 23:11:28.817404  7239 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0129 23:11:52.238256  7239 solver.cpp:218] Iteration 5300 (4.26987 iter/s, 23.4199s/100 iters), loss = 0.265155
I0129 23:11:52.238283  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265155 (* 1 = 0.265155 loss)
I0129 23:11:52.238291  7239 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0129 23:12:15.860700  7239 solver.cpp:218] Iteration 5400 (4.23344 iter/s, 23.6215s/100 iters), loss = 0.405102
I0129 23:12:15.860770  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405102 (* 1 = 0.405102 loss)
I0129 23:12:15.860780  7239 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0129 23:12:30.925820  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:12:39.299417  7239 solver.cpp:218] Iteration 5500 (4.26663 iter/s, 23.4377s/100 iters), loss = 0.294689
I0129 23:12:39.299446  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294689 (* 1 = 0.294689 loss)
I0129 23:12:39.299455  7239 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0129 23:13:02.585440  7239 solver.cpp:330] Iteration 5600, Testing net (#0)
I0129 23:13:19.372588  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:13:19.706511  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0129 23:13:19.706534  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.6204 (* 1 = 2.6204 loss)
I0129 23:13:19.952533  7239 solver.cpp:218] Iteration 5600 (2.45994 iter/s, 40.6515s/100 iters), loss = 0.335753
I0129 23:13:19.952556  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335753 (* 1 = 0.335753 loss)
I0129 23:13:19.952571  7239 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0129 23:13:43.258950  7239 solver.cpp:218] Iteration 5700 (4.29084 iter/s, 23.3054s/100 iters), loss = 0.324002
I0129 23:13:43.259024  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324003 (* 1 = 0.324003 loss)
I0129 23:13:43.259033  7239 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0129 23:14:06.771685  7239 solver.cpp:218] Iteration 5800 (4.2532 iter/s, 23.5117s/100 iters), loss = 0.152526
I0129 23:14:06.771714  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152527 (* 1 = 0.152527 loss)
I0129 23:14:06.771721  7239 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0129 23:14:20.129169  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:14:30.876401  7239 solver.cpp:218] Iteration 5900 (4.14874 iter/s, 24.1037s/100 iters), loss = 0.269089
I0129 23:14:30.876430  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269089 (* 1 = 0.269089 loss)
I0129 23:14:30.876436  7239 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0129 23:14:54.380801  7239 solver.cpp:330] Iteration 6000, Testing net (#0)
I0129 23:15:11.086278  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:15:11.418200  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1006
I0129 23:15:11.418222  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.59409 (* 1 = 2.59409 loss)
I0129 23:15:11.666344  7239 solver.cpp:218] Iteration 6000 (2.45169 iter/s, 40.7883s/100 iters), loss = 0.669322
I0129 23:15:11.666373  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.669322 (* 1 = 0.669322 loss)
I0129 23:15:11.666381  7239 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0129 23:15:34.731215  7239 solver.cpp:218] Iteration 6100 (4.33578 iter/s, 23.0639s/100 iters), loss = 0.320483
I0129 23:15:34.731289  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320484 (* 1 = 0.320484 loss)
I0129 23:15:34.731302  7239 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0129 23:15:58.408960  7239 solver.cpp:218] Iteration 6200 (4.22356 iter/s, 23.6767s/100 iters), loss = 0.370947
I0129 23:15:58.408987  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370948 (* 1 = 0.370948 loss)
I0129 23:15:58.408993  7239 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0129 23:16:09.200584  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:16:22.220294  7239 solver.cpp:218] Iteration 6300 (4.19985 iter/s, 23.8103s/100 iters), loss = 0.308621
I0129 23:16:22.220322  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308621 (* 1 = 0.308621 loss)
I0129 23:16:22.220329  7239 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0129 23:16:45.507217  7239 solver.cpp:330] Iteration 6400, Testing net (#0)
I0129 23:17:02.378298  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:17:02.721930  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1005
I0129 23:17:02.721952  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.79351 (* 1 = 2.79351 loss)
I0129 23:17:02.963654  7239 solver.cpp:218] Iteration 6400 (2.45449 iter/s, 40.7417s/100 iters), loss = 0.378595
I0129 23:17:02.963676  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378596 (* 1 = 0.378596 loss)
I0129 23:17:02.963691  7239 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0129 23:17:26.285415  7239 solver.cpp:218] Iteration 6500 (4.28802 iter/s, 23.3208s/100 iters), loss = 0.485021
I0129 23:17:26.286851  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.485021 (* 1 = 0.485021 loss)
I0129 23:17:26.286860  7239 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0129 23:17:50.151724  7239 solver.cpp:218] Iteration 6600 (4.19043 iter/s, 23.8639s/100 iters), loss = 0.325018
I0129 23:17:50.151751  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325018 (* 1 = 0.325018 loss)
I0129 23:17:50.151757  7239 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0129 23:17:58.662124  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:18:13.929163  7239 solver.cpp:218] Iteration 6700 (4.20584 iter/s, 23.7764s/100 iters), loss = 0.198411
I0129 23:18:13.929189  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198411 (* 1 = 0.198411 loss)
I0129 23:18:13.929198  7239 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0129 23:18:37.548593  7239 solver.cpp:330] Iteration 6800, Testing net (#0)
I0129 23:18:54.305057  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:18:54.639988  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1036
I0129 23:18:54.640010  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.6977 (* 1 = 2.6977 loss)
I0129 23:18:54.887194  7239 solver.cpp:218] Iteration 6800 (2.44162 iter/s, 40.9564s/100 iters), loss = 0.26853
I0129 23:18:54.887218  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26853 (* 1 = 0.26853 loss)
I0129 23:18:54.887226  7239 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0129 23:19:18.164880  7239 solver.cpp:218] Iteration 6900 (4.29614 iter/s, 23.2767s/100 iters), loss = 0.833373
I0129 23:19:18.164953  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.833373 (* 1 = 0.833373 loss)
I0129 23:19:18.164961  7239 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0129 23:19:42.030874  7239 solver.cpp:218] Iteration 7000 (4.19024 iter/s, 23.865s/100 iters), loss = 0.346256
I0129 23:19:42.030901  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346256 (* 1 = 0.346256 loss)
I0129 23:19:42.030911  7239 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0129 23:19:48.351411  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:20:05.416945  7239 solver.cpp:218] Iteration 7100 (4.27623 iter/s, 23.3851s/100 iters), loss = 0.373492
I0129 23:20:05.416973  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373493 (* 1 = 0.373493 loss)
I0129 23:20:05.416980  7239 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0129 23:20:28.844475  7239 solver.cpp:330] Iteration 7200, Testing net (#0)
I0129 23:20:45.551139  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:20:45.888901  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.152
I0129 23:20:45.888923  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.469 (* 1 = 2.469 loss)
I0129 23:20:46.139509  7239 solver.cpp:218] Iteration 7200 (2.45574 iter/s, 40.7209s/100 iters), loss = 0.373896
I0129 23:20:46.139538  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373896 (* 1 = 0.373896 loss)
I0129 23:20:46.139549  7239 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0129 23:21:09.261106  7239 solver.cpp:218] Iteration 7300 (4.32514 iter/s, 23.1206s/100 iters), loss = 0.340683
I0129 23:21:09.263801  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340683 (* 1 = 0.340683 loss)
I0129 23:21:09.263811  7239 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0129 23:21:32.651453  7239 solver.cpp:218] Iteration 7400 (4.27593 iter/s, 23.3867s/100 iters), loss = 0.262807
I0129 23:21:32.651479  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262807 (* 1 = 0.262807 loss)
I0129 23:21:32.651489  7239 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0129 23:21:36.634129  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:21:56.359163  7239 solver.cpp:218] Iteration 7500 (4.21821 iter/s, 23.7067s/100 iters), loss = 0.168889
I0129 23:21:56.359233  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168889 (* 1 = 0.168889 loss)
I0129 23:21:56.359243  7239 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0129 23:22:19.871314  7239 solver.cpp:330] Iteration 7600, Testing net (#0)
I0129 23:22:36.461239  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:22:36.792781  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2881
I0129 23:22:36.792804  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.04817 (* 1 = 2.04817 loss)
I0129 23:22:37.036659  7239 solver.cpp:218] Iteration 7600 (2.45846 iter/s, 40.6758s/100 iters), loss = 0.298222
I0129 23:22:37.036686  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298222 (* 1 = 0.298222 loss)
I0129 23:22:37.036695  7239 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0129 23:23:00.203846  7239 solver.cpp:218] Iteration 7700 (4.31663 iter/s, 23.1662s/100 iters), loss = 0.50266
I0129 23:23:00.203874  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.502661 (* 1 = 0.502661 loss)
I0129 23:23:00.203881  7239 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0129 23:23:23.740409  7239 solver.cpp:218] Iteration 7800 (4.24889 iter/s, 23.5356s/100 iters), loss = 0.160638
I0129 23:23:23.740499  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160639 (* 1 = 0.160639 loss)
I0129 23:23:23.740510  7239 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0129 23:23:25.628396  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:23:47.208096  7239 solver.cpp:218] Iteration 7900 (4.26137 iter/s, 23.4667s/100 iters), loss = 0.328128
I0129 23:23:47.208122  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328128 (* 1 = 0.328128 loss)
I0129 23:23:47.208132  7239 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0129 23:24:10.713649  7239 solver.cpp:330] Iteration 8000, Testing net (#0)
I0129 23:24:27.379112  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:24:27.710614  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3427
I0129 23:24:27.710636  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.99073 (* 1 = 1.99073 loss)
I0129 23:24:27.951732  7239 solver.cpp:218] Iteration 8000 (2.45447 iter/s, 40.742s/100 iters), loss = 0.295893
I0129 23:24:27.951761  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295893 (* 1 = 0.295893 loss)
I0129 23:24:27.951768  7239 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0129 23:24:51.325996  7239 solver.cpp:218] Iteration 8100 (4.27839 iter/s, 23.3733s/100 iters), loss = 0.328693
I0129 23:24:51.327555  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328694 (* 1 = 0.328694 loss)
I0129 23:24:51.327564  7239 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0129 23:25:14.657479  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:25:14.881994  7239 solver.cpp:218] Iteration 8200 (4.24566 iter/s, 23.5535s/100 iters), loss = 0.175226
I0129 23:25:14.882019  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175226 (* 1 = 0.175226 loss)
I0129 23:25:14.882026  7239 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0129 23:25:38.441617  7239 solver.cpp:218] Iteration 8300 (4.24473 iter/s, 23.5586s/100 iters), loss = 0.324746
I0129 23:25:38.443918  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324746 (* 1 = 0.324746 loss)
I0129 23:25:38.443928  7239 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0129 23:26:01.886004  7239 solver.cpp:330] Iteration 8400, Testing net (#0)
I0129 23:26:18.745731  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:26:19.076025  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5082
I0129 23:26:19.076050  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.51156 (* 1 = 1.51156 loss)
I0129 23:26:19.318434  7239 solver.cpp:218] Iteration 8400 (2.44661 iter/s, 40.8729s/100 iters), loss = 0.355515
I0129 23:26:19.318457  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355515 (* 1 = 0.355515 loss)
I0129 23:26:19.318471  7239 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0129 23:26:42.552072  7239 solver.cpp:218] Iteration 8500 (4.30428 iter/s, 23.2327s/100 iters), loss = 0.436094
I0129 23:26:42.552105  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436094 (* 1 = 0.436094 loss)
I0129 23:26:42.552115  7239 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0129 23:27:03.582180  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:27:06.221979  7239 solver.cpp:218] Iteration 8600 (4.22495 iter/s, 23.6689s/100 iters), loss = 0.37841
I0129 23:27:06.222007  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378411 (* 1 = 0.378411 loss)
I0129 23:27:06.222015  7239 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0129 23:27:29.900938  7239 solver.cpp:218] Iteration 8700 (4.22333 iter/s, 23.678s/100 iters), loss = 0.291199
I0129 23:27:29.900969  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2912 (* 1 = 0.2912 loss)
I0129 23:27:29.900979  7239 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0129 23:27:53.120990  7239 solver.cpp:330] Iteration 8800, Testing net (#0)
I0129 23:28:10.038650  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:28:10.378170  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5464
I0129 23:28:10.378197  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.37915 (* 1 = 1.37915 loss)
I0129 23:28:10.622848  7239 solver.cpp:218] Iteration 8800 (2.45578 iter/s, 40.7202s/100 iters), loss = 0.112186
I0129 23:28:10.622871  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112186 (* 1 = 0.112186 loss)
I0129 23:28:10.622886  7239 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0129 23:28:33.885423  7239 solver.cpp:218] Iteration 8900 (4.29893 iter/s, 23.2616s/100 iters), loss = 0.292786
I0129 23:28:33.885494  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292786 (* 1 = 0.292786 loss)
I0129 23:28:33.885504  7239 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0129 23:28:52.814096  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:28:57.505697  7239 solver.cpp:218] Iteration 9000 (4.23384 iter/s, 23.6192s/100 iters), loss = 0.227626
I0129 23:28:57.505730  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227626 (* 1 = 0.227626 loss)
I0129 23:28:57.505741  7239 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0129 23:29:21.324154  7239 solver.cpp:218] Iteration 9100 (4.1986 iter/s, 23.8175s/100 iters), loss = 0.22343
I0129 23:29:21.325242  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22343 (* 1 = 0.22343 loss)
I0129 23:29:21.325254  7239 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0129 23:29:44.497921  7239 solver.cpp:330] Iteration 9200, Testing net (#0)
I0129 23:30:01.401376  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:30:01.742278  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7736
I0129 23:30:01.742301  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.695314 (* 1 = 0.695314 loss)
I0129 23:30:01.988409  7239 solver.cpp:218] Iteration 9200 (2.45933 iter/s, 40.6615s/100 iters), loss = 0.296905
I0129 23:30:01.988432  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296905 (* 1 = 0.296905 loss)
I0129 23:30:01.988446  7239 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0129 23:30:25.258224  7239 solver.cpp:218] Iteration 9300 (4.29759 iter/s, 23.2689s/100 iters), loss = 0.467386
I0129 23:30:25.258251  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467387 (* 1 = 0.467387 loss)
I0129 23:30:25.258258  7239 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0129 23:30:41.823475  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:30:48.771415  7239 solver.cpp:218] Iteration 9400 (4.25311 iter/s, 23.5122s/100 iters), loss = 0.125573
I0129 23:30:48.771441  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125573 (* 1 = 0.125573 loss)
I0129 23:30:48.771448  7239 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0129 23:31:12.604418  7239 solver.cpp:218] Iteration 9500 (4.19604 iter/s, 23.832s/100 iters), loss = 0.14893
I0129 23:31:12.607043  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14893 (* 1 = 0.14893 loss)
I0129 23:31:12.607051  7239 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0129 23:31:35.899613  7239 solver.cpp:330] Iteration 9600, Testing net (#0)
I0129 23:31:52.504592  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:31:52.838655  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7255
I0129 23:31:52.838678  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.79654 (* 1 = 0.79654 loss)
I0129 23:31:53.081698  7239 solver.cpp:218] Iteration 9600 (2.47078 iter/s, 40.473s/100 iters), loss = 0.121813
I0129 23:31:53.081722  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121814 (* 1 = 0.121814 loss)
I0129 23:31:53.081732  7239 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0129 23:32:16.367530  7239 solver.cpp:218] Iteration 9700 (4.29464 iter/s, 23.2849s/100 iters), loss = 0.23824
I0129 23:32:16.367558  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23824 (* 1 = 0.23824 loss)
I0129 23:32:16.367565  7239 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0129 23:32:30.773932  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:32:39.811530  7239 solver.cpp:218] Iteration 9800 (4.26566 iter/s, 23.443s/100 iters), loss = 0.229815
I0129 23:32:39.811565  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229816 (* 1 = 0.229816 loss)
I0129 23:32:39.811575  7239 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0129 23:33:03.341717  7239 solver.cpp:218] Iteration 9900 (4.25004 iter/s, 23.5292s/100 iters), loss = 0.174739
I0129 23:33:03.343250  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17474 (* 1 = 0.17474 loss)
I0129 23:33:03.343258  7239 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0129 23:33:26.826598  7239 solver.cpp:330] Iteration 10000, Testing net (#0)
I0129 23:33:43.482765  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:33:43.811902  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7682
I0129 23:33:43.811925  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.683072 (* 1 = 0.683072 loss)
I0129 23:33:44.057953  7239 solver.cpp:218] Iteration 10000 (2.45621 iter/s, 40.7131s/100 iters), loss = 0.280997
I0129 23:33:44.057976  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280998 (* 1 = 0.280998 loss)
I0129 23:33:44.057994  7239 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0129 23:34:07.317643  7239 solver.cpp:218] Iteration 10100 (4.29946 iter/s, 23.2587s/100 iters), loss = 0.202725
I0129 23:34:07.317672  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202725 (* 1 = 0.202725 loss)
I0129 23:34:07.317678  7239 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0129 23:34:19.557039  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:34:31.055047  7239 solver.cpp:218] Iteration 10200 (4.21294 iter/s, 23.7364s/100 iters), loss = 0.297837
I0129 23:34:31.055073  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297837 (* 1 = 0.297837 loss)
I0129 23:34:31.055080  7239 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0129 23:34:54.647156  7239 solver.cpp:218] Iteration 10300 (4.23888 iter/s, 23.5911s/100 iters), loss = 0.479803
I0129 23:34:54.648128  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479804 (* 1 = 0.479804 loss)
I0129 23:34:54.648138  7239 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0129 23:35:18.023411  7239 solver.cpp:330] Iteration 10400, Testing net (#0)
I0129 23:35:34.907969  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:35:35.246834  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7042
I0129 23:35:35.246856  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.986792 (* 1 = 0.986792 loss)
I0129 23:35:35.496379  7239 solver.cpp:218] Iteration 10400 (2.44818 iter/s, 40.8466s/100 iters), loss = 0.36942
I0129 23:35:35.496402  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36942 (* 1 = 0.36942 loss)
I0129 23:35:35.496417  7239 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0129 23:35:58.741081  7239 solver.cpp:218] Iteration 10500 (4.30223 iter/s, 23.2437s/100 iters), loss = 0.15212
I0129 23:35:58.741107  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152121 (* 1 = 0.152121 loss)
I0129 23:35:58.741114  7239 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0129 23:36:08.454563  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:36:22.086632  7239 solver.cpp:218] Iteration 10600 (4.28365 iter/s, 23.3446s/100 iters), loss = 0.457588
I0129 23:36:22.086660  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457588 (* 1 = 0.457588 loss)
I0129 23:36:22.086668  7239 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0129 23:36:46.029614  7239 solver.cpp:218] Iteration 10700 (4.17676 iter/s, 23.942s/100 iters), loss = 0.130396
I0129 23:36:46.029702  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130397 (* 1 = 0.130397 loss)
I0129 23:36:46.029711  7239 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0129 23:37:09.572270  7239 solver.cpp:330] Iteration 10800, Testing net (#0)
I0129 23:37:26.202015  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:37:26.538846  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7936
I0129 23:37:26.538869  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.605582 (* 1 = 0.605582 loss)
I0129 23:37:26.782071  7239 solver.cpp:218] Iteration 10800 (2.45394 iter/s, 40.7507s/100 iters), loss = 0.354894
I0129 23:37:26.782094  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354895 (* 1 = 0.354895 loss)
I0129 23:37:26.782109  7239 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0129 23:37:50.088049  7239 solver.cpp:218] Iteration 10900 (4.29092 iter/s, 23.305s/100 iters), loss = 0.352339
I0129 23:37:50.088075  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35234 (* 1 = 0.35234 loss)
I0129 23:37:50.088083  7239 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0129 23:37:57.876919  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:38:13.765775  7239 solver.cpp:218] Iteration 11000 (4.22356 iter/s, 23.6767s/100 iters), loss = 0.339734
I0129 23:38:13.765801  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339735 (* 1 = 0.339735 loss)
I0129 23:38:13.765810  7239 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0129 23:38:37.326974  7239 solver.cpp:218] Iteration 11100 (4.24444 iter/s, 23.5602s/100 iters), loss = 0.16661
I0129 23:38:37.331192  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166611 (* 1 = 0.166611 loss)
I0129 23:38:37.331202  7239 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0129 23:39:00.992828  7239 solver.cpp:330] Iteration 11200, Testing net (#0)
I0129 23:39:17.538400  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:39:17.877199  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.749
I0129 23:39:17.877224  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.757253 (* 1 = 0.757253 loss)
I0129 23:39:18.127578  7239 solver.cpp:218] Iteration 11200 (2.4513 iter/s, 40.7947s/100 iters), loss = 0.25336
I0129 23:39:18.127602  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25336 (* 1 = 0.25336 loss)
I0129 23:39:18.127616  7239 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0129 23:39:41.212167  7239 solver.cpp:218] Iteration 11300 (4.33208 iter/s, 23.0836s/100 iters), loss = 0.442653
I0129 23:39:41.212198  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442654 (* 1 = 0.442654 loss)
I0129 23:39:41.212204  7239 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0129 23:39:46.951967  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:40:04.918489  7239 solver.cpp:218] Iteration 11400 (4.21846 iter/s, 23.7053s/100 iters), loss = 0.161934
I0129 23:40:04.918560  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161934 (* 1 = 0.161934 loss)
I0129 23:40:04.918568  7239 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0129 23:40:28.725738  7239 solver.cpp:218] Iteration 11500 (4.20058 iter/s, 23.8062s/100 iters), loss = 0.0521434
I0129 23:40:28.725769  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0521441 (* 1 = 0.0521441 loss)
I0129 23:40:28.725777  7239 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0129 23:40:51.981889  7239 solver.cpp:330] Iteration 11600, Testing net (#0)
I0129 23:41:08.691716  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:41:09.031769  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8078
I0129 23:41:09.031795  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.57238 (* 1 = 0.57238 loss)
I0129 23:41:09.274951  7239 solver.cpp:218] Iteration 11600 (2.46624 iter/s, 40.5476s/100 iters), loss = 0.310122
I0129 23:41:09.274974  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310122 (* 1 = 0.310122 loss)
I0129 23:41:09.274981  7239 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0129 23:41:32.552536  7239 solver.cpp:218] Iteration 11700 (4.29616 iter/s, 23.2766s/100 iters), loss = 0.414552
I0129 23:41:32.552616  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414552 (* 1 = 0.414552 loss)
I0129 23:41:32.552625  7239 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0129 23:41:35.827385  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:41:56.105501  7239 solver.cpp:218] Iteration 11800 (4.24594 iter/s, 23.5519s/100 iters), loss = 0.488857
I0129 23:41:56.105531  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488857 (* 1 = 0.488857 loss)
I0129 23:41:56.105538  7239 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0129 23:42:19.869624  7239 solver.cpp:218] Iteration 11900 (4.2082 iter/s, 23.7631s/100 iters), loss = 0.297989
I0129 23:42:19.871464  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29799 (* 1 = 0.29799 loss)
I0129 23:42:19.871474  7239 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0129 23:42:43.249289  7239 solver.cpp:447] Snapshotting to binary proto file examples/bao/WRN-28_iter_12000.caffemodel
I0129 23:42:43.747035  7239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/bao/WRN-28_iter_12000.solverstate
I0129 23:42:43.944056  7239 solver.cpp:330] Iteration 12000, Testing net (#0)
I0129 23:43:00.521266  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:43:00.857626  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7163
I0129 23:43:00.857650  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.903825 (* 1 = 0.903825 loss)
I0129 23:43:01.099690  7239 solver.cpp:218] Iteration 12000 (2.42562 iter/s, 41.2266s/100 iters), loss = 0.0901688
I0129 23:43:01.099712  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0901695 (* 1 = 0.0901695 loss)
I0129 23:43:01.099728  7239 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0129 23:43:24.244743  7239 solver.cpp:218] Iteration 12100 (4.32076 iter/s, 23.1441s/100 iters), loss = 0.0914818
I0129 23:43:24.244771  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0914825 (* 1 = 0.0914825 loss)
I0129 23:43:24.244781  7239 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0129 23:43:25.425377  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:43:47.876756  7239 solver.cpp:218] Iteration 12200 (4.23172 iter/s, 23.631s/100 iters), loss = 0.181724
I0129 23:43:47.877892  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181725 (* 1 = 0.181725 loss)
I0129 23:43:47.877900  7239 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0129 23:44:11.562243  7239 solver.cpp:218] Iteration 12300 (4.22237 iter/s, 23.6834s/100 iters), loss = 0.22045
I0129 23:44:11.562269  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220451 (* 1 = 0.220451 loss)
I0129 23:44:11.562281  7239 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0129 23:44:34.874863  7239 solver.cpp:330] Iteration 12400, Testing net (#0)
I0129 23:44:51.566889  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:44:51.909535  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6447
I0129 23:44:51.909557  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15186 (* 1 = 1.15186 loss)
I0129 23:44:52.157189  7239 solver.cpp:218] Iteration 12400 (2.46346 iter/s, 40.5933s/100 iters), loss = 0.453824
I0129 23:44:52.157213  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453825 (* 1 = 0.453825 loss)
I0129 23:44:52.157228  7239 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0129 23:45:14.294929  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:45:15.209033  7239 solver.cpp:218] Iteration 12500 (4.33823 iter/s, 23.0509s/100 iters), loss = 0.0695813
I0129 23:45:15.209060  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.069582 (* 1 = 0.069582 loss)
I0129 23:45:15.209069  7239 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0129 23:45:38.839026  7239 solver.cpp:218] Iteration 12600 (4.23209 iter/s, 23.629s/100 iters), loss = 0.138731
I0129 23:45:38.839053  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138732 (* 1 = 0.138732 loss)
I0129 23:45:38.839061  7239 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0129 23:46:02.448695  7239 solver.cpp:218] Iteration 12700 (4.236 iter/s, 23.6072s/100 iters), loss = 0.46272
I0129 23:46:02.449451  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.462721 (* 1 = 0.462721 loss)
I0129 23:46:02.449460  7239 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0129 23:46:25.944365  7239 solver.cpp:330] Iteration 12800, Testing net (#0)
I0129 23:46:42.691928  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:46:43.027545  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7709
I0129 23:46:43.027570  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.735454 (* 1 = 0.735454 loss)
I0129 23:46:43.273373  7239 solver.cpp:218] Iteration 12800 (2.44979 iter/s, 40.8198s/100 iters), loss = 0.345496
I0129 23:46:43.273402  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345496 (* 1 = 0.345496 loss)
I0129 23:46:43.273409  7239 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0129 23:47:03.316349  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:47:06.604293  7239 solver.cpp:218] Iteration 12900 (4.28658 iter/s, 23.3286s/100 iters), loss = 0.309484
I0129 23:47:06.604323  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309485 (* 1 = 0.309485 loss)
I0129 23:47:06.604331  7239 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0129 23:47:30.018604  7239 solver.cpp:218] Iteration 13000 (4.2713 iter/s, 23.4121s/100 iters), loss = 0.147879
I0129 23:47:30.018676  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147879 (* 1 = 0.147879 loss)
I0129 23:47:30.018685  7239 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0129 23:47:53.608556  7239 solver.cpp:218] Iteration 13100 (4.2395 iter/s, 23.5877s/100 iters), loss = 0.54337
I0129 23:47:53.608583  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.543371 (* 1 = 0.543371 loss)
I0129 23:47:53.608592  7239 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0129 23:48:17.079571  7239 solver.cpp:330] Iteration 13200, Testing net (#0)
I0129 23:48:33.689302  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:48:34.036020  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7848
I0129 23:48:34.036046  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.639497 (* 1 = 0.639497 loss)
I0129 23:48:34.278213  7239 solver.cpp:218] Iteration 13200 (2.45906 iter/s, 40.666s/100 iters), loss = 0.247504
I0129 23:48:34.278235  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247505 (* 1 = 0.247505 loss)
I0129 23:48:34.278252  7239 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0129 23:48:52.180658  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:48:57.465415  7239 solver.cpp:218] Iteration 13300 (4.31311 iter/s, 23.1851s/100 iters), loss = 0.103253
I0129 23:48:57.465445  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103254 (* 1 = 0.103254 loss)
I0129 23:48:57.465452  7239 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0129 23:49:20.985533  7239 solver.cpp:218] Iteration 13400 (4.25205 iter/s, 23.5181s/100 iters), loss = 0.114048
I0129 23:49:20.985560  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114049 (* 1 = 0.114049 loss)
I0129 23:49:20.985568  7239 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0129 23:49:44.502372  7239 solver.cpp:218] Iteration 13500 (4.25264 iter/s, 23.5148s/100 iters), loss = 0.188251
I0129 23:49:44.502440  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188252 (* 1 = 0.188252 loss)
I0129 23:49:44.502449  7239 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0129 23:50:08.011935  7239 solver.cpp:330] Iteration 13600, Testing net (#0)
I0129 23:50:24.699184  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:50:25.033351  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8365
I0129 23:50:25.033375  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.490922 (* 1 = 0.490922 loss)
I0129 23:50:25.276684  7239 solver.cpp:218] Iteration 13600 (2.45273 iter/s, 40.7709s/100 iters), loss = 0.25101
I0129 23:50:25.276707  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25101 (* 1 = 0.25101 loss)
I0129 23:50:25.276722  7239 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0129 23:50:40.761458  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:50:48.353850  7239 solver.cpp:218] Iteration 13700 (4.33364 iter/s, 23.0753s/100 iters), loss = 0.275828
I0129 23:50:48.353879  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275829 (* 1 = 0.275829 loss)
I0129 23:50:48.353888  7239 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0129 23:51:12.061332  7239 solver.cpp:218] Iteration 13800 (4.21842 iter/s, 23.7056s/100 iters), loss = 0.182382
I0129 23:51:12.061408  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182382 (* 1 = 0.182382 loss)
I0129 23:51:12.061417  7239 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0129 23:51:35.689654  7239 solver.cpp:218] Iteration 13900 (4.23255 iter/s, 23.6264s/100 iters), loss = 0.188543
I0129 23:51:35.689680  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188544 (* 1 = 0.188544 loss)
I0129 23:51:35.689688  7239 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0129 23:51:59.109513  7239 solver.cpp:330] Iteration 14000, Testing net (#0)
I0129 23:52:16.016587  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:52:16.358851  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7246
I0129 23:52:16.358876  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.901397 (* 1 = 0.901397 loss)
I0129 23:52:16.607337  7239 solver.cpp:218] Iteration 14000 (2.44412 iter/s, 40.9146s/100 iters), loss = 0.301786
I0129 23:52:16.607362  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301786 (* 1 = 0.301786 loss)
I0129 23:52:16.607378  7239 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0129 23:52:30.025393  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:52:39.768115  7239 solver.cpp:218] Iteration 14100 (4.31797 iter/s, 23.159s/100 iters), loss = 0.403111
I0129 23:52:39.768146  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403111 (* 1 = 0.403111 loss)
I0129 23:52:39.768152  7239 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0129 23:53:03.164183  7239 solver.cpp:218] Iteration 14200 (4.27454 iter/s, 23.3943s/100 iters), loss = 0.247644
I0129 23:53:03.168862  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247645 (* 1 = 0.247645 loss)
I0129 23:53:03.168870  7239 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0129 23:53:27.137738  7239 solver.cpp:218] Iteration 14300 (4.17238 iter/s, 23.9671s/100 iters), loss = 0.221308
I0129 23:53:27.137769  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221308 (* 1 = 0.221308 loss)
I0129 23:53:27.137779  7239 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0129 23:53:50.386570  7239 solver.cpp:330] Iteration 14400, Testing net (#0)
I0129 23:54:07.274574  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:54:07.610168  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6959
I0129 23:54:07.610191  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04129 (* 1 = 1.04129 loss)
I0129 23:54:07.854044  7239 solver.cpp:218] Iteration 14400 (2.45619 iter/s, 40.7134s/100 iters), loss = 0.1237
I0129 23:54:07.854068  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123701 (* 1 = 0.123701 loss)
I0129 23:54:07.854082  7239 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0129 23:54:19.253696  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:54:30.952847  7239 solver.cpp:218] Iteration 14500 (4.32953 iter/s, 23.0972s/100 iters), loss = 0.274497
I0129 23:54:30.953364  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274498 (* 1 = 0.274498 loss)
I0129 23:54:30.953373  7239 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0129 23:54:54.491564  7239 solver.cpp:218] Iteration 14600 (4.2487 iter/s, 23.5366s/100 iters), loss = 0.083782
I0129 23:54:54.491593  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0837825 (* 1 = 0.0837825 loss)
I0129 23:54:54.491601  7239 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0129 23:55:18.474894  7239 solver.cpp:218] Iteration 14700 (4.16985 iter/s, 23.9817s/100 iters), loss = 0.142804
I0129 23:55:18.475507  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142804 (* 1 = 0.142804 loss)
I0129 23:55:18.475515  7239 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0129 23:55:42.028230  7239 solver.cpp:330] Iteration 14800, Testing net (#0)
I0129 23:55:58.498517  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:55:58.840035  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8175
I0129 23:55:58.840057  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.532056 (* 1 = 0.532056 loss)
I0129 23:55:59.086467  7239 solver.cpp:218] Iteration 14800 (2.46255 iter/s, 40.6083s/100 iters), loss = 0.330846
I0129 23:55:59.086493  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330846 (* 1 = 0.330846 loss)
I0129 23:55:59.086503  7239 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0129 23:56:08.142979  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:56:22.257889  7239 solver.cpp:218] Iteration 14900 (4.31595 iter/s, 23.1699s/100 iters), loss = 0.174165
I0129 23:56:22.257917  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174165 (* 1 = 0.174165 loss)
I0129 23:56:22.257926  7239 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0129 23:56:45.661425  7239 solver.cpp:218] Iteration 15000 (4.27314 iter/s, 23.402s/100 iters), loss = 0.121487
I0129 23:56:45.661494  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121488 (* 1 = 0.121488 loss)
I0129 23:56:45.661502  7239 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0129 23:57:09.115578  7239 solver.cpp:218] Iteration 15100 (4.26392 iter/s, 23.4526s/100 iters), loss = 0.354831
I0129 23:57:09.115605  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354831 (* 1 = 0.354831 loss)
I0129 23:57:09.115612  7239 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0129 23:57:32.599958  7239 solver.cpp:330] Iteration 15200, Testing net (#0)
I0129 23:57:49.475087  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:57:49.814097  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7853
I0129 23:57:49.814117  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.698709 (* 1 = 0.698709 loss)
I0129 23:57:50.055752  7239 solver.cpp:218] Iteration 15200 (2.44274 iter/s, 40.9376s/100 iters), loss = 0.085299
I0129 23:57:50.055778  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0852993 (* 1 = 0.0852993 loss)
I0129 23:57:50.055789  7239 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0129 23:57:57.109527  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:58:13.486790  7239 solver.cpp:218] Iteration 15300 (4.26811 iter/s, 23.4296s/100 iters), loss = 0.131953
I0129 23:58:13.486862  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131954 (* 1 = 0.131954 loss)
I0129 23:58:13.486871  7239 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0129 23:58:36.840489  7239 solver.cpp:218] Iteration 15400 (4.28225 iter/s, 23.3522s/100 iters), loss = 0.293852
I0129 23:58:36.840517  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293852 (* 1 = 0.293852 loss)
I0129 23:58:36.840524  7239 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0129 23:59:00.662616  7239 solver.cpp:218] Iteration 15500 (4.19804 iter/s, 23.8206s/100 iters), loss = 0.0739805
I0129 23:59:00.662725  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0739806 (* 1 = 0.0739806 loss)
I0129 23:59:00.662734  7239 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0129 23:59:23.962388  7239 solver.cpp:330] Iteration 15600, Testing net (#0)
I0129 23:59:40.651023  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0129 23:59:40.995554  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6456
I0129 23:59:40.995577  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.35507 (* 1 = 1.35507 loss)
I0129 23:59:41.251335  7239 solver.cpp:218] Iteration 15600 (2.46389 iter/s, 40.5862s/100 iters), loss = 0.115346
I0129 23:59:41.251365  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115346 (* 1 = 0.115346 loss)
I0129 23:59:41.251372  7239 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0129 23:59:46.221900  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:00:04.432251  7239 solver.cpp:218] Iteration 15700 (4.31416 iter/s, 23.1795s/100 iters), loss = 0.0863936
I0130 00:00:04.432279  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0863939 (* 1 = 0.0863939 loss)
I0130 00:00:04.432286  7239 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0130 00:00:28.270524  7239 solver.cpp:218] Iteration 15800 (4.19519 iter/s, 23.8368s/100 iters), loss = 0.159554
I0130 00:00:28.270594  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159554 (* 1 = 0.159554 loss)
I0130 00:00:28.270603  7239 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0130 00:00:51.778127  7239 solver.cpp:218] Iteration 15900 (4.2542 iter/s, 23.5062s/100 iters), loss = 0.137772
I0130 00:00:51.778154  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137772 (* 1 = 0.137772 loss)
I0130 00:00:51.778162  7239 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0130 00:01:15.235167  7239 solver.cpp:330] Iteration 16000, Testing net (#0)
I0130 00:01:32.154886  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:01:32.491022  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7029
I0130 00:01:32.491048  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.884426 (* 1 = 0.884426 loss)
I0130 00:01:32.740489  7239 solver.cpp:218] Iteration 16000 (2.44141 iter/s, 40.96s/100 iters), loss = 0.305227
I0130 00:01:32.740514  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305227 (* 1 = 0.305227 loss)
I0130 00:01:32.740530  7239 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0130 00:01:35.364614  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:01:55.801744  7239 solver.cpp:218] Iteration 16100 (4.33653 iter/s, 23.0599s/100 iters), loss = 0.162801
I0130 00:01:55.801810  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162801 (* 1 = 0.162801 loss)
I0130 00:01:55.801820  7239 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0130 00:02:19.477052  7239 solver.cpp:218] Iteration 16200 (4.22406 iter/s, 23.6739s/100 iters), loss = 0.25953
I0130 00:02:19.477079  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25953 (* 1 = 0.25953 loss)
I0130 00:02:19.477087  7239 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0130 00:02:43.147405  7239 solver.cpp:218] Iteration 16300 (4.22494 iter/s, 23.669s/100 iters), loss = 0.113539
I0130 00:02:43.148478  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113539 (* 1 = 0.113539 loss)
I0130 00:02:43.148488  7239 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0130 00:03:06.350759  7239 solver.cpp:330] Iteration 16400, Testing net (#0)
I0130 00:03:23.195448  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:03:23.530899  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.725
I0130 00:03:23.530921  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.962801 (* 1 = 0.962801 loss)
I0130 00:03:23.776654  7239 solver.cpp:218] Iteration 16400 (2.46148 iter/s, 40.6259s/100 iters), loss = 0.107064
I0130 00:03:23.776677  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107065 (* 1 = 0.107065 loss)
I0130 00:03:23.776695  7239 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0130 00:03:24.278795  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:03:46.876631  7239 solver.cpp:218] Iteration 16500 (4.32926 iter/s, 23.0987s/100 iters), loss = 0.272071
I0130 00:03:46.876662  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272071 (* 1 = 0.272071 loss)
I0130 00:03:46.876669  7239 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0130 00:04:10.585129  7239 solver.cpp:218] Iteration 16600 (4.21814 iter/s, 23.7071s/100 iters), loss = 0.116396
I0130 00:04:10.585220  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116396 (* 1 = 0.116396 loss)
I0130 00:04:10.585233  7239 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0130 00:04:34.026465  7239 solver.cpp:218] Iteration 16700 (4.26622 iter/s, 23.4399s/100 iters), loss = 0.296781
I0130 00:04:34.026494  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296781 (* 1 = 0.296781 loss)
I0130 00:04:34.026500  7239 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0130 00:04:55.705171  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:04:57.323412  7239 solver.cpp:330] Iteration 16800, Testing net (#0)
I0130 00:05:14.155357  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:05:14.492861  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8024
I0130 00:05:14.492887  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.602553 (* 1 = 0.602553 loss)
I0130 00:05:14.738584  7239 solver.cpp:218] Iteration 16800 (2.45641 iter/s, 40.7099s/100 iters), loss = 0.227082
I0130 00:05:14.738606  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227082 (* 1 = 0.227082 loss)
I0130 00:05:14.738621  7239 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0130 00:05:37.918418  7239 solver.cpp:218] Iteration 16900 (4.31434 iter/s, 23.1785s/100 iters), loss = 0.0910133
I0130 00:05:37.918490  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0910134 (* 1 = 0.0910134 loss)
I0130 00:05:37.918498  7239 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0130 00:06:01.463640  7239 solver.cpp:218] Iteration 17000 (4.24739 iter/s, 23.5439s/100 iters), loss = 0.146446
I0130 00:06:01.463668  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146447 (* 1 = 0.146447 loss)
I0130 00:06:01.463676  7239 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0130 00:06:25.388597  7239 solver.cpp:218] Iteration 17100 (4.17997 iter/s, 23.9236s/100 iters), loss = 0.443685
I0130 00:06:25.388664  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443685 (* 1 = 0.443685 loss)
I0130 00:06:25.388672  7239 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0130 00:06:45.057004  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:06:48.876833  7239 solver.cpp:330] Iteration 17200, Testing net (#0)
I0130 00:07:05.687710  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:07:06.021402  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8165
I0130 00:07:06.021425  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.598851 (* 1 = 0.598851 loss)
I0130 00:07:06.268853  7239 solver.cpp:218] Iteration 17200 (2.4463 iter/s, 40.878s/100 iters), loss = 0.0316122
I0130 00:07:06.268880  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316123 (* 1 = 0.0316123 loss)
I0130 00:07:06.268887  7239 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0130 00:07:29.275534  7239 solver.cpp:218] Iteration 17300 (4.3468 iter/s, 23.0054s/100 iters), loss = 0.398593
I0130 00:07:29.275562  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398594 (* 1 = 0.398594 loss)
I0130 00:07:29.275568  7239 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0130 00:07:52.619637  7239 solver.cpp:218] Iteration 17400 (4.28397 iter/s, 23.3428s/100 iters), loss = 0.071388
I0130 00:07:52.619843  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0713881 (* 1 = 0.0713881 loss)
I0130 00:07:52.619853  7239 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0130 00:08:16.615830  7239 solver.cpp:218] Iteration 17500 (4.16758 iter/s, 23.9947s/100 iters), loss = 0.236533
I0130 00:08:16.615866  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236533 (* 1 = 0.236533 loss)
I0130 00:08:16.615885  7239 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0130 00:08:34.108798  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:08:40.049010  7239 solver.cpp:330] Iteration 17600, Testing net (#0)
I0130 00:08:56.516876  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:08:56.850072  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7706
I0130 00:08:56.850095  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.691247 (* 1 = 0.691247 loss)
I0130 00:08:57.091218  7239 solver.cpp:218] Iteration 17600 (2.47077 iter/s, 40.4732s/100 iters), loss = 0.14076
I0130 00:08:57.091243  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140761 (* 1 = 0.140761 loss)
I0130 00:08:57.091258  7239 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0130 00:09:20.450117  7239 solver.cpp:218] Iteration 17700 (4.28125 iter/s, 23.3576s/100 iters), loss = 0.403816
I0130 00:09:20.450181  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403816 (* 1 = 0.403816 loss)
I0130 00:09:20.450189  7239 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0130 00:09:43.786126  7239 solver.cpp:218] Iteration 17800 (4.28546 iter/s, 23.3347s/100 iters), loss = 0.284189
I0130 00:09:43.786154  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28419 (* 1 = 0.28419 loss)
I0130 00:09:43.786161  7239 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0130 00:10:07.351208  7239 solver.cpp:218] Iteration 17900 (4.24379 iter/s, 23.5638s/100 iters), loss = 0.437724
I0130 00:10:07.351279  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437724 (* 1 = 0.437724 loss)
I0130 00:10:07.351289  7239 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0130 00:10:22.690654  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:10:30.860322  7239 solver.cpp:330] Iteration 18000, Testing net (#0)
I0130 00:10:47.595291  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:10:47.941828  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8099
I0130 00:10:47.941853  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.597894 (* 1 = 0.597894 loss)
I0130 00:10:48.195502  7239 solver.cpp:218] Iteration 18000 (2.44845 iter/s, 40.8421s/100 iters), loss = 0.142911
I0130 00:10:48.195533  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142911 (* 1 = 0.142911 loss)
I0130 00:10:48.195542  7239 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0130 00:11:11.403055  7239 solver.cpp:218] Iteration 18100 (4.30917 iter/s, 23.2063s/100 iters), loss = 0.26704
I0130 00:11:11.403080  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26704 (* 1 = 0.26704 loss)
I0130 00:11:11.403089  7239 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0130 00:11:34.891669  7239 solver.cpp:218] Iteration 18200 (4.25761 iter/s, 23.4874s/100 iters), loss = 0.341813
I0130 00:11:34.891757  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341813 (* 1 = 0.341813 loss)
I0130 00:11:34.891768  7239 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0130 00:11:58.783931  7239 solver.cpp:218] Iteration 18300 (4.18569 iter/s, 23.8909s/100 iters), loss = 0.0905581
I0130 00:11:58.783957  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0905582 (* 1 = 0.0905582 loss)
I0130 00:11:58.783967  7239 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0130 00:12:11.657989  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:12:22.104871  7239 solver.cpp:330] Iteration 18400, Testing net (#0)
I0130 00:12:38.556082  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:12:38.891809  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7794
I0130 00:12:38.891834  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.682196 (* 1 = 0.682196 loss)
I0130 00:12:39.138566  7239 solver.cpp:218] Iteration 18400 (2.47816 iter/s, 40.3525s/100 iters), loss = 0.144446
I0130 00:12:39.138597  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144446 (* 1 = 0.144446 loss)
I0130 00:12:39.138604  7239 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0130 00:13:02.575951  7239 solver.cpp:218] Iteration 18500 (4.26691 iter/s, 23.4361s/100 iters), loss = 0.243974
I0130 00:13:02.576031  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243975 (* 1 = 0.243975 loss)
I0130 00:13:02.576041  7239 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0130 00:13:25.829016  7239 solver.cpp:218] Iteration 18600 (4.30074 iter/s, 23.2518s/100 iters), loss = 0.329595
I0130 00:13:25.829043  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329595 (* 1 = 0.329595 loss)
I0130 00:13:25.829052  7239 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0130 00:13:49.654484  7239 solver.cpp:218] Iteration 18700 (4.19741 iter/s, 23.8242s/100 iters), loss = 0.113865
I0130 00:13:49.654553  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113865 (* 1 = 0.113865 loss)
I0130 00:13:49.654563  7239 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0130 00:14:00.710014  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:14:13.072755  7239 solver.cpp:330] Iteration 18800, Testing net (#0)
I0130 00:14:29.800660  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:14:30.137346  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7795
I0130 00:14:30.137370  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.722664 (* 1 = 0.722664 loss)
I0130 00:14:30.382524  7239 solver.cpp:218] Iteration 18800 (2.45544 iter/s, 40.7259s/100 iters), loss = 0.40796
I0130 00:14:30.382547  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40796 (* 1 = 0.40796 loss)
I0130 00:14:30.382566  7239 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0130 00:14:53.697643  7239 solver.cpp:218] Iteration 18900 (4.28929 iter/s, 23.3139s/100 iters), loss = 0.31156
I0130 00:14:53.697670  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31156 (* 1 = 0.31156 loss)
I0130 00:14:53.697679  7239 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0130 00:15:17.269177  7239 solver.cpp:218] Iteration 19000 (4.24263 iter/s, 23.5703s/100 iters), loss = 0.436435
I0130 00:15:17.269243  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436435 (* 1 = 0.436435 loss)
I0130 00:15:17.269253  7239 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0130 00:15:41.136764  7239 solver.cpp:218] Iteration 19100 (4.19001 iter/s, 23.8663s/100 iters), loss = 0.260659
I0130 00:15:41.136790  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26066 (* 1 = 0.26066 loss)
I0130 00:15:41.136801  7239 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0130 00:15:49.548815  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:16:04.487920  7239 solver.cpp:330] Iteration 19200, Testing net (#0)
I0130 00:16:21.136757  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:16:21.469408  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7998
I0130 00:16:21.469430  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.632139 (* 1 = 0.632139 loss)
I0130 00:16:21.714319  7239 solver.cpp:218] Iteration 19200 (2.46454 iter/s, 40.5755s/100 iters), loss = 0.296932
I0130 00:16:21.714349  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296933 (* 1 = 0.296933 loss)
I0130 00:16:21.714355  7239 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0130 00:16:45.083029  7239 solver.cpp:218] Iteration 19300 (4.27945 iter/s, 23.3675s/100 iters), loss = 0.250458
I0130 00:16:45.083056  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250459 (* 1 = 0.250459 loss)
I0130 00:16:45.083065  7239 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0130 00:17:08.559356  7239 solver.cpp:218] Iteration 19400 (4.25983 iter/s, 23.4751s/100 iters), loss = 0.193123
I0130 00:17:08.559443  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193123 (* 1 = 0.193123 loss)
I0130 00:17:08.559453  7239 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0130 00:17:32.619858  7239 solver.cpp:218] Iteration 19500 (4.15641 iter/s, 24.0592s/100 iters), loss = 0.431659
I0130 00:17:32.619884  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43166 (* 1 = 0.43166 loss)
I0130 00:17:32.619891  7239 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0130 00:17:39.013854  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:17:55.668787  7239 solver.cpp:330] Iteration 19600, Testing net (#0)
I0130 00:18:12.553555  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:18:12.889740  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7284
I0130 00:18:12.889767  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.906149 (* 1 = 0.906149 loss)
I0130 00:18:13.133090  7239 solver.cpp:218] Iteration 19600 (2.46846 iter/s, 40.5112s/100 iters), loss = 0.313602
I0130 00:18:13.133116  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313603 (* 1 = 0.313603 loss)
I0130 00:18:13.133126  7239 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0130 00:18:36.206815  7239 solver.cpp:218] Iteration 19700 (4.33416 iter/s, 23.0725s/100 iters), loss = 0.0829006
I0130 00:18:36.206845  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.082901 (* 1 = 0.082901 loss)
I0130 00:18:36.206852  7239 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0130 00:19:00.025442  7239 solver.cpp:218] Iteration 19800 (4.19861 iter/s, 23.8174s/100 iters), loss = 0.411149
I0130 00:19:00.027550  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411149 (* 1 = 0.411149 loss)
I0130 00:19:00.027559  7239 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0130 00:19:23.543862  7239 solver.cpp:218] Iteration 19900 (4.25258 iter/s, 23.5151s/100 iters), loss = 0.416407
I0130 00:19:23.543889  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416408 (* 1 = 0.416408 loss)
I0130 00:19:23.543896  7239 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0130 00:19:27.501544  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:19:46.919944  7239 solver.cpp:330] Iteration 20000, Testing net (#0)
I0130 00:20:03.734604  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:20:04.068213  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.757
I0130 00:20:04.068236  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.718386 (* 1 = 0.718386 loss)
I0130 00:20:04.307591  7239 solver.cpp:218] Iteration 20000 (2.45321 iter/s, 40.7629s/100 iters), loss = 0.353341
I0130 00:20:04.307615  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353342 (* 1 = 0.353342 loss)
I0130 00:20:04.307629  7239 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0130 00:20:27.617095  7239 solver.cpp:218] Iteration 20100 (4.29002 iter/s, 23.3099s/100 iters), loss = 0.530434
I0130 00:20:27.617163  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.530435 (* 1 = 0.530435 loss)
I0130 00:20:27.617172  7239 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0130 00:20:51.035390  7239 solver.cpp:218] Iteration 20200 (4.27011 iter/s, 23.4186s/100 iters), loss = 0.403779
I0130 00:20:51.035421  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40378 (* 1 = 0.40378 loss)
I0130 00:20:51.035429  7239 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0130 00:21:14.519834  7239 solver.cpp:218] Iteration 20300 (4.25809 iter/s, 23.4847s/100 iters), loss = 0.107691
I0130 00:21:14.519907  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107692 (* 1 = 0.107692 loss)
I0130 00:21:14.519917  7239 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0130 00:21:16.488668  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:21:38.014878  7239 solver.cpp:330] Iteration 20400, Testing net (#0)
I0130 00:21:54.719323  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:21:55.063398  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8133
I0130 00:21:55.063424  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.578593 (* 1 = 0.578593 loss)
I0130 00:21:55.311480  7239 solver.cpp:218] Iteration 20400 (2.45146 iter/s, 40.792s/100 iters), loss = 0.26317
I0130 00:21:55.311506  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263171 (* 1 = 0.263171 loss)
I0130 00:21:55.311514  7239 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0130 00:22:18.525445  7239 solver.cpp:218] Iteration 20500 (4.30773 iter/s, 23.2141s/100 iters), loss = 0.159029
I0130 00:22:18.525475  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15903 (* 1 = 0.15903 loss)
I0130 00:22:18.525482  7239 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0130 00:22:42.119042  7239 solver.cpp:218] Iteration 20600 (4.23843 iter/s, 23.5937s/100 iters), loss = 0.428663
I0130 00:22:42.119109  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428663 (* 1 = 0.428663 loss)
I0130 00:22:42.119118  7239 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0130 00:23:05.222085  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:23:05.449182  7239 solver.cpp:218] Iteration 20700 (4.2863 iter/s, 23.3301s/100 iters), loss = 0.208885
I0130 00:23:05.449209  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208886 (* 1 = 0.208886 loss)
I0130 00:23:05.449218  7239 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0130 00:23:29.206120  7239 solver.cpp:330] Iteration 20800, Testing net (#0)
I0130 00:23:45.877866  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:23:46.214228  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7938
I0130 00:23:46.214251  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.659347 (* 1 = 0.659347 loss)
I0130 00:23:46.462374  7239 solver.cpp:218] Iteration 20800 (2.43824 iter/s, 41.0131s/100 iters), loss = 0.163088
I0130 00:23:46.462399  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163089 (* 1 = 0.163089 loss)
I0130 00:23:46.462409  7239 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0130 00:24:09.593216  7239 solver.cpp:218] Iteration 20900 (4.32325 iter/s, 23.1307s/100 iters), loss = 0.436896
I0130 00:24:09.593289  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436897 (* 1 = 0.436897 loss)
I0130 00:24:09.593297  7239 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0130 00:24:33.102207  7239 solver.cpp:218] Iteration 21000 (4.25373 iter/s, 23.5088s/100 iters), loss = 0.161574
I0130 00:24:33.102234  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161575 (* 1 = 0.161575 loss)
I0130 00:24:33.102243  7239 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0130 00:24:54.193696  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:24:56.738586  7239 solver.cpp:218] Iteration 21100 (4.2308 iter/s, 23.6362s/100 iters), loss = 0.448367
I0130 00:24:56.738612  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448367 (* 1 = 0.448367 loss)
I0130 00:24:56.738622  7239 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0130 00:25:20.074204  7239 solver.cpp:330] Iteration 21200, Testing net (#0)
I0130 00:25:36.962179  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:25:37.299875  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7931
I0130 00:25:37.299901  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.630185 (* 1 = 0.630185 loss)
I0130 00:25:37.544600  7239 solver.cpp:218] Iteration 21200 (2.45064 iter/s, 40.8056s/100 iters), loss = 0.330799
I0130 00:25:37.544622  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3308 (* 1 = 0.3308 loss)
I0130 00:25:37.544636  7239 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0130 00:26:00.866142  7239 solver.cpp:218] Iteration 21300 (4.28793 iter/s, 23.3213s/100 iters), loss = 0.118847
I0130 00:26:00.866173  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118847 (* 1 = 0.118847 loss)
I0130 00:26:00.866183  7239 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0130 00:26:24.464526  7239 solver.cpp:218] Iteration 21400 (4.23764 iter/s, 23.5981s/100 iters), loss = 0.185126
I0130 00:26:24.465337  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185127 (* 1 = 0.185127 loss)
I0130 00:26:24.465346  7239 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0130 00:26:43.450731  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:26:48.195029  7239 solver.cpp:218] Iteration 21500 (4.21419 iter/s, 23.7294s/100 iters), loss = 0.355595
I0130 00:26:48.195055  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355596 (* 1 = 0.355596 loss)
I0130 00:26:48.195063  7239 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0130 00:27:11.713901  7239 solver.cpp:330] Iteration 21600, Testing net (#0)
I0130 00:27:28.171398  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:27:28.509553  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8076
I0130 00:27:28.509575  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.59048 (* 1 = 0.59048 loss)
I0130 00:27:28.755882  7239 solver.cpp:218] Iteration 21600 (2.46547 iter/s, 40.5602s/100 iters), loss = 0.132929
I0130 00:27:28.755904  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132929 (* 1 = 0.132929 loss)
I0130 00:27:28.755918  7239 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0130 00:27:51.989351  7239 solver.cpp:218] Iteration 21700 (4.30421 iter/s, 23.2331s/100 iters), loss = 0.421811
I0130 00:27:51.989430  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421811 (* 1 = 0.421811 loss)
I0130 00:27:51.989439  7239 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0130 00:28:15.627460  7239 solver.cpp:218] Iteration 21800 (4.23055 iter/s, 23.6376s/100 iters), loss = 0.161714
I0130 00:28:15.627485  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161715 (* 1 = 0.161715 loss)
I0130 00:28:15.627493  7239 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0130 00:28:32.709486  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:28:39.480011  7239 solver.cpp:218] Iteration 21900 (4.19251 iter/s, 23.8521s/100 iters), loss = 0.16863
I0130 00:28:39.480037  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168631 (* 1 = 0.168631 loss)
I0130 00:28:39.480046  7239 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0130 00:29:03.036996  7239 solver.cpp:330] Iteration 22000, Testing net (#0)
I0130 00:29:19.567814  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:29:19.906359  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8092
I0130 00:29:19.906383  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.598286 (* 1 = 0.598286 loss)
I0130 00:29:20.151026  7239 solver.cpp:218] Iteration 22000 (2.4588 iter/s, 40.6702s/100 iters), loss = 0.257914
I0130 00:29:20.151051  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257914 (* 1 = 0.257914 loss)
I0130 00:29:20.151064  7239 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0130 00:29:43.307847  7239 solver.cpp:218] Iteration 22100 (4.31848 iter/s, 23.1563s/100 iters), loss = 0.0977839
I0130 00:29:43.307916  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0977845 (* 1 = 0.0977845 loss)
I0130 00:29:43.307926  7239 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0130 00:30:06.889791  7239 solver.cpp:218] Iteration 22200 (4.24064 iter/s, 23.5813s/100 iters), loss = 0.162711
I0130 00:30:06.889819  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162712 (* 1 = 0.162712 loss)
I0130 00:30:06.889827  7239 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0130 00:30:21.319387  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:30:30.466218  7239 solver.cpp:218] Iteration 22300 (4.24163 iter/s, 23.5758s/100 iters), loss = 0.118872
I0130 00:30:30.466245  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118873 (* 1 = 0.118873 loss)
I0130 00:30:30.466259  7239 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0130 00:30:53.810801  7239 solver.cpp:330] Iteration 22400, Testing net (#0)
I0130 00:31:10.403739  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:31:10.741169  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.806
I0130 00:31:10.741192  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.568212 (* 1 = 0.568212 loss)
I0130 00:31:10.987403  7239 solver.cpp:218] Iteration 22400 (2.46791 iter/s, 40.5202s/100 iters), loss = 0.0966308
I0130 00:31:10.987426  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0966315 (* 1 = 0.0966315 loss)
I0130 00:31:10.987447  7239 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0130 00:31:34.237843  7239 solver.cpp:218] Iteration 22500 (4.30111 iter/s, 23.2498s/100 iters), loss = 0.351907
I0130 00:31:34.237907  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351908 (* 1 = 0.351908 loss)
I0130 00:31:34.237915  7239 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0130 00:31:57.632174  7239 solver.cpp:218] Iteration 22600 (4.27466 iter/s, 23.3937s/100 iters), loss = 0.343517
I0130 00:31:57.632201  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343518 (* 1 = 0.343518 loss)
I0130 00:31:57.632210  7239 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0130 00:32:09.844770  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:32:21.205415  7239 solver.cpp:218] Iteration 22700 (4.24222 iter/s, 23.5726s/100 iters), loss = 0.219256
I0130 00:32:21.205443  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219257 (* 1 = 0.219257 loss)
I0130 00:32:21.205451  7239 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0130 00:32:45.010624  7239 solver.cpp:330] Iteration 22800, Testing net (#0)
I0130 00:33:01.452249  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:33:01.788908  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6882
I0130 00:33:01.788930  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.11634 (* 1 = 1.11634 loss)
I0130 00:33:02.040277  7239 solver.cpp:218] Iteration 22800 (2.44896 iter/s, 40.8337s/100 iters), loss = 0.279799
I0130 00:33:02.040305  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2798 (* 1 = 0.2798 loss)
I0130 00:33:02.040313  7239 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0130 00:33:25.308714  7239 solver.cpp:218] Iteration 22900 (4.2978 iter/s, 23.2677s/100 iters), loss = 0.198658
I0130 00:33:25.308785  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198658 (* 1 = 0.198658 loss)
I0130 00:33:25.308794  7239 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0130 00:33:48.743973  7239 solver.cpp:218] Iteration 23000 (4.26721 iter/s, 23.4345s/100 iters), loss = 0.174194
I0130 00:33:48.743999  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174195 (* 1 = 0.174195 loss)
I0130 00:33:48.744007  7239 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0130 00:33:58.668905  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:34:12.509891  7239 solver.cpp:218] Iteration 23100 (4.20784 iter/s, 23.7652s/100 iters), loss = 0.404895
I0130 00:34:12.509918  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404896 (* 1 = 0.404896 loss)
I0130 00:34:12.509928  7239 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0130 00:34:35.883110  7239 solver.cpp:330] Iteration 23200, Testing net (#0)
I0130 00:34:52.547667  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:34:52.891533  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7449
I0130 00:34:52.891556  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.739834 (* 1 = 0.739834 loss)
I0130 00:34:53.136196  7239 solver.cpp:218] Iteration 23200 (2.46154 iter/s, 40.625s/100 iters), loss = 0.0442175
I0130 00:34:53.136224  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0442184 (* 1 = 0.0442184 loss)
I0130 00:34:53.136231  7239 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0130 00:35:16.385241  7239 solver.cpp:218] Iteration 23300 (4.30139 iter/s, 23.2483s/100 iters), loss = 0.167622
I0130 00:35:16.386219  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167623 (* 1 = 0.167623 loss)
I0130 00:35:16.386227  7239 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0130 00:35:39.942435  7239 solver.cpp:218] Iteration 23400 (4.2453 iter/s, 23.5555s/100 iters), loss = 0.250253
I0130 00:35:39.942467  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250254 (* 1 = 0.250254 loss)
I0130 00:35:39.942476  7239 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0130 00:35:47.797967  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:36:03.547916  7239 solver.cpp:218] Iteration 23500 (4.23644 iter/s, 23.6047s/100 iters), loss = 0.19433
I0130 00:36:03.547946  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19433 (* 1 = 0.19433 loss)
I0130 00:36:03.547953  7239 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0130 00:36:26.776729  7239 solver.cpp:330] Iteration 23600, Testing net (#0)
I0130 00:36:43.638321  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:36:43.980047  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7403
I0130 00:36:43.980072  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.975257 (* 1 = 0.975257 loss)
I0130 00:36:44.225302  7239 solver.cpp:218] Iteration 23600 (2.45845 iter/s, 40.676s/100 iters), loss = 0.199796
I0130 00:36:44.225327  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199797 (* 1 = 0.199797 loss)
I0130 00:36:44.225338  7239 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0130 00:37:07.549091  7239 solver.cpp:218] Iteration 23700 (4.28761 iter/s, 23.323s/100 iters), loss = 0.403178
I0130 00:37:07.551201  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403178 (* 1 = 0.403178 loss)
I0130 00:37:07.551213  7239 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0130 00:37:31.089673  7239 solver.cpp:218] Iteration 23800 (4.24851 iter/s, 23.5377s/100 iters), loss = 0.26523
I0130 00:37:31.089699  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265231 (* 1 = 0.265231 loss)
I0130 00:37:31.089705  7239 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0130 00:37:36.716284  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:37:54.704990  7239 solver.cpp:218] Iteration 23900 (4.23469 iter/s, 23.6145s/100 iters), loss = 0.201775
I0130 00:37:54.705054  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201776 (* 1 = 0.201776 loss)
I0130 00:37:54.705066  7239 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0130 00:38:17.904104  7239 solver.cpp:447] Snapshotting to binary proto file examples/bao/WRN-28_iter_24000.caffemodel
I0130 00:38:18.256971  7239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/bao/WRN-28_iter_24000.solverstate
I0130 00:38:18.454886  7239 solver.cpp:330] Iteration 24000, Testing net (#0)
I0130 00:38:35.385453  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:38:35.725529  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7774
I0130 00:38:35.725555  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.715796 (* 1 = 0.715796 loss)
I0130 00:38:35.971282  7239 solver.cpp:218] Iteration 24000 (2.42337 iter/s, 41.2648s/100 iters), loss = 0.0844926
I0130 00:38:35.971304  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0844933 (* 1 = 0.0844933 loss)
I0130 00:38:35.971323  7239 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0130 00:38:35.971326  7239 sgd_solver.cpp:105] Iteration 24000, lr = 0.02
I0130 00:38:35.971343  7267 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0130 00:38:35.971343  7266 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0130 00:38:35.971345  7265 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 1
I0130 00:38:59.125260  7239 solver.cpp:218] Iteration 24100 (4.31907 iter/s, 23.1531s/100 iters), loss = 0.0825908
I0130 00:38:59.125288  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0825914 (* 1 = 0.0825914 loss)
I0130 00:38:59.125296  7239 sgd_solver.cpp:105] Iteration 24100, lr = 0.02
I0130 00:39:22.574285  7239 solver.cpp:218] Iteration 24200 (4.26472 iter/s, 23.4482s/100 iters), loss = 0.201206
I0130 00:39:22.574395  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201207 (* 1 = 0.201207 loss)
I0130 00:39:22.574409  7239 sgd_solver.cpp:105] Iteration 24200, lr = 0.02
I0130 00:39:25.952848  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:39:46.118582  7239 solver.cpp:218] Iteration 24300 (4.24748 iter/s, 23.5434s/100 iters), loss = 0.160784
I0130 00:39:46.118608  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160785 (* 1 = 0.160785 loss)
I0130 00:39:46.118618  7239 sgd_solver.cpp:105] Iteration 24300, lr = 0.02
I0130 00:40:09.331632  7239 solver.cpp:330] Iteration 24400, Testing net (#0)
I0130 00:40:26.215793  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:40:26.553246  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I0130 00:40:26.553269  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.276516 (* 1 = 0.276516 loss)
I0130 00:40:26.796227  7239 solver.cpp:218] Iteration 24400 (2.45844 iter/s, 40.6762s/100 iters), loss = 0.0646806
I0130 00:40:26.796252  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0646812 (* 1 = 0.0646812 loss)
I0130 00:40:26.796267  7239 sgd_solver.cpp:105] Iteration 24400, lr = 0.02
I0130 00:40:49.799340  7239 solver.cpp:218] Iteration 24500 (4.3474 iter/s, 23.0023s/100 iters), loss = 0.0339457
I0130 00:40:49.800689  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339464 (* 1 = 0.0339464 loss)
I0130 00:40:49.800698  7239 sgd_solver.cpp:105] Iteration 24500, lr = 0.02
I0130 00:41:13.381662  7239 solver.cpp:218] Iteration 24600 (4.24086 iter/s, 23.5801s/100 iters), loss = 0.00946166
I0130 00:41:13.381691  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00946228 (* 1 = 0.00946228 loss)
I0130 00:41:13.381700  7239 sgd_solver.cpp:105] Iteration 24600, lr = 0.02
I0130 00:41:14.572896  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:41:37.215078  7239 solver.cpp:218] Iteration 24700 (4.19595 iter/s, 23.8325s/100 iters), loss = 0.0511704
I0130 00:41:37.221086  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.051171 (* 1 = 0.051171 loss)
I0130 00:41:37.221094  7239 sgd_solver.cpp:105] Iteration 24700, lr = 0.02
I0130 00:42:00.485743  7239 solver.cpp:330] Iteration 24800, Testing net (#0)
I0130 00:42:17.133888  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:42:17.469063  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8064
I0130 00:42:17.469087  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.602175 (* 1 = 0.602175 loss)
I0130 00:42:17.714231  7239 solver.cpp:218] Iteration 24800 (2.46964 iter/s, 40.4917s/100 iters), loss = 0.0521057
I0130 00:42:17.714256  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0521063 (* 1 = 0.0521063 loss)
I0130 00:42:17.714262  7239 sgd_solver.cpp:105] Iteration 24800, lr = 0.02
I0130 00:42:40.913602  7239 solver.cpp:218] Iteration 24900 (4.31063 iter/s, 23.1985s/100 iters), loss = 0.0525741
I0130 00:42:40.913630  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0525747 (* 1 = 0.0525747 loss)
I0130 00:42:40.913640  7239 sgd_solver.cpp:105] Iteration 24900, lr = 0.02
I0130 00:43:03.382225  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:43:04.332741  7239 solver.cpp:218] Iteration 25000 (4.27018 iter/s, 23.4182s/100 iters), loss = 0.0079066
I0130 00:43:04.332774  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0079072 (* 1 = 0.0079072 loss)
I0130 00:43:04.332784  7239 sgd_solver.cpp:105] Iteration 25000, lr = 0.02
I0130 00:43:27.831298  7239 solver.cpp:218] Iteration 25100 (4.25575 iter/s, 23.4976s/100 iters), loss = 0.0114828
I0130 00:43:27.831324  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114834 (* 1 = 0.0114834 loss)
I0130 00:43:27.831332  7239 sgd_solver.cpp:105] Iteration 25100, lr = 0.02
I0130 00:43:50.884567  7239 solver.cpp:330] Iteration 25200, Testing net (#0)
I0130 00:44:07.840611  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:44:08.179689  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6926
I0130 00:44:08.179715  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.950388 (* 1 = 0.950388 loss)
I0130 00:44:08.425572  7239 solver.cpp:218] Iteration 25200 (2.4635 iter/s, 40.5927s/100 iters), loss = 0.134638
I0130 00:44:08.425602  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134639 (* 1 = 0.134639 loss)
I0130 00:44:08.425609  7239 sgd_solver.cpp:105] Iteration 25200, lr = 0.02
I0130 00:44:31.487558  7239 solver.cpp:218] Iteration 25300 (4.33631 iter/s, 23.0611s/100 iters), loss = 0.0990998
I0130 00:44:31.488878  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0991003 (* 1 = 0.0991003 loss)
I0130 00:44:31.488888  7239 sgd_solver.cpp:105] Iteration 25300, lr = 0.02
I0130 00:44:51.413210  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:44:54.709774  7239 solver.cpp:218] Iteration 25400 (4.30663 iter/s, 23.22s/100 iters), loss = 0.022782
I0130 00:44:54.709802  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227825 (* 1 = 0.0227825 loss)
I0130 00:44:54.709810  7239 sgd_solver.cpp:105] Iteration 25400, lr = 0.02
I0130 00:45:18.277194  7239 solver.cpp:218] Iteration 25500 (4.24331 iter/s, 23.5665s/100 iters), loss = 0.00812078
I0130 00:45:18.278229  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0081213 (* 1 = 0.0081213 loss)
I0130 00:45:18.278239  7239 sgd_solver.cpp:105] Iteration 25500, lr = 0.02
I0130 00:45:41.664932  7239 solver.cpp:330] Iteration 25600, Testing net (#0)
I0130 00:45:58.178202  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:45:58.509487  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6734
I0130 00:45:58.509510  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07058 (* 1 = 1.07058 loss)
I0130 00:45:58.757992  7239 solver.cpp:218] Iteration 25600 (2.47046 iter/s, 40.4782s/100 iters), loss = 0.112435
I0130 00:45:58.758014  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112436 (* 1 = 0.112436 loss)
I0130 00:45:58.758033  7239 sgd_solver.cpp:105] Iteration 25600, lr = 0.02
I0130 00:46:21.808250  7239 solver.cpp:218] Iteration 25700 (4.33852 iter/s, 23.0493s/100 iters), loss = 0.00385537
I0130 00:46:21.808279  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385587 (* 1 = 0.00385587 loss)
I0130 00:46:21.808286  7239 sgd_solver.cpp:105] Iteration 25700, lr = 0.02
I0130 00:46:39.774091  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:46:45.144928  7239 solver.cpp:218] Iteration 25800 (4.28527 iter/s, 23.3357s/100 iters), loss = 0.00811723
I0130 00:46:45.144956  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00811775 (* 1 = 0.00811775 loss)
I0130 00:46:45.144963  7239 sgd_solver.cpp:105] Iteration 25800, lr = 0.02
I0130 00:47:08.661767  7239 solver.cpp:218] Iteration 25900 (4.25244 iter/s, 23.5159s/100 iters), loss = 0.0310203
I0130 00:47:08.661794  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310208 (* 1 = 0.0310208 loss)
I0130 00:47:08.661801  7239 sgd_solver.cpp:105] Iteration 25900, lr = 0.02
I0130 00:47:31.933018  7239 solver.cpp:330] Iteration 26000, Testing net (#0)
I0130 00:47:48.629097  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:47:48.960786  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6537
I0130 00:47:48.960809  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.18133 (* 1 = 1.18133 loss)
I0130 00:47:49.211956  7239 solver.cpp:218] Iteration 26000 (2.46618 iter/s, 40.5486s/100 iters), loss = 0.0126236
I0130 00:47:49.211978  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126241 (* 1 = 0.0126241 loss)
I0130 00:47:49.211992  7239 sgd_solver.cpp:105] Iteration 26000, lr = 0.02
I0130 00:48:12.301852  7239 solver.cpp:218] Iteration 26100 (4.33107 iter/s, 23.089s/100 iters), loss = 0.136305
I0130 00:48:12.301939  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136305 (* 1 = 0.136305 loss)
I0130 00:48:12.301951  7239 sgd_solver.cpp:105] Iteration 26100, lr = 0.02
I0130 00:48:27.986454  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:48:35.906977  7239 solver.cpp:218] Iteration 26200 (4.23655 iter/s, 23.6041s/100 iters), loss = 0.00460033
I0130 00:48:35.907003  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460086 (* 1 = 0.00460086 loss)
I0130 00:48:35.907011  7239 sgd_solver.cpp:105] Iteration 26200, lr = 0.02
I0130 00:48:59.625879  7239 solver.cpp:218] Iteration 26300 (4.21622 iter/s, 23.7179s/100 iters), loss = 0.088492
I0130 00:48:59.625952  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0884925 (* 1 = 0.0884925 loss)
I0130 00:48:59.625962  7239 sgd_solver.cpp:105] Iteration 26300, lr = 0.02
I0130 00:49:22.850636  7239 solver.cpp:330] Iteration 26400, Testing net (#0)
I0130 00:49:39.600320  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:49:39.940775  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5692
I0130 00:49:39.940798  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.63304 (* 1 = 1.63304 loss)
I0130 00:49:40.186424  7239 solver.cpp:218] Iteration 26400 (2.46555 iter/s, 40.5589s/100 iters), loss = 0.0101863
I0130 00:49:40.186448  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101868 (* 1 = 0.0101868 loss)
I0130 00:49:40.186457  7239 sgd_solver.cpp:105] Iteration 26400, lr = 0.02
I0130 00:50:03.395189  7239 solver.cpp:218] Iteration 26500 (4.30889 iter/s, 23.2078s/100 iters), loss = 0.0560061
I0130 00:50:03.395216  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560066 (* 1 = 0.0560066 loss)
I0130 00:50:03.395226  7239 sgd_solver.cpp:105] Iteration 26500, lr = 0.02
I0130 00:50:16.884914  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:50:26.665645  7239 solver.cpp:218] Iteration 26600 (4.29747 iter/s, 23.2695s/100 iters), loss = 0.00376944
I0130 00:50:26.665673  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00376996 (* 1 = 0.00376996 loss)
I0130 00:50:26.665681  7239 sgd_solver.cpp:105] Iteration 26600, lr = 0.02
I0130 00:50:50.552186  7239 solver.cpp:218] Iteration 26700 (4.18663 iter/s, 23.8856s/100 iters), loss = 0.00350092
I0130 00:50:50.554801  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350141 (* 1 = 0.00350141 loss)
I0130 00:50:50.554811  7239 sgd_solver.cpp:105] Iteration 26700, lr = 0.02
I0130 00:51:13.983883  7239 solver.cpp:330] Iteration 26800, Testing net (#0)
I0130 00:51:30.539620  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:51:30.874022  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5119
I0130 00:51:30.874045  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.55615 (* 1 = 1.55615 loss)
I0130 00:51:31.115898  7239 solver.cpp:218] Iteration 26800 (2.46551 iter/s, 40.5595s/100 iters), loss = 0.0148289
I0130 00:51:31.115926  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148294 (* 1 = 0.0148294 loss)
I0130 00:51:31.115934  7239 sgd_solver.cpp:105] Iteration 26800, lr = 0.02
I0130 00:51:54.039692  7239 solver.cpp:218] Iteration 26900 (4.36246 iter/s, 22.9228s/100 iters), loss = 0.0241376
I0130 00:51:54.039719  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241381 (* 1 = 0.0241381 loss)
I0130 00:51:54.039726  7239 sgd_solver.cpp:105] Iteration 26900, lr = 0.02
I0130 00:52:05.609010  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:52:17.832237  7239 solver.cpp:218] Iteration 27000 (4.20317 iter/s, 23.7916s/100 iters), loss = 0.0134927
I0130 00:52:17.832265  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134932 (* 1 = 0.0134932 loss)
I0130 00:52:17.832273  7239 sgd_solver.cpp:105] Iteration 27000, lr = 0.02
I0130 00:52:41.240466  7239 solver.cpp:218] Iteration 27100 (4.27218 iter/s, 23.4073s/100 iters), loss = 0.0063325
I0130 00:52:41.240535  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00633298 (* 1 = 0.00633298 loss)
I0130 00:52:41.240542  7239 sgd_solver.cpp:105] Iteration 27100, lr = 0.02
I0130 00:53:04.629325  7239 solver.cpp:330] Iteration 27200, Testing net (#0)
I0130 00:53:21.089516  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:53:21.426091  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5639
I0130 00:53:21.426117  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.48363 (* 1 = 1.48363 loss)
I0130 00:53:21.673807  7239 solver.cpp:218] Iteration 27200 (2.47331 iter/s, 40.4317s/100 iters), loss = 0.0245071
I0130 00:53:21.673830  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0245076 (* 1 = 0.0245076 loss)
I0130 00:53:21.673838  7239 sgd_solver.cpp:105] Iteration 27200, lr = 0.02
I0130 00:53:44.936216  7239 solver.cpp:218] Iteration 27300 (4.29896 iter/s, 23.2614s/100 iters), loss = 0.127469
I0130 00:53:44.936247  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127469 (* 1 = 0.127469 loss)
I0130 00:53:44.936254  7239 sgd_solver.cpp:105] Iteration 27300, lr = 0.02
I0130 00:53:54.010321  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:54:08.513234  7239 solver.cpp:218] Iteration 27400 (4.24174 iter/s, 23.5752s/100 iters), loss = 0.0739752
I0130 00:54:08.513262  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0739757 (* 1 = 0.0739757 loss)
I0130 00:54:08.513268  7239 sgd_solver.cpp:105] Iteration 27400, lr = 0.02
I0130 00:54:32.288162  7239 solver.cpp:218] Iteration 27500 (4.20655 iter/s, 23.7724s/100 iters), loss = 0.00782304
I0130 00:54:32.288228  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00782356 (* 1 = 0.00782356 loss)
I0130 00:54:32.288236  7239 sgd_solver.cpp:105] Iteration 27500, lr = 0.02
I0130 00:54:55.730031  7239 solver.cpp:330] Iteration 27600, Testing net (#0)
I0130 00:55:12.182838  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:55:12.519459  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6671
I0130 00:55:12.519484  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04946 (* 1 = 1.04946 loss)
I0130 00:55:12.761646  7239 solver.cpp:218] Iteration 27600 (2.47101 iter/s, 40.4693s/100 iters), loss = 0.0702426
I0130 00:55:12.761669  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0702431 (* 1 = 0.0702431 loss)
I0130 00:55:12.761682  7239 sgd_solver.cpp:105] Iteration 27600, lr = 0.02
I0130 00:55:35.830602  7239 solver.cpp:218] Iteration 27700 (4.33526 iter/s, 23.0667s/100 iters), loss = 0.140909
I0130 00:55:35.830628  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140909 (* 1 = 0.140909 loss)
I0130 00:55:35.830637  7239 sgd_solver.cpp:105] Iteration 27700, lr = 0.02
I0130 00:55:42.796856  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:55:59.287220  7239 solver.cpp:218] Iteration 27800 (4.2636 iter/s, 23.4543s/100 iters), loss = 0.0427594
I0130 00:55:59.287245  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0427599 (* 1 = 0.0427599 loss)
I0130 00:55:59.287252  7239 sgd_solver.cpp:105] Iteration 27800, lr = 0.02
I0130 00:56:22.792192  7239 solver.cpp:218] Iteration 27900 (4.25482 iter/s, 23.5027s/100 iters), loss = 0.0137095
I0130 00:56:22.792261  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01371 (* 1 = 0.01371 loss)
I0130 00:56:22.792270  7239 sgd_solver.cpp:105] Iteration 27900, lr = 0.02
I0130 00:56:46.052626  7239 solver.cpp:330] Iteration 28000, Testing net (#0)
I0130 00:57:02.825808  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:57:03.163177  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5483
I0130 00:57:03.163202  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.56858 (* 1 = 1.56858 loss)
I0130 00:57:03.409739  7239 solver.cpp:218] Iteration 28000 (2.46222 iter/s, 40.6138s/100 iters), loss = 0.0121191
I0130 00:57:03.409768  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121196 (* 1 = 0.0121196 loss)
I0130 00:57:03.409776  7239 sgd_solver.cpp:105] Iteration 28000, lr = 0.02
I0130 00:57:26.769124  7239 solver.cpp:218] Iteration 28100 (4.28132 iter/s, 23.3573s/100 iters), loss = 0.0360464
I0130 00:57:26.769153  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360468 (* 1 = 0.0360468 loss)
I0130 00:57:26.769160  7239 sgd_solver.cpp:105] Iteration 28100, lr = 0.02
I0130 00:57:31.725739  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:57:50.070520  7239 solver.cpp:218] Iteration 28200 (4.29197 iter/s, 23.2993s/100 iters), loss = 0.011773
I0130 00:57:50.070585  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117735 (* 1 = 0.0117735 loss)
I0130 00:57:50.070593  7239 sgd_solver.cpp:105] Iteration 28200, lr = 0.02
I0130 00:58:13.588723  7239 solver.cpp:218] Iteration 28300 (4.2524 iter/s, 23.5161s/100 iters), loss = 0.00255725
I0130 00:58:13.588750  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255768 (* 1 = 0.00255768 loss)
I0130 00:58:13.588758  7239 sgd_solver.cpp:105] Iteration 28300, lr = 0.02
I0130 00:58:37.015246  7239 solver.cpp:330] Iteration 28400, Testing net (#0)
I0130 00:58:53.534957  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:58:53.865401  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5784
I0130 00:58:53.865422  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.52254 (* 1 = 1.52254 loss)
I0130 00:58:54.109282  7239 solver.cpp:218] Iteration 28400 (2.46809 iter/s, 40.5171s/100 iters), loss = 0.00648244
I0130 00:58:54.109310  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00648287 (* 1 = 0.00648287 loss)
I0130 00:58:54.109318  7239 sgd_solver.cpp:105] Iteration 28400, lr = 0.02
I0130 00:59:17.410866  7239 solver.cpp:218] Iteration 28500 (4.29191 iter/s, 23.2996s/100 iters), loss = 0.00901654
I0130 00:59:17.410930  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00901695 (* 1 = 0.00901695 loss)
I0130 00:59:17.410939  7239 sgd_solver.cpp:105] Iteration 28500, lr = 0.02
I0130 00:59:19.954236  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 00:59:41.112431  7239 solver.cpp:218] Iteration 28600 (4.21948 iter/s, 23.6996s/100 iters), loss = 0.152721
I0130 00:59:41.112460  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152722 (* 1 = 0.152722 loss)
I0130 00:59:41.112466  7239 sgd_solver.cpp:105] Iteration 28600, lr = 0.02
I0130 01:00:04.706418  7239 solver.cpp:218] Iteration 28700 (4.23871 iter/s, 23.5921s/100 iters), loss = 0.0564243
I0130 01:00:04.706485  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0564246 (* 1 = 0.0564246 loss)
I0130 01:00:04.706495  7239 sgd_solver.cpp:105] Iteration 28700, lr = 0.02
I0130 01:00:27.740826  7239 solver.cpp:330] Iteration 28800, Testing net (#0)
I0130 01:00:44.687891  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:00:45.028074  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6632
I0130 01:00:45.028101  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.11052 (* 1 = 1.11052 loss)
I0130 01:00:45.275878  7239 solver.cpp:218] Iteration 28800 (2.4651 iter/s, 40.5663s/100 iters), loss = 0.0134331
I0130 01:00:45.275902  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134334 (* 1 = 0.0134334 loss)
I0130 01:00:45.275914  7239 sgd_solver.cpp:105] Iteration 28800, lr = 0.02
I0130 01:01:08.476030  7239 solver.cpp:218] Iteration 28900 (4.31065 iter/s, 23.1984s/100 iters), loss = 0.0210486
I0130 01:01:08.476058  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021049 (* 1 = 0.021049 loss)
I0130 01:01:08.476068  7239 sgd_solver.cpp:105] Iteration 28900, lr = 0.02
I0130 01:01:08.979104  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:01:31.984004  7239 solver.cpp:218] Iteration 29000 (4.2542 iter/s, 23.5062s/100 iters), loss = 0.0145014
I0130 01:01:31.984091  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145018 (* 1 = 0.0145018 loss)
I0130 01:01:31.984099  7239 sgd_solver.cpp:105] Iteration 29000, lr = 0.02
I0130 01:01:55.577467  7239 solver.cpp:218] Iteration 29100 (4.23879 iter/s, 23.5916s/100 iters), loss = 0.0765385
I0130 01:01:55.577494  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0765389 (* 1 = 0.0765389 loss)
I0130 01:01:55.577502  7239 sgd_solver.cpp:105] Iteration 29100, lr = 0.02
I0130 01:02:18.935402  7239 solver.cpp:330] Iteration 29200, Testing net (#0)
I0130 01:02:35.822844  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:02:36.157161  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7236
I0130 01:02:36.157184  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.970794 (* 1 = 0.970794 loss)
I0130 01:02:36.410171  7239 solver.cpp:218] Iteration 29200 (2.4492 iter/s, 40.8297s/100 iters), loss = 0.0183019
I0130 01:02:36.410194  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183023 (* 1 = 0.0183023 loss)
I0130 01:02:36.410208  7239 sgd_solver.cpp:105] Iteration 29200, lr = 0.02
I0130 01:02:57.622824  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:02:59.472568  7239 solver.cpp:218] Iteration 29300 (4.33638 iter/s, 23.0607s/100 iters), loss = 0.00578767
I0130 01:02:59.472602  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00578812 (* 1 = 0.00578812 loss)
I0130 01:02:59.472612  7239 sgd_solver.cpp:105] Iteration 29300, lr = 0.02
I0130 01:03:22.955759  7239 solver.cpp:218] Iteration 29400 (4.25867 iter/s, 23.4815s/100 iters), loss = 0.0146821
I0130 01:03:22.955796  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146825 (* 1 = 0.0146825 loss)
I0130 01:03:22.955806  7239 sgd_solver.cpp:105] Iteration 29400, lr = 0.02
I0130 01:03:46.444584  7239 solver.cpp:218] Iteration 29500 (4.25765 iter/s, 23.4872s/100 iters), loss = 0.0474782
I0130 01:03:46.444653  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474787 (* 1 = 0.0474787 loss)
I0130 01:03:46.444661  7239 sgd_solver.cpp:105] Iteration 29500, lr = 0.02
I0130 01:04:09.845854  7239 solver.cpp:330] Iteration 29600, Testing net (#0)
I0130 01:04:26.693245  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:04:27.030556  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8086
I0130 01:04:27.030580  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.61847 (* 1 = 0.61847 loss)
I0130 01:04:27.280174  7239 solver.cpp:218] Iteration 29600 (2.44902 iter/s, 40.8327s/100 iters), loss = 0.0334879
I0130 01:04:27.280198  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334883 (* 1 = 0.0334883 loss)
I0130 01:04:27.280210  7239 sgd_solver.cpp:105] Iteration 29600, lr = 0.02
I0130 01:04:46.574209  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:04:50.663110  7239 solver.cpp:218] Iteration 29700 (4.27692 iter/s, 23.3813s/100 iters), loss = 0.00584823
I0130 01:04:50.663137  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00584863 (* 1 = 0.00584863 loss)
I0130 01:04:50.663151  7239 sgd_solver.cpp:105] Iteration 29700, lr = 0.02
I0130 01:05:14.326819  7239 solver.cpp:218] Iteration 29800 (4.22617 iter/s, 23.6621s/100 iters), loss = 0.0246655
I0130 01:05:14.326890  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0246659 (* 1 = 0.0246659 loss)
I0130 01:05:14.326898  7239 sgd_solver.cpp:105] Iteration 29800, lr = 0.02
I0130 01:05:37.876632  7239 solver.cpp:218] Iteration 29900 (4.24661 iter/s, 23.5482s/100 iters), loss = 0.0121784
I0130 01:05:37.876659  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121788 (* 1 = 0.0121788 loss)
I0130 01:05:37.876667  7239 sgd_solver.cpp:105] Iteration 29900, lr = 0.02
I0130 01:06:01.015089  7239 solver.cpp:330] Iteration 30000, Testing net (#0)
I0130 01:06:17.840085  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:06:18.179484  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8179
I0130 01:06:18.179508  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.633354 (* 1 = 0.633354 loss)
I0130 01:06:18.422153  7239 solver.cpp:218] Iteration 30000 (2.46653 iter/s, 40.5429s/100 iters), loss = 0.00627049
I0130 01:06:18.422183  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00627079 (* 1 = 0.00627079 loss)
I0130 01:06:18.422190  7239 sgd_solver.cpp:105] Iteration 30000, lr = 0.02
I0130 01:06:35.839779  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:06:41.801571  7239 solver.cpp:218] Iteration 30100 (4.27755 iter/s, 23.3779s/100 iters), loss = 0.0301584
I0130 01:06:41.801599  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301588 (* 1 = 0.0301588 loss)
I0130 01:06:41.801605  7239 sgd_solver.cpp:105] Iteration 30100, lr = 0.02
I0130 01:07:05.040189  7239 solver.cpp:218] Iteration 30200 (4.30346 iter/s, 23.2371s/100 iters), loss = 0.050053
I0130 01:07:05.040215  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0500534 (* 1 = 0.0500534 loss)
I0130 01:07:05.040222  7239 sgd_solver.cpp:105] Iteration 30200, lr = 0.02
I0130 01:07:28.476231  7239 solver.cpp:218] Iteration 30300 (4.26721 iter/s, 23.4345s/100 iters), loss = 0.133568
I0130 01:07:28.477792  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133568 (* 1 = 0.133568 loss)
I0130 01:07:28.477800  7239 sgd_solver.cpp:105] Iteration 30300, lr = 0.02
I0130 01:07:51.486685  7239 solver.cpp:330] Iteration 30400, Testing net (#0)
I0130 01:08:08.304360  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:08:08.638209  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.833
I0130 01:08:08.638232  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.568856 (* 1 = 0.568856 loss)
I0130 01:08:08.883178  7239 solver.cpp:218] Iteration 30400 (2.47507 iter/s, 40.4029s/100 iters), loss = 0.0472987
I0130 01:08:08.883203  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.047299 (* 1 = 0.047299 loss)
I0130 01:08:08.883214  7239 sgd_solver.cpp:105] Iteration 30400, lr = 0.02
I0130 01:08:23.828572  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:08:32.168807  7239 solver.cpp:218] Iteration 30500 (4.29477 iter/s, 23.2842s/100 iters), loss = 0.0181993
I0130 01:08:32.168838  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181996 (* 1 = 0.0181996 loss)
I0130 01:08:32.168846  7239 sgd_solver.cpp:105] Iteration 30500, lr = 0.02
I0130 01:08:55.482038  7239 solver.cpp:218] Iteration 30600 (4.28968 iter/s, 23.3118s/100 iters), loss = 0.00815321
I0130 01:08:55.482107  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00815347 (* 1 = 0.00815347 loss)
I0130 01:08:55.482116  7239 sgd_solver.cpp:105] Iteration 30600, lr = 0.02
I0130 01:09:18.821933  7239 solver.cpp:218] Iteration 30700 (4.28478 iter/s, 23.3384s/100 iters), loss = 0.11399
I0130 01:09:18.821960  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113991 (* 1 = 0.113991 loss)
I0130 01:09:18.821967  7239 sgd_solver.cpp:105] Iteration 30700, lr = 0.02
I0130 01:09:42.349689  7239 solver.cpp:330] Iteration 30800, Testing net (#0)
I0130 01:09:58.810339  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:09:59.141924  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8902
I0130 01:09:59.141950  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358882 (* 1 = 0.358882 loss)
I0130 01:09:59.379830  7239 solver.cpp:218] Iteration 30800 (2.46576 iter/s, 40.5554s/100 iters), loss = 0.0102348
I0130 01:09:59.379855  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010235 (* 1 = 0.010235 loss)
I0130 01:09:59.379865  7239 sgd_solver.cpp:105] Iteration 30800, lr = 0.02
I0130 01:10:12.051172  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:10:22.400441  7239 solver.cpp:218] Iteration 30900 (4.3442 iter/s, 23.0192s/100 iters), loss = 0.0126517
I0130 01:10:22.400534  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012652 (* 1 = 0.012652 loss)
I0130 01:10:22.400542  7239 sgd_solver.cpp:105] Iteration 30900, lr = 0.02
I0130 01:10:46.169108  7239 solver.cpp:218] Iteration 31000 (4.20749 iter/s, 23.7672s/100 iters), loss = 0.00609485
I0130 01:10:46.169136  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00609516 (* 1 = 0.00609516 loss)
I0130 01:10:46.169143  7239 sgd_solver.cpp:105] Iteration 31000, lr = 0.02
I0130 01:11:09.589215  7239 solver.cpp:218] Iteration 31100 (4.27009 iter/s, 23.4187s/100 iters), loss = 0.191093
I0130 01:11:09.589284  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191094 (* 1 = 0.191094 loss)
I0130 01:11:09.589293  7239 sgd_solver.cpp:105] Iteration 31100, lr = 0.02
I0130 01:11:32.979038  7239 solver.cpp:330] Iteration 31200, Testing net (#0)
I0130 01:11:49.712106  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:11:50.049893  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8648
I0130 01:11:50.049916  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.45017 (* 1 = 0.45017 loss)
I0130 01:11:50.290230  7239 solver.cpp:218] Iteration 31200 (2.45709 iter/s, 40.6986s/100 iters), loss = 0.0483512
I0130 01:11:50.290253  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0483515 (* 1 = 0.0483515 loss)
I0130 01:11:50.290266  7239 sgd_solver.cpp:105] Iteration 31200, lr = 0.02
I0130 01:12:01.090804  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:12:13.557777  7239 solver.cpp:218] Iteration 31300 (4.29809 iter/s, 23.2662s/100 iters), loss = 0.0493164
I0130 01:12:13.557804  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0493167 (* 1 = 0.0493167 loss)
I0130 01:12:13.557816  7239 sgd_solver.cpp:105] Iteration 31300, lr = 0.02
I0130 01:12:37.248306  7239 solver.cpp:218] Iteration 31400 (4.22135 iter/s, 23.6891s/100 iters), loss = 0.0260383
I0130 01:12:37.248373  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260385 (* 1 = 0.0260385 loss)
I0130 01:12:37.248380  7239 sgd_solver.cpp:105] Iteration 31400, lr = 0.02
I0130 01:13:00.935962  7239 solver.cpp:218] Iteration 31500 (4.22186 iter/s, 23.6862s/100 iters), loss = 0.00951657
I0130 01:13:00.935989  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951681 (* 1 = 0.00951681 loss)
I0130 01:13:00.935998  7239 sgd_solver.cpp:105] Iteration 31500, lr = 0.02
I0130 01:13:24.397176  7239 solver.cpp:330] Iteration 31600, Testing net (#0)
I0130 01:13:40.885416  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:13:41.223201  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8676
I0130 01:13:41.223225  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.454636 (* 1 = 0.454636 loss)
I0130 01:13:41.471117  7239 solver.cpp:218] Iteration 31600 (2.46714 iter/s, 40.5328s/100 iters), loss = 0.144625
I0130 01:13:41.471139  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144625 (* 1 = 0.144625 loss)
I0130 01:13:41.471158  7239 sgd_solver.cpp:105] Iteration 31600, lr = 0.02
I0130 01:13:49.952360  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:14:04.694588  7239 solver.cpp:218] Iteration 31700 (4.30624 iter/s, 23.2221s/100 iters), loss = 0.0138602
I0130 01:14:04.694654  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138605 (* 1 = 0.0138605 loss)
I0130 01:14:04.694663  7239 sgd_solver.cpp:105] Iteration 31700, lr = 0.02
I0130 01:14:28.188563  7239 solver.cpp:218] Iteration 31800 (4.25666 iter/s, 23.4926s/100 iters), loss = 0.269884
I0130 01:14:28.188593  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269884 (* 1 = 0.269884 loss)
I0130 01:14:28.188603  7239 sgd_solver.cpp:105] Iteration 31800, lr = 0.02
I0130 01:14:51.845762  7239 solver.cpp:218] Iteration 31900 (4.22729 iter/s, 23.6558s/100 iters), loss = 0.0953288
I0130 01:14:51.845846  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0953291 (* 1 = 0.0953291 loss)
I0130 01:14:51.845855  7239 sgd_solver.cpp:105] Iteration 31900, lr = 0.02
I0130 01:15:14.990077  7239 solver.cpp:330] Iteration 32000, Testing net (#0)
I0130 01:15:31.788079  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:15:32.126597  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8645
I0130 01:15:32.126619  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.46981 (* 1 = 0.46981 loss)
I0130 01:15:32.369029  7239 solver.cpp:218] Iteration 32000 (2.46786 iter/s, 40.5209s/100 iters), loss = 0.0988765
I0130 01:15:32.369052  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0988767 (* 1 = 0.0988767 loss)
I0130 01:15:32.369067  7239 sgd_solver.cpp:105] Iteration 32000, lr = 0.02
I0130 01:15:38.591817  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:15:55.715390  7239 solver.cpp:218] Iteration 32100 (4.28357 iter/s, 23.345s/100 iters), loss = 0.0242798
I0130 01:15:55.715418  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02428 (* 1 = 0.02428 loss)
I0130 01:15:55.715426  7239 sgd_solver.cpp:105] Iteration 32100, lr = 0.02
I0130 01:16:19.128593  7239 solver.cpp:218] Iteration 32200 (4.27134 iter/s, 23.4119s/100 iters), loss = 0.0125635
I0130 01:16:19.128803  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125638 (* 1 = 0.0125638 loss)
I0130 01:16:19.128814  7239 sgd_solver.cpp:105] Iteration 32200, lr = 0.02
I0130 01:16:42.695550  7239 solver.cpp:218] Iteration 32300 (4.2435 iter/s, 23.5654s/100 iters), loss = 0.154865
I0130 01:16:42.695578  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154865 (* 1 = 0.154865 loss)
I0130 01:16:42.695587  7239 sgd_solver.cpp:105] Iteration 32300, lr = 0.02
I0130 01:17:06.257761  7239 solver.cpp:330] Iteration 32400, Testing net (#0)
I0130 01:17:22.944353  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:17:23.278259  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8793
I0130 01:17:23.278282  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.434594 (* 1 = 0.434594 loss)
I0130 01:17:23.520705  7239 solver.cpp:218] Iteration 32400 (2.44961 iter/s, 40.8229s/100 iters), loss = 0.108371
I0130 01:17:23.520731  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108371 (* 1 = 0.108371 loss)
I0130 01:17:23.520740  7239 sgd_solver.cpp:105] Iteration 32400, lr = 0.02
I0130 01:17:27.552752  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:17:46.699067  7239 solver.cpp:218] Iteration 32500 (4.31461 iter/s, 23.1771s/100 iters), loss = 0.00217581
I0130 01:17:46.699141  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217609 (* 1 = 0.00217609 loss)
I0130 01:17:46.699151  7239 sgd_solver.cpp:105] Iteration 32500, lr = 0.02
I0130 01:18:10.130851  7239 solver.cpp:218] Iteration 32600 (4.26796 iter/s, 23.4304s/100 iters), loss = 0.0489919
I0130 01:18:10.130882  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0489921 (* 1 = 0.0489921 loss)
I0130 01:18:10.130892  7239 sgd_solver.cpp:105] Iteration 32600, lr = 0.02
I0130 01:18:33.467288  7239 solver.cpp:218] Iteration 32700 (4.28538 iter/s, 23.3351s/100 iters), loss = 0.0717405
I0130 01:18:33.467355  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0717407 (* 1 = 0.0717407 loss)
I0130 01:18:33.467363  7239 sgd_solver.cpp:105] Iteration 32700, lr = 0.02
I0130 01:18:57.070449  7239 solver.cpp:330] Iteration 32800, Testing net (#0)
I0130 01:19:13.696422  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:19:14.032922  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8756
I0130 01:19:14.032945  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.454536 (* 1 = 0.454536 loss)
I0130 01:19:14.274186  7239 solver.cpp:218] Iteration 32800 (2.4507 iter/s, 40.8046s/100 iters), loss = 0.00995174
I0130 01:19:14.274214  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00995207 (* 1 = 0.00995207 loss)
I0130 01:19:14.274224  7239 sgd_solver.cpp:105] Iteration 32800, lr = 0.02
I0130 01:19:16.141911  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:19:37.666709  7239 solver.cpp:218] Iteration 32900 (4.27511 iter/s, 23.3912s/100 iters), loss = 0.0388469
I0130 01:19:37.666739  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0388472 (* 1 = 0.0388472 loss)
I0130 01:19:37.666746  7239 sgd_solver.cpp:105] Iteration 32900, lr = 0.02
I0130 01:20:01.063704  7239 solver.cpp:218] Iteration 33000 (4.27429 iter/s, 23.3957s/100 iters), loss = 0.0213127
I0130 01:20:01.063781  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021313 (* 1 = 0.021313 loss)
I0130 01:20:01.063791  7239 sgd_solver.cpp:105] Iteration 33000, lr = 0.02
I0130 01:20:24.500567  7239 solver.cpp:218] Iteration 33100 (4.26703 iter/s, 23.4355s/100 iters), loss = 0.117555
I0130 01:20:24.500593  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117555 (* 1 = 0.117555 loss)
I0130 01:20:24.500602  7239 sgd_solver.cpp:105] Iteration 33100, lr = 0.02
I0130 01:20:48.063271  7239 solver.cpp:330] Iteration 33200, Testing net (#0)
I0130 01:21:04.498112  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:21:04.835536  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8917
I0130 01:21:04.835561  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36428 (* 1 = 0.36428 loss)
I0130 01:21:04.836653  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:21:05.077421  7239 solver.cpp:218] Iteration 33200 (2.46459 iter/s, 40.5746s/100 iters), loss = 0.0517839
I0130 01:21:05.077446  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0517843 (* 1 = 0.0517843 loss)
I0130 01:21:05.077458  7239 sgd_solver.cpp:105] Iteration 33200, lr = 0.02
I0130 01:21:28.315652  7239 solver.cpp:218] Iteration 33300 (4.30349 iter/s, 23.2369s/100 iters), loss = 0.0405437
I0130 01:21:28.315722  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040544 (* 1 = 0.040544 loss)
I0130 01:21:28.315734  7239 sgd_solver.cpp:105] Iteration 33300, lr = 0.02
I0130 01:21:51.516631  7239 solver.cpp:218] Iteration 33400 (4.31041 iter/s, 23.1997s/100 iters), loss = 0.0913983
I0130 01:21:51.516661  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0913986 (* 1 = 0.0913986 loss)
I0130 01:21:51.516669  7239 sgd_solver.cpp:105] Iteration 33400, lr = 0.02
I0130 01:22:14.905400  7239 solver.cpp:218] Iteration 33500 (4.27579 iter/s, 23.3875s/100 iters), loss = 0.0364716
I0130 01:22:14.905799  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364719 (* 1 = 0.0364719 loss)
I0130 01:22:14.905808  7239 sgd_solver.cpp:105] Iteration 33500, lr = 0.02
I0130 01:22:36.134348  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:22:38.566109  7239 solver.cpp:330] Iteration 33600, Testing net (#0)
I0130 01:22:55.238222  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:22:55.572623  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8979
I0130 01:22:55.572649  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345081 (* 1 = 0.345081 loss)
I0130 01:22:55.815371  7239 solver.cpp:218] Iteration 33600 (2.44455 iter/s, 40.9074s/100 iters), loss = 0.115031
I0130 01:22:55.815398  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115031 (* 1 = 0.115031 loss)
I0130 01:22:55.815407  7239 sgd_solver.cpp:105] Iteration 33600, lr = 0.02
I0130 01:23:18.883069  7239 solver.cpp:218] Iteration 33700 (4.3353 iter/s, 23.0664s/100 iters), loss = 0.0960529
I0130 01:23:18.883096  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0960532 (* 1 = 0.0960532 loss)
I0130 01:23:18.883107  7239 sgd_solver.cpp:105] Iteration 33700, lr = 0.02
I0130 01:23:42.333024  7239 solver.cpp:218] Iteration 33800 (4.26463 iter/s, 23.4487s/100 iters), loss = 0.0612411
I0130 01:23:42.333119  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0612414 (* 1 = 0.0612414 loss)
I0130 01:23:42.333130  7239 sgd_solver.cpp:105] Iteration 33800, lr = 0.02
I0130 01:24:05.746145  7239 solver.cpp:218] Iteration 33900 (4.27135 iter/s, 23.4118s/100 iters), loss = 0.0038819
I0130 01:24:05.746171  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388226 (* 1 = 0.00388226 loss)
I0130 01:24:05.746181  7239 sgd_solver.cpp:105] Iteration 33900, lr = 0.02
I0130 01:24:24.326839  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:24:28.783557  7239 solver.cpp:330] Iteration 34000, Testing net (#0)
I0130 01:24:45.671442  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:24:46.012203  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9078
I0130 01:24:46.012225  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332849 (* 1 = 0.332849 loss)
I0130 01:24:46.251889  7239 solver.cpp:218] Iteration 34000 (2.46892 iter/s, 40.5036s/100 iters), loss = 0.124279
I0130 01:24:46.251911  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12428 (* 1 = 0.12428 loss)
I0130 01:24:46.251922  7239 sgd_solver.cpp:105] Iteration 34000, lr = 0.02
I0130 01:25:09.578917  7239 solver.cpp:218] Iteration 34100 (4.28711 iter/s, 23.3258s/100 iters), loss = 0.00667553
I0130 01:25:09.578991  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00667586 (* 1 = 0.00667586 loss)
I0130 01:25:09.579000  7239 sgd_solver.cpp:105] Iteration 34100, lr = 0.02
I0130 01:25:32.828199  7239 solver.cpp:218] Iteration 34200 (4.30145 iter/s, 23.248s/100 iters), loss = 0.010396
I0130 01:25:32.828228  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103963 (* 1 = 0.0103963 loss)
I0130 01:25:32.828236  7239 sgd_solver.cpp:105] Iteration 34200, lr = 0.02
I0130 01:25:56.340183  7239 solver.cpp:218] Iteration 34300 (4.25338 iter/s, 23.5107s/100 iters), loss = 0.0174269
I0130 01:25:56.340791  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174272 (* 1 = 0.0174272 loss)
I0130 01:25:56.340800  7239 sgd_solver.cpp:105] Iteration 34300, lr = 0.02
I0130 01:26:12.809674  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:26:19.521117  7239 solver.cpp:330] Iteration 34400, Testing net (#0)
I0130 01:26:36.242077  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:26:36.581199  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8993
I0130 01:26:36.581225  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348653 (* 1 = 0.348653 loss)
I0130 01:26:36.829879  7239 solver.cpp:218] Iteration 34400 (2.46993 iter/s, 40.4869s/100 iters), loss = 0.150169
I0130 01:26:36.829903  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150169 (* 1 = 0.150169 loss)
I0130 01:26:36.829915  7239 sgd_solver.cpp:105] Iteration 34400, lr = 0.02
I0130 01:26:59.949004  7239 solver.cpp:218] Iteration 34500 (4.32566 iter/s, 23.1179s/100 iters), loss = 0.025771
I0130 01:26:59.949033  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257713 (* 1 = 0.0257713 loss)
I0130 01:26:59.949040  7239 sgd_solver.cpp:105] Iteration 34500, lr = 0.02
I0130 01:27:23.605845  7239 solver.cpp:218] Iteration 34600 (4.22734 iter/s, 23.6556s/100 iters), loss = 0.00426349
I0130 01:27:23.606528  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00426385 (* 1 = 0.00426385 loss)
I0130 01:27:23.606537  7239 sgd_solver.cpp:105] Iteration 34600, lr = 0.02
I0130 01:27:46.969045  7239 solver.cpp:218] Iteration 34700 (4.28059 iter/s, 23.3613s/100 iters), loss = 0.0929621
I0130 01:27:46.969074  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0929624 (* 1 = 0.0929624 loss)
I0130 01:27:46.969081  7239 sgd_solver.cpp:105] Iteration 34700, lr = 0.02
I0130 01:28:01.504273  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:28:10.302480  7239 solver.cpp:330] Iteration 34800, Testing net (#0)
I0130 01:28:27.005409  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:28:27.347692  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I0130 01:28:27.347717  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33762 (* 1 = 0.33762 loss)
I0130 01:28:27.589608  7239 solver.cpp:218] Iteration 34800 (2.46194 iter/s, 40.6184s/100 iters), loss = 0.0376887
I0130 01:28:27.589630  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.037689 (* 1 = 0.037689 loss)
I0130 01:28:27.589646  7239 sgd_solver.cpp:105] Iteration 34800, lr = 0.02
I0130 01:28:50.787922  7239 solver.cpp:218] Iteration 34900 (4.31088 iter/s, 23.1971s/100 iters), loss = 0.0105778
I0130 01:28:50.788709  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105782 (* 1 = 0.0105782 loss)
I0130 01:28:50.788718  7239 sgd_solver.cpp:105] Iteration 34900, lr = 0.02
I0130 01:29:14.088991  7239 solver.cpp:218] Iteration 35000 (4.292 iter/s, 23.2992s/100 iters), loss = 0.185308
I0130 01:29:14.089020  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185308 (* 1 = 0.185308 loss)
I0130 01:29:14.089030  7239 sgd_solver.cpp:105] Iteration 35000, lr = 0.02
I0130 01:29:37.806221  7239 solver.cpp:218] Iteration 35100 (4.21655 iter/s, 23.7161s/100 iters), loss = 0.0224198
I0130 01:29:37.806287  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224202 (* 1 = 0.0224202 loss)
I0130 01:29:37.806295  7239 sgd_solver.cpp:105] Iteration 35100, lr = 0.02
I0130 01:29:49.961745  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:30:00.923452  7239 solver.cpp:330] Iteration 35200, Testing net (#0)
I0130 01:30:17.606940  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:30:17.951594  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I0130 01:30:17.951617  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305429 (* 1 = 0.305429 loss)
I0130 01:30:18.197023  7239 solver.cpp:218] Iteration 35200 (2.47593 iter/s, 40.3888s/100 iters), loss = 0.0362395
I0130 01:30:18.197046  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0362399 (* 1 = 0.0362399 loss)
I0130 01:30:18.197062  7239 sgd_solver.cpp:105] Iteration 35200, lr = 0.02
I0130 01:30:41.449079  7239 solver.cpp:218] Iteration 35300 (4.30091 iter/s, 23.2509s/100 iters), loss = 0.0624923
I0130 01:30:41.449110  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0624927 (* 1 = 0.0624927 loss)
I0130 01:30:41.449121  7239 sgd_solver.cpp:105] Iteration 35300, lr = 0.02
I0130 01:31:04.891021  7239 solver.cpp:218] Iteration 35400 (4.26607 iter/s, 23.4408s/100 iters), loss = 0.0186014
I0130 01:31:04.891085  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186018 (* 1 = 0.0186018 loss)
I0130 01:31:04.891093  7239 sgd_solver.cpp:105] Iteration 35400, lr = 0.02
I0130 01:31:28.620893  7239 solver.cpp:218] Iteration 35500 (4.21431 iter/s, 23.7287s/100 iters), loss = 0.126002
I0130 01:31:28.620919  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126003 (* 1 = 0.126003 loss)
I0130 01:31:28.620926  7239 sgd_solver.cpp:105] Iteration 35500, lr = 0.02
I0130 01:31:38.420331  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:31:51.884104  7239 solver.cpp:330] Iteration 35600, Testing net (#0)
I0130 01:32:08.400395  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:32:08.739645  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8631
I0130 01:32:08.739702  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.481964 (* 1 = 0.481964 loss)
I0130 01:32:08.985515  7239 solver.cpp:218] Iteration 35600 (2.47754 iter/s, 40.3626s/100 iters), loss = 0.0550285
I0130 01:32:08.985538  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0550289 (* 1 = 0.0550289 loss)
I0130 01:32:08.985553  7239 sgd_solver.cpp:105] Iteration 35600, lr = 0.02
I0130 01:32:31.914535  7239 solver.cpp:218] Iteration 35700 (4.3615 iter/s, 22.9279s/100 iters), loss = 0.0284744
I0130 01:32:31.914563  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284748 (* 1 = 0.0284748 loss)
I0130 01:32:31.914572  7239 sgd_solver.cpp:105] Iteration 35700, lr = 0.02
I0130 01:32:55.969103  7239 solver.cpp:218] Iteration 35800 (4.15742 iter/s, 24.0534s/100 iters), loss = 0.0323416
I0130 01:32:55.969197  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032342 (* 1 = 0.032342 loss)
I0130 01:32:55.969209  7239 sgd_solver.cpp:105] Iteration 35800, lr = 0.02
I0130 01:33:19.511473  7239 solver.cpp:218] Iteration 35900 (4.24788 iter/s, 23.5411s/100 iters), loss = 0.0114403
I0130 01:33:19.511502  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114407 (* 1 = 0.0114407 loss)
I0130 01:33:19.511510  7239 sgd_solver.cpp:105] Iteration 35900, lr = 0.02
I0130 01:33:27.285128  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:33:42.774461  7239 solver.cpp:447] Snapshotting to binary proto file examples/bao/WRN-28_iter_36000.caffemodel
I0130 01:33:43.113539  7239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/bao/WRN-28_iter_36000.solverstate
I0130 01:33:43.310649  7239 solver.cpp:330] Iteration 36000, Testing net (#0)
I0130 01:34:00.068321  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:34:00.403311  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8269
I0130 01:34:00.403337  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.641315 (* 1 = 0.641315 loss)
I0130 01:34:00.646009  7239 solver.cpp:218] Iteration 36000 (2.43117 iter/s, 41.1325s/100 iters), loss = 0.0440036
I0130 01:34:00.646033  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440039 (* 1 = 0.0440039 loss)
I0130 01:34:00.646047  7239 sgd_solver.cpp:105] Iteration 36000, lr = 0.02
I0130 01:34:23.796228  7239 solver.cpp:218] Iteration 36100 (4.31983 iter/s, 23.1491s/100 iters), loss = 0.0262596
I0130 01:34:23.796255  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02626 (* 1 = 0.02626 loss)
I0130 01:34:23.796264  7239 sgd_solver.cpp:105] Iteration 36100, lr = 0.02
I0130 01:34:47.428093  7239 solver.cpp:218] Iteration 36200 (4.23179 iter/s, 23.6307s/100 iters), loss = 0.109246
I0130 01:34:47.429399  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109246 (* 1 = 0.109246 loss)
I0130 01:34:47.429406  7239 sgd_solver.cpp:105] Iteration 36200, lr = 0.02
I0130 01:35:10.866557  7239 solver.cpp:218] Iteration 36300 (4.26694 iter/s, 23.436s/100 iters), loss = 0.0303744
I0130 01:35:10.866585  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303748 (* 1 = 0.0303748 loss)
I0130 01:35:10.866591  7239 sgd_solver.cpp:105] Iteration 36300, lr = 0.02
I0130 01:35:16.562124  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:35:34.390383  7239 solver.cpp:330] Iteration 36400, Testing net (#0)
I0130 01:35:51.045655  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:35:51.376526  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8923
I0130 01:35:51.376549  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381272 (* 1 = 0.381272 loss)
I0130 01:35:51.619761  7239 solver.cpp:218] Iteration 36400 (2.45392 iter/s, 40.7512s/100 iters), loss = 0.0404346
I0130 01:35:51.619783  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040435 (* 1 = 0.040435 loss)
I0130 01:35:51.619798  7239 sgd_solver.cpp:105] Iteration 36400, lr = 0.02
I0130 01:36:14.664201  7239 solver.cpp:218] Iteration 36500 (4.33966 iter/s, 23.0433s/100 iters), loss = 0.0168244
I0130 01:36:14.665220  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168248 (* 1 = 0.0168248 loss)
I0130 01:36:14.665231  7239 sgd_solver.cpp:105] Iteration 36500, lr = 0.02
I0130 01:36:38.322665  7239 solver.cpp:218] Iteration 36600 (4.22721 iter/s, 23.6563s/100 iters), loss = 0.00520556
I0130 01:36:38.322695  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520598 (* 1 = 0.00520598 loss)
I0130 01:36:38.322702  7239 sgd_solver.cpp:105] Iteration 36600, lr = 0.02
I0130 01:37:02.197089  7239 solver.cpp:218] Iteration 36700 (4.1888 iter/s, 23.8732s/100 iters), loss = 0.0298184
I0130 01:37:02.197161  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298188 (* 1 = 0.0298188 loss)
I0130 01:37:02.197170  7239 sgd_solver.cpp:105] Iteration 36700, lr = 0.02
I0130 01:37:05.531644  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:37:25.562881  7239 solver.cpp:330] Iteration 36800, Testing net (#0)
I0130 01:37:42.151500  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:37:42.499487  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.906
I0130 01:37:42.499511  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330285 (* 1 = 0.330285 loss)
I0130 01:37:42.741752  7239 solver.cpp:218] Iteration 36800 (2.46654 iter/s, 40.5426s/100 iters), loss = 0.00660522
I0130 01:37:42.741775  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00660564 (* 1 = 0.00660564 loss)
I0130 01:37:42.741792  7239 sgd_solver.cpp:105] Iteration 36800, lr = 0.02
I0130 01:38:05.954339  7239 solver.cpp:218] Iteration 36900 (4.30823 iter/s, 23.2114s/100 iters), loss = 0.00737497
I0130 01:38:05.954367  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00737541 (* 1 = 0.00737541 loss)
I0130 01:38:05.954375  7239 sgd_solver.cpp:105] Iteration 36900, lr = 0.02
I0130 01:38:29.195196  7239 solver.cpp:218] Iteration 37000 (4.30299 iter/s, 23.2397s/100 iters), loss = 0.135056
I0130 01:38:29.195266  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135057 (* 1 = 0.135057 loss)
I0130 01:38:29.195274  7239 sgd_solver.cpp:105] Iteration 37000, lr = 0.02
I0130 01:38:52.988904  7239 solver.cpp:218] Iteration 37100 (4.20301 iter/s, 23.7925s/100 iters), loss = 0.0321878
I0130 01:38:52.988934  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321883 (* 1 = 0.0321883 loss)
I0130 01:38:52.988942  7239 sgd_solver.cpp:105] Iteration 37100, lr = 0.02
I0130 01:38:54.191772  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:39:16.324668  7239 solver.cpp:330] Iteration 37200, Testing net (#0)
I0130 01:39:33.107440  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:39:33.455329  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.895
I0130 01:39:33.455353  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35576 (* 1 = 0.35576 loss)
I0130 01:39:33.699898  7239 solver.cpp:218] Iteration 37200 (2.45646 iter/s, 40.7089s/100 iters), loss = 0.0238395
I0130 01:39:33.699921  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02384 (* 1 = 0.02384 loss)
I0130 01:39:33.699935  7239 sgd_solver.cpp:105] Iteration 37200, lr = 0.02
I0130 01:39:57.044795  7239 solver.cpp:218] Iteration 37300 (4.28381 iter/s, 23.3437s/100 iters), loss = 0.124842
I0130 01:39:57.044862  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124843 (* 1 = 0.124843 loss)
I0130 01:39:57.044870  7239 sgd_solver.cpp:105] Iteration 37300, lr = 0.02
I0130 01:40:20.383409  7239 solver.cpp:218] Iteration 37400 (4.28497 iter/s, 23.3374s/100 iters), loss = 0.0259956
I0130 01:40:20.383437  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025996 (* 1 = 0.025996 loss)
I0130 01:40:20.383446  7239 sgd_solver.cpp:105] Iteration 37400, lr = 0.02
I0130 01:40:43.074859  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:40:44.036739  7239 solver.cpp:218] Iteration 37500 (4.22795 iter/s, 23.6521s/100 iters), loss = 0.00820108
I0130 01:40:44.036767  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00820145 (* 1 = 0.00820145 loss)
I0130 01:40:44.036773  7239 sgd_solver.cpp:105] Iteration 37500, lr = 0.02
I0130 01:41:07.534083  7239 solver.cpp:330] Iteration 37600, Testing net (#0)
I0130 01:41:24.157260  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:41:24.499429  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8743
I0130 01:41:24.499456  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.47434 (* 1 = 0.47434 loss)
I0130 01:41:24.742514  7239 solver.cpp:218] Iteration 37600 (2.45678 iter/s, 40.7037s/100 iters), loss = 0.0520894
I0130 01:41:24.742539  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0520897 (* 1 = 0.0520897 loss)
I0130 01:41:24.742552  7239 sgd_solver.cpp:105] Iteration 37600, lr = 0.02
I0130 01:41:48.092840  7239 solver.cpp:218] Iteration 37700 (4.28282 iter/s, 23.3491s/100 iters), loss = 0.137043
I0130 01:41:48.092869  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137043 (* 1 = 0.137043 loss)
I0130 01:41:48.092876  7239 sgd_solver.cpp:105] Iteration 37700, lr = 0.02
I0130 01:42:11.504163  7239 solver.cpp:218] Iteration 37800 (4.27166 iter/s, 23.4101s/100 iters), loss = 0.0547148
I0130 01:42:11.504557  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0547152 (* 1 = 0.0547152 loss)
I0130 01:42:11.504566  7239 sgd_solver.cpp:105] Iteration 37800, lr = 0.02
I0130 01:42:31.635191  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:42:34.885118  7239 solver.cpp:218] Iteration 37900 (4.27727 iter/s, 23.3794s/100 iters), loss = 0.0848464
I0130 01:42:34.885145  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0848468 (* 1 = 0.0848468 loss)
I0130 01:42:34.885154  7239 sgd_solver.cpp:105] Iteration 37900, lr = 0.02
I0130 01:42:58.341516  7239 solver.cpp:330] Iteration 38000, Testing net (#0)
I0130 01:43:14.922809  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:43:15.260632  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8715
I0130 01:43:15.260658  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.486732 (* 1 = 0.486732 loss)
I0130 01:43:15.506813  7239 solver.cpp:218] Iteration 38000 (2.46186 iter/s, 40.6196s/100 iters), loss = 0.0104399
I0130 01:43:15.506839  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104403 (* 1 = 0.0104403 loss)
I0130 01:43:15.506849  7239 sgd_solver.cpp:105] Iteration 38000, lr = 0.02
I0130 01:43:38.495910  7239 solver.cpp:218] Iteration 38100 (4.35011 iter/s, 22.9879s/100 iters), loss = 0.0307196
I0130 01:43:38.497609  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307199 (* 1 = 0.0307199 loss)
I0130 01:43:38.497617  7239 sgd_solver.cpp:105] Iteration 38100, lr = 0.02
I0130 01:44:02.186246  7239 solver.cpp:218] Iteration 38200 (4.22165 iter/s, 23.6874s/100 iters), loss = 0.0175493
I0130 01:44:02.186273  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175496 (* 1 = 0.0175496 loss)
I0130 01:44:02.186282  7239 sgd_solver.cpp:105] Iteration 38200, lr = 0.02
I0130 01:44:20.070178  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:44:25.482343  7239 solver.cpp:218] Iteration 38300 (4.29279 iter/s, 23.2949s/100 iters), loss = 0.0393809
I0130 01:44:25.482368  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393813 (* 1 = 0.0393813 loss)
I0130 01:44:25.482376  7239 sgd_solver.cpp:105] Iteration 38300, lr = 0.02
I0130 01:44:48.955797  7239 solver.cpp:330] Iteration 38400, Testing net (#0)
I0130 01:45:05.551295  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:45:05.886701  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8976
I0130 01:45:05.886728  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360032 (* 1 = 0.360032 loss)
I0130 01:45:06.128789  7239 solver.cpp:218] Iteration 38400 (2.46037 iter/s, 40.6444s/100 iters), loss = 0.139645
I0130 01:45:06.128816  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139646 (* 1 = 0.139646 loss)
I0130 01:45:06.128831  7239 sgd_solver.cpp:105] Iteration 38400, lr = 0.02
I0130 01:45:29.287596  7239 solver.cpp:218] Iteration 38500 (4.31824 iter/s, 23.1576s/100 iters), loss = 0.023641
I0130 01:45:29.287626  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236413 (* 1 = 0.0236413 loss)
I0130 01:45:29.287637  7239 sgd_solver.cpp:105] Iteration 38500, lr = 0.02
I0130 01:45:52.806617  7239 solver.cpp:218] Iteration 38600 (4.2521 iter/s, 23.5178s/100 iters), loss = 0.0528395
I0130 01:45:52.806706  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0528398 (* 1 = 0.0528398 loss)
I0130 01:45:52.806715  7239 sgd_solver.cpp:105] Iteration 38600, lr = 0.02
I0130 01:46:08.835650  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:46:16.461937  7239 solver.cpp:218] Iteration 38700 (4.22761 iter/s, 23.654s/100 iters), loss = 0.105674
I0130 01:46:16.461966  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105674 (* 1 = 0.105674 loss)
I0130 01:46:16.461972  7239 sgd_solver.cpp:105] Iteration 38700, lr = 0.02
I0130 01:46:39.705626  7239 solver.cpp:330] Iteration 38800, Testing net (#0)
I0130 01:46:56.448905  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:46:56.775926  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8996
I0130 01:46:56.775950  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345847 (* 1 = 0.345847 loss)
I0130 01:46:57.021615  7239 solver.cpp:218] Iteration 38800 (2.46563 iter/s, 40.5576s/100 iters), loss = 0.0404593
I0130 01:46:57.021642  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404597 (* 1 = 0.0404597 loss)
I0130 01:46:57.021652  7239 sgd_solver.cpp:105] Iteration 38800, lr = 0.02
I0130 01:47:20.200620  7239 solver.cpp:218] Iteration 38900 (4.31447 iter/s, 23.1778s/100 iters), loss = 0.00416162
I0130 01:47:20.201751  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416198 (* 1 = 0.00416198 loss)
I0130 01:47:20.201764  7239 sgd_solver.cpp:105] Iteration 38900, lr = 0.02
I0130 01:47:43.887264  7239 solver.cpp:218] Iteration 39000 (4.2222 iter/s, 23.6843s/100 iters), loss = 0.0695429
I0130 01:47:43.887292  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0695432 (* 1 = 0.0695432 loss)
I0130 01:47:43.887302  7239 sgd_solver.cpp:105] Iteration 39000, lr = 0.02
I0130 01:47:57.458070  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:48:07.515794  7239 solver.cpp:218] Iteration 39100 (4.23239 iter/s, 23.6273s/100 iters), loss = 0.0155606
I0130 01:48:07.515821  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015561 (* 1 = 0.015561 loss)
I0130 01:48:07.515830  7239 sgd_solver.cpp:105] Iteration 39100, lr = 0.02
I0130 01:48:31.137959  7239 solver.cpp:330] Iteration 39200, Testing net (#0)
I0130 01:48:47.841547  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:48:48.182654  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8843
I0130 01:48:48.182677  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.392293 (* 1 = 0.392293 loss)
I0130 01:48:48.427341  7239 solver.cpp:218] Iteration 39200 (2.44442 iter/s, 40.9094s/100 iters), loss = 0.00415607
I0130 01:48:48.427366  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415642 (* 1 = 0.00415642 loss)
I0130 01:48:48.427374  7239 sgd_solver.cpp:105] Iteration 39200, lr = 0.02
I0130 01:49:11.556886  7239 solver.cpp:218] Iteration 39300 (4.3237 iter/s, 23.1283s/100 iters), loss = 0.0324562
I0130 01:49:11.556949  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324566 (* 1 = 0.0324566 loss)
I0130 01:49:11.556958  7239 sgd_solver.cpp:105] Iteration 39300, lr = 0.02
I0130 01:49:35.099359  7239 solver.cpp:218] Iteration 39400 (4.24787 iter/s, 23.5412s/100 iters), loss = 0.0135905
I0130 01:49:35.099387  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135908 (* 1 = 0.0135908 loss)
I0130 01:49:35.099395  7239 sgd_solver.cpp:105] Iteration 39400, lr = 0.02
I0130 01:49:46.644034  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:49:58.862246  7239 solver.cpp:218] Iteration 39500 (4.20846 iter/s, 23.7617s/100 iters), loss = 0.445093
I0130 01:49:58.862274  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445094 (* 1 = 0.445094 loss)
I0130 01:49:58.862282  7239 sgd_solver.cpp:105] Iteration 39500, lr = 0.02
I0130 01:50:22.365360  7239 solver.cpp:330] Iteration 39600, Testing net (#0)
I0130 01:50:39.044558  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:50:39.383020  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9058
I0130 01:50:39.383044  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326526 (* 1 = 0.326526 loss)
I0130 01:50:39.633471  7239 solver.cpp:218] Iteration 39600 (2.45284 iter/s, 40.7691s/100 iters), loss = 0.00398464
I0130 01:50:39.633500  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398496 (* 1 = 0.00398496 loss)
I0130 01:50:39.633507  7239 sgd_solver.cpp:105] Iteration 39600, lr = 0.02
I0130 01:51:02.599732  7239 solver.cpp:218] Iteration 39700 (4.35444 iter/s, 22.9651s/100 iters), loss = 0.0502194
I0130 01:51:02.600054  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0502197 (* 1 = 0.0502197 loss)
I0130 01:51:02.600062  7239 sgd_solver.cpp:105] Iteration 39700, lr = 0.02
I0130 01:51:26.039961  7239 solver.cpp:218] Iteration 39800 (4.26644 iter/s, 23.4387s/100 iters), loss = 0.0633087
I0130 01:51:26.039988  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.063309 (* 1 = 0.063309 loss)
I0130 01:51:26.039996  7239 sgd_solver.cpp:105] Iteration 39800, lr = 0.02
I0130 01:51:35.102850  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:51:49.483441  7239 solver.cpp:218] Iteration 39900 (4.2658 iter/s, 23.4423s/100 iters), loss = 0.0759019
I0130 01:51:49.483470  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0759022 (* 1 = 0.0759022 loss)
I0130 01:51:49.483479  7239 sgd_solver.cpp:105] Iteration 39900, lr = 0.02
I0130 01:52:12.579033  7239 solver.cpp:330] Iteration 40000, Testing net (#0)
I0130 01:52:29.373667  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:52:29.719555  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8912
I0130 01:52:29.719581  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383107 (* 1 = 0.383107 loss)
I0130 01:52:29.966718  7239 solver.cpp:218] Iteration 40000 (2.47028 iter/s, 40.4812s/100 iters), loss = 0.0774085
I0130 01:52:29.966744  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0774089 (* 1 = 0.0774089 loss)
I0130 01:52:29.966755  7239 sgd_solver.cpp:105] Iteration 40000, lr = 0.02
I0130 01:52:53.238227  7239 solver.cpp:218] Iteration 40100 (4.29732 iter/s, 23.2703s/100 iters), loss = 0.0338125
I0130 01:52:53.238296  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338129 (* 1 = 0.0338129 loss)
I0130 01:52:53.238306  7239 sgd_solver.cpp:105] Iteration 40100, lr = 0.02
I0130 01:53:16.575063  7239 solver.cpp:218] Iteration 40200 (4.2853 iter/s, 23.3356s/100 iters), loss = 0.117753
I0130 01:53:16.575093  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117753 (* 1 = 0.117753 loss)
I0130 01:53:16.575100  7239 sgd_solver.cpp:105] Iteration 40200, lr = 0.02
I0130 01:53:23.524315  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:53:39.989697  7239 solver.cpp:218] Iteration 40300 (4.27106 iter/s, 23.4134s/100 iters), loss = 0.0114
I0130 01:53:39.989725  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114003 (* 1 = 0.0114003 loss)
I0130 01:53:39.989732  7239 sgd_solver.cpp:105] Iteration 40300, lr = 0.02
I0130 01:54:03.569339  7239 solver.cpp:330] Iteration 40400, Testing net (#0)
I0130 01:54:20.031318  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:54:20.361541  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8708
I0130 01:54:20.361564  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.483906 (* 1 = 0.483906 loss)
I0130 01:54:20.603536  7239 solver.cpp:218] Iteration 40400 (2.46234 iter/s, 40.6117s/100 iters), loss = 0.0833153
I0130 01:54:20.603559  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0833156 (* 1 = 0.0833156 loss)
I0130 01:54:20.603571  7239 sgd_solver.cpp:105] Iteration 40400, lr = 0.02
I0130 01:54:43.888257  7239 solver.cpp:218] Iteration 40500 (4.29489 iter/s, 23.2835s/100 iters), loss = 0.00642084
I0130 01:54:43.888344  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00642121 (* 1 = 0.00642121 loss)
I0130 01:54:43.888352  7239 sgd_solver.cpp:105] Iteration 40500, lr = 0.02
I0130 01:55:07.396834  7239 solver.cpp:218] Iteration 40600 (4.254 iter/s, 23.5073s/100 iters), loss = 0.023757
I0130 01:55:07.396864  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237575 (* 1 = 0.0237575 loss)
I0130 01:55:07.396875  7239 sgd_solver.cpp:105] Iteration 40600, lr = 0.02
I0130 01:55:12.341591  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:55:30.760551  7239 solver.cpp:218] Iteration 40700 (4.28036 iter/s, 23.3625s/100 iters), loss = 0.0261273
I0130 01:55:30.760627  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261277 (* 1 = 0.0261277 loss)
I0130 01:55:30.760638  7239 sgd_solver.cpp:105] Iteration 40700, lr = 0.02
I0130 01:55:54.362962  7239 solver.cpp:330] Iteration 40800, Testing net (#0)
I0130 01:56:10.800994  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:56:11.135535  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8826
I0130 01:56:11.135560  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.441371 (* 1 = 0.441371 loss)
I0130 01:56:11.379245  7239 solver.cpp:218] Iteration 40800 (2.46205 iter/s, 40.6166s/100 iters), loss = 0.0388415
I0130 01:56:11.379292  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.038842 (* 1 = 0.038842 loss)
I0130 01:56:11.379307  7239 sgd_solver.cpp:105] Iteration 40800, lr = 0.02
I0130 01:56:34.768327  7239 solver.cpp:218] Iteration 40900 (4.27573 iter/s, 23.3878s/100 iters), loss = 0.00866087
I0130 01:56:34.768354  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00866133 (* 1 = 0.00866133 loss)
I0130 01:56:34.768363  7239 sgd_solver.cpp:105] Iteration 40900, lr = 0.02
I0130 01:56:58.012578  7239 solver.cpp:218] Iteration 41000 (4.30236 iter/s, 23.243s/100 iters), loss = 0.11992
I0130 01:56:58.012780  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11992 (* 1 = 0.11992 loss)
I0130 01:56:58.012789  7239 sgd_solver.cpp:105] Iteration 41000, lr = 0.02
I0130 01:57:00.624315  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:57:21.803421  7239 solver.cpp:218] Iteration 41100 (4.20355 iter/s, 23.7894s/100 iters), loss = 0.0227843
I0130 01:57:21.803449  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227847 (* 1 = 0.0227847 loss)
I0130 01:57:21.803457  7239 sgd_solver.cpp:105] Iteration 41100, lr = 0.02
I0130 01:57:44.818253  7239 solver.cpp:330] Iteration 41200, Testing net (#0)
I0130 01:58:01.555282  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:58:01.891744  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8524
I0130 01:58:01.891770  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.540488 (* 1 = 0.540488 loss)
I0130 01:58:02.135121  7239 solver.cpp:218] Iteration 41200 (2.47957 iter/s, 40.3296s/100 iters), loss = 0.0556942
I0130 01:58:02.135144  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556946 (* 1 = 0.0556946 loss)
I0130 01:58:02.135159  7239 sgd_solver.cpp:105] Iteration 41200, lr = 0.02
I0130 01:58:25.408443  7239 solver.cpp:218] Iteration 41300 (4.29699 iter/s, 23.2721s/100 iters), loss = 0.0146558
I0130 01:58:25.408510  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146562 (* 1 = 0.0146562 loss)
I0130 01:58:25.408519  7239 sgd_solver.cpp:105] Iteration 41300, lr = 0.02
I0130 01:58:49.194716  7239 solver.cpp:218] Iteration 41400 (4.20433 iter/s, 23.785s/100 iters), loss = 0.00760522
I0130 01:58:49.194749  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00760562 (* 1 = 0.00760562 loss)
I0130 01:58:49.194757  7239 sgd_solver.cpp:105] Iteration 41400, lr = 0.02
I0130 01:58:49.705471  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:59:12.624614  7239 solver.cpp:218] Iteration 41500 (4.26828 iter/s, 23.4287s/100 iters), loss = 0.00545262
I0130 01:59:12.624770  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545296 (* 1 = 0.00545296 loss)
I0130 01:59:12.624783  7239 sgd_solver.cpp:105] Iteration 41500, lr = 0.02
I0130 01:59:36.280149  7239 solver.cpp:330] Iteration 41600, Testing net (#0)
I0130 01:59:52.685091  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 01:59:53.019177  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8767
I0130 01:59:53.019201  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.454494 (* 1 = 0.454494 loss)
I0130 01:59:53.260565  7239 solver.cpp:218] Iteration 41600 (2.46101 iter/s, 40.6337s/100 iters), loss = 0.0263919
I0130 01:59:53.260587  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263922 (* 1 = 0.0263922 loss)
I0130 01:59:53.260606  7239 sgd_solver.cpp:105] Iteration 41600, lr = 0.02
I0130 02:00:16.513314  7239 solver.cpp:218] Iteration 41700 (4.30079 iter/s, 23.2515s/100 iters), loss = 0.030943
I0130 02:00:16.513340  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309434 (* 1 = 0.0309434 loss)
I0130 02:00:16.513348  7239 sgd_solver.cpp:105] Iteration 41700, lr = 0.02
I0130 02:00:37.738731  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:00:39.604133  7239 solver.cpp:218] Iteration 41800 (4.33095 iter/s, 23.0896s/100 iters), loss = 0.0324163
I0130 02:00:39.604161  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324166 (* 1 = 0.0324166 loss)
I0130 02:00:39.604167  7239 sgd_solver.cpp:105] Iteration 41800, lr = 0.02
I0130 02:01:02.874305  7239 solver.cpp:218] Iteration 41900 (4.29757 iter/s, 23.269s/100 iters), loss = 0.0124319
I0130 02:01:02.874332  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124323 (* 1 = 0.0124323 loss)
I0130 02:01:02.874339  7239 sgd_solver.cpp:105] Iteration 41900, lr = 0.02
I0130 02:01:25.975970  7239 solver.cpp:330] Iteration 42000, Testing net (#0)
I0130 02:01:42.809010  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:01:43.142984  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8874
I0130 02:01:43.143007  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.437735 (* 1 = 0.437735 loss)
I0130 02:01:43.391207  7239 solver.cpp:218] Iteration 42000 (2.46823 iter/s, 40.5148s/100 iters), loss = 0.147499
I0130 02:01:43.391237  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147499 (* 1 = 0.147499 loss)
I0130 02:01:43.391244  7239 sgd_solver.cpp:105] Iteration 42000, lr = 0.02
I0130 02:02:06.429116  7239 solver.cpp:218] Iteration 42100 (4.3409 iter/s, 23.0367s/100 iters), loss = 0.0608558
I0130 02:02:06.431780  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0608562 (* 1 = 0.0608562 loss)
I0130 02:02:06.431808  7239 sgd_solver.cpp:105] Iteration 42100, lr = 0.02
I0130 02:02:25.680449  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:02:29.724166  7239 solver.cpp:218] Iteration 42200 (4.29346 iter/s, 23.2912s/100 iters), loss = 0.0130894
I0130 02:02:29.724194  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130898 (* 1 = 0.0130898 loss)
I0130 02:02:29.724201  7239 sgd_solver.cpp:105] Iteration 42200, lr = 0.02
I0130 02:02:53.762398  7239 solver.cpp:218] Iteration 42300 (4.16026 iter/s, 24.037s/100 iters), loss = 0.188873
I0130 02:02:53.763871  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188873 (* 1 = 0.188873 loss)
I0130 02:02:53.763880  7239 sgd_solver.cpp:105] Iteration 42300, lr = 0.02
I0130 02:03:17.292316  7239 solver.cpp:330] Iteration 42400, Testing net (#0)
I0130 02:03:33.753795  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:03:34.087167  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8882
I0130 02:03:34.087194  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385515 (* 1 = 0.385515 loss)
I0130 02:03:34.325577  7239 solver.cpp:218] Iteration 42400 (2.46551 iter/s, 40.5596s/100 iters), loss = 0.0461958
I0130 02:03:34.325603  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461962 (* 1 = 0.0461962 loss)
I0130 02:03:34.325615  7239 sgd_solver.cpp:105] Iteration 42400, lr = 0.02
I0130 02:03:57.348134  7239 solver.cpp:218] Iteration 42500 (4.34379 iter/s, 23.0214s/100 iters), loss = 0.00967048
I0130 02:03:57.348165  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0096709 (* 1 = 0.0096709 loss)
I0130 02:03:57.348176  7239 sgd_solver.cpp:105] Iteration 42500, lr = 0.02
I0130 02:04:14.811717  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:04:21.135922  7239 solver.cpp:218] Iteration 42600 (4.20406 iter/s, 23.7865s/100 iters), loss = 0.0441911
I0130 02:04:21.135951  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441915 (* 1 = 0.0441915 loss)
I0130 02:04:21.135958  7239 sgd_solver.cpp:105] Iteration 42600, lr = 0.02
I0130 02:04:44.864209  7239 solver.cpp:218] Iteration 42700 (4.2146 iter/s, 23.727s/100 iters), loss = 0.143863
I0130 02:04:44.864765  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143864 (* 1 = 0.143864 loss)
I0130 02:04:44.864773  7239 sgd_solver.cpp:105] Iteration 42700, lr = 0.02
I0130 02:05:08.146852  7239 solver.cpp:330] Iteration 42800, Testing net (#0)
I0130 02:05:24.578531  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:05:24.914105  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9021
I0130 02:05:24.914129  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354699 (* 1 = 0.354699 loss)
I0130 02:05:25.155112  7239 solver.cpp:218] Iteration 42800 (2.48211 iter/s, 40.2883s/100 iters), loss = 0.0335877
I0130 02:05:25.155133  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335882 (* 1 = 0.0335882 loss)
I0130 02:05:25.155153  7239 sgd_solver.cpp:105] Iteration 42800, lr = 0.02
I0130 02:05:48.315378  7239 solver.cpp:218] Iteration 42900 (4.31797 iter/s, 23.1591s/100 iters), loss = 0.00946566
I0130 02:05:48.315407  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00946611 (* 1 = 0.00946611 loss)
I0130 02:05:48.315413  7239 sgd_solver.cpp:105] Iteration 42900, lr = 0.02
I0130 02:06:03.280294  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:06:11.743408  7239 solver.cpp:218] Iteration 43000 (4.26862 iter/s, 23.4268s/100 iters), loss = 0.0161557
I0130 02:06:11.743438  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161562 (* 1 = 0.0161562 loss)
I0130 02:06:11.743445  7239 sgd_solver.cpp:105] Iteration 43000, lr = 0.02
I0130 02:06:35.516533  7239 solver.cpp:218] Iteration 43100 (4.20665 iter/s, 23.7719s/100 iters), loss = 0.0552848
I0130 02:06:35.518983  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0552852 (* 1 = 0.0552852 loss)
I0130 02:06:35.518996  7239 sgd_solver.cpp:105] Iteration 43100, lr = 0.02
I0130 02:06:58.890751  7239 solver.cpp:330] Iteration 43200, Testing net (#0)
I0130 02:07:15.492514  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:07:15.823248  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8862
I0130 02:07:15.823271  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.400549 (* 1 = 0.400549 loss)
I0130 02:07:16.065218  7239 solver.cpp:218] Iteration 43200 (2.46645 iter/s, 40.5442s/100 iters), loss = 0.0552581
I0130 02:07:16.065241  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0552585 (* 1 = 0.0552585 loss)
I0130 02:07:16.065258  7239 sgd_solver.cpp:105] Iteration 43200, lr = 0.02
I0130 02:07:39.157732  7239 solver.cpp:218] Iteration 43300 (4.33063 iter/s, 23.0913s/100 iters), loss = 0.00403795
I0130 02:07:39.157759  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403837 (* 1 = 0.00403837 loss)
I0130 02:07:39.157768  7239 sgd_solver.cpp:105] Iteration 43300, lr = 0.02
I0130 02:07:51.920492  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:08:02.695261  7239 solver.cpp:218] Iteration 43400 (4.24876 iter/s, 23.5363s/100 iters), loss = 0.0286804
I0130 02:08:02.695291  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286808 (* 1 = 0.0286808 loss)
I0130 02:08:02.695302  7239 sgd_solver.cpp:105] Iteration 43400, lr = 0.02
I0130 02:08:26.362634  7239 solver.cpp:218] Iteration 43500 (4.22545 iter/s, 23.6661s/100 iters), loss = 0.200861
I0130 02:08:26.362709  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200862 (* 1 = 0.200862 loss)
I0130 02:08:26.362717  7239 sgd_solver.cpp:105] Iteration 43500, lr = 0.02
I0130 02:08:49.831323  7239 solver.cpp:330] Iteration 43600, Testing net (#0)
I0130 02:09:06.278539  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:09:06.613044  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8598
I0130 02:09:06.613066  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.532396 (* 1 = 0.532396 loss)
I0130 02:09:06.855875  7239 solver.cpp:218] Iteration 43600 (2.46968 iter/s, 40.4911s/100 iters), loss = 0.242746
I0130 02:09:06.855904  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242746 (* 1 = 0.242746 loss)
I0130 02:09:06.855913  7239 sgd_solver.cpp:105] Iteration 43600, lr = 0.02
I0130 02:09:30.021772  7239 solver.cpp:218] Iteration 43700 (4.31692 iter/s, 23.1647s/100 iters), loss = 0.006848
I0130 02:09:30.021802  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068484 (* 1 = 0.0068484 loss)
I0130 02:09:30.021812  7239 sgd_solver.cpp:105] Iteration 43700, lr = 0.02
I0130 02:09:40.642354  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:09:53.282599  7239 solver.cpp:218] Iteration 43800 (4.2993 iter/s, 23.2596s/100 iters), loss = 0.131902
I0130 02:09:53.282626  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131902 (* 1 = 0.131902 loss)
I0130 02:09:53.282634  7239 sgd_solver.cpp:105] Iteration 43800, lr = 0.02
I0130 02:10:16.629109  7239 solver.cpp:218] Iteration 43900 (4.28352 iter/s, 23.3453s/100 iters), loss = 0.0732071
I0130 02:10:16.629175  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0732075 (* 1 = 0.0732075 loss)
I0130 02:10:16.629184  7239 sgd_solver.cpp:105] Iteration 43900, lr = 0.02
I0130 02:10:39.591428  7239 solver.cpp:330] Iteration 44000, Testing net (#0)
I0130 02:10:56.419147  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:10:56.755159  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9057
I0130 02:10:56.755185  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321603 (* 1 = 0.321603 loss)
I0130 02:10:56.998765  7239 solver.cpp:218] Iteration 44000 (2.47724 iter/s, 40.3675s/100 iters), loss = 0.00750865
I0130 02:10:56.998790  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750905 (* 1 = 0.00750905 loss)
I0130 02:10:56.998806  7239 sgd_solver.cpp:105] Iteration 44000, lr = 0.02
I0130 02:11:20.350461  7239 solver.cpp:218] Iteration 44100 (4.28257 iter/s, 23.3505s/100 iters), loss = 0.042525
I0130 02:11:20.350492  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0425254 (* 1 = 0.0425254 loss)
I0130 02:11:20.350498  7239 sgd_solver.cpp:105] Iteration 44100, lr = 0.02
I0130 02:11:28.741545  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:11:43.976449  7239 solver.cpp:218] Iteration 44200 (4.23285 iter/s, 23.6247s/100 iters), loss = 0.012486
I0130 02:11:43.976478  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124864 (* 1 = 0.0124864 loss)
I0130 02:11:43.976485  7239 sgd_solver.cpp:105] Iteration 44200, lr = 0.02
I0130 02:12:07.274631  7239 solver.cpp:218] Iteration 44300 (4.29241 iter/s, 23.297s/100 iters), loss = 0.00867993
I0130 02:12:07.274727  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00868033 (* 1 = 0.00868033 loss)
I0130 02:12:07.274739  7239 sgd_solver.cpp:105] Iteration 44300, lr = 0.02
I0130 02:12:30.798854  7239 solver.cpp:330] Iteration 44400, Testing net (#0)
I0130 02:12:47.350332  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:12:47.684022  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8988
I0130 02:12:47.684049  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365409 (* 1 = 0.365409 loss)
I0130 02:12:47.927737  7239 solver.cpp:218] Iteration 44400 (2.45997 iter/s, 40.6509s/100 iters), loss = 0.154434
I0130 02:12:47.927762  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154434 (* 1 = 0.154434 loss)
I0130 02:12:47.927772  7239 sgd_solver.cpp:105] Iteration 44400, lr = 0.02
I0130 02:13:10.925513  7239 solver.cpp:218] Iteration 44500 (4.34847 iter/s, 22.9966s/100 iters), loss = 0.00869482
I0130 02:13:10.925539  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869523 (* 1 = 0.00869523 loss)
I0130 02:13:10.925547  7239 sgd_solver.cpp:105] Iteration 44500, lr = 0.02
I0130 02:13:17.293783  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:13:34.244920  7239 solver.cpp:218] Iteration 44600 (4.2885 iter/s, 23.3182s/100 iters), loss = 0.110139
I0130 02:13:34.247264  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11014 (* 1 = 0.11014 loss)
I0130 02:13:34.247272  7239 sgd_solver.cpp:105] Iteration 44600, lr = 0.02
I0130 02:13:58.161190  7239 solver.cpp:218] Iteration 44700 (4.18188 iter/s, 23.9127s/100 iters), loss = 0.00814632
I0130 02:13:58.161216  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0081467 (* 1 = 0.0081467 loss)
I0130 02:13:58.161224  7239 sgd_solver.cpp:105] Iteration 44700, lr = 0.02
I0130 02:14:21.285073  7239 solver.cpp:330] Iteration 44800, Testing net (#0)
I0130 02:14:37.952013  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:14:38.287632  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8549
I0130 02:14:38.287655  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.543601 (* 1 = 0.543601 loss)
I0130 02:14:38.528033  7239 solver.cpp:218] Iteration 44800 (2.47741 iter/s, 40.3648s/100 iters), loss = 0.0222897
I0130 02:14:38.528055  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222901 (* 1 = 0.0222901 loss)
I0130 02:14:38.528065  7239 sgd_solver.cpp:105] Iteration 44800, lr = 0.02
I0130 02:15:01.746089  7239 solver.cpp:218] Iteration 44900 (4.30722 iter/s, 23.2168s/100 iters), loss = 0.0321372
I0130 02:15:01.746156  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321375 (* 1 = 0.0321375 loss)
I0130 02:15:01.746167  7239 sgd_solver.cpp:105] Iteration 44900, lr = 0.02
I0130 02:15:05.820127  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:15:25.441226  7239 solver.cpp:218] Iteration 45000 (4.2205 iter/s, 23.6939s/100 iters), loss = 0.00569862
I0130 02:15:25.441256  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00569898 (* 1 = 0.00569898 loss)
I0130 02:15:25.441262  7239 sgd_solver.cpp:105] Iteration 45000, lr = 0.02
I0130 02:15:48.942881  7239 solver.cpp:218] Iteration 45100 (4.25524 iter/s, 23.5004s/100 iters), loss = 0.00957234
I0130 02:15:48.947582  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00957271 (* 1 = 0.00957271 loss)
I0130 02:15:48.947590  7239 sgd_solver.cpp:105] Iteration 45100, lr = 0.02
I0130 02:16:12.214484  7239 solver.cpp:330] Iteration 45200, Testing net (#0)
I0130 02:16:28.948927  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:16:29.288251  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8855
I0130 02:16:29.288277  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381212 (* 1 = 0.381212 loss)
I0130 02:16:29.533154  7239 solver.cpp:218] Iteration 45200 (2.46406 iter/s, 40.5835s/100 iters), loss = 0.00539365
I0130 02:16:29.533179  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00539402 (* 1 = 0.00539402 loss)
I0130 02:16:29.533191  7239 sgd_solver.cpp:105] Iteration 45200, lr = 0.02
I0130 02:16:52.969024  7239 solver.cpp:218] Iteration 45300 (4.26719 iter/s, 23.4346s/100 iters), loss = 0.00601027
I0130 02:16:52.969051  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601062 (* 1 = 0.00601062 loss)
I0130 02:16:52.969058  7239 sgd_solver.cpp:105] Iteration 45300, lr = 0.02
I0130 02:16:54.873412  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:17:16.499034  7239 solver.cpp:218] Iteration 45400 (4.25011 iter/s, 23.5288s/100 iters), loss = 0.0323284
I0130 02:17:16.499119  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323287 (* 1 = 0.0323287 loss)
I0130 02:17:16.499128  7239 sgd_solver.cpp:105] Iteration 45400, lr = 0.02
I0130 02:17:39.867751  7239 solver.cpp:218] Iteration 45500 (4.27946 iter/s, 23.3674s/100 iters), loss = 0.28953
I0130 02:17:39.867779  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28953 (* 1 = 0.28953 loss)
I0130 02:17:39.867791  7239 sgd_solver.cpp:105] Iteration 45500, lr = 0.02
I0130 02:18:03.326194  7239 solver.cpp:330] Iteration 45600, Testing net (#0)
I0130 02:18:19.928725  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:18:20.260004  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8884
I0130 02:18:20.260026  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.394689 (* 1 = 0.394689 loss)
I0130 02:18:20.498309  7239 solver.cpp:218] Iteration 45600 (2.46133 iter/s, 40.6285s/100 iters), loss = 0.0794629
I0130 02:18:20.498332  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0794633 (* 1 = 0.0794633 loss)
I0130 02:18:20.498348  7239 sgd_solver.cpp:105] Iteration 45600, lr = 0.02
I0130 02:18:43.270587  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:18:43.503511  7239 solver.cpp:218] Iteration 45700 (4.34707 iter/s, 23.004s/100 iters), loss = 0.0144957
I0130 02:18:43.503547  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014496 (* 1 = 0.014496 loss)
I0130 02:18:43.503556  7239 sgd_solver.cpp:105] Iteration 45700, lr = 0.02
I0130 02:19:07.206126  7239 solver.cpp:218] Iteration 45800 (4.21917 iter/s, 23.7014s/100 iters), loss = 0.0439922
I0130 02:19:07.206156  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439925 (* 1 = 0.0439925 loss)
I0130 02:19:07.206163  7239 sgd_solver.cpp:105] Iteration 45800, lr = 0.02
I0130 02:19:30.590407  7239 solver.cpp:218] Iteration 45900 (4.2766 iter/s, 23.3831s/100 iters), loss = 0.0767153
I0130 02:19:30.593351  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0767156 (* 1 = 0.0767156 loss)
I0130 02:19:30.593361  7239 sgd_solver.cpp:105] Iteration 45900, lr = 0.02
I0130 02:19:53.874357  7239 solver.cpp:330] Iteration 46000, Testing net (#0)
I0130 02:20:10.582684  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:20:10.916579  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8934
I0130 02:20:10.916605  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381622 (* 1 = 0.381622 loss)
I0130 02:20:11.162369  7239 solver.cpp:218] Iteration 46000 (2.46506 iter/s, 40.5669s/100 iters), loss = 0.0161119
I0130 02:20:11.162392  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161123 (* 1 = 0.0161123 loss)
I0130 02:20:11.162406  7239 sgd_solver.cpp:105] Iteration 46000, lr = 0.02
I0130 02:20:31.839211  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:20:34.448035  7239 solver.cpp:218] Iteration 46100 (4.29471 iter/s, 23.2844s/100 iters), loss = 0.0915817
I0130 02:20:34.448062  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.091582 (* 1 = 0.091582 loss)
I0130 02:20:34.448071  7239 sgd_solver.cpp:105] Iteration 46100, lr = 0.02
I0130 02:20:58.147416  7239 solver.cpp:218] Iteration 46200 (4.21974 iter/s, 23.6981s/100 iters), loss = 0.0170899
I0130 02:20:58.147513  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170903 (* 1 = 0.0170903 loss)
I0130 02:20:58.147521  7239 sgd_solver.cpp:105] Iteration 46200, lr = 0.02
I0130 02:21:21.701092  7239 solver.cpp:218] Iteration 46300 (4.24586 iter/s, 23.5524s/100 iters), loss = 0.134344
I0130 02:21:21.701118  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134345 (* 1 = 0.134345 loss)
I0130 02:21:21.701125  7239 sgd_solver.cpp:105] Iteration 46300, lr = 0.02
I0130 02:21:44.931792  7239 solver.cpp:330] Iteration 46400, Testing net (#0)
I0130 02:22:01.769805  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:22:02.106812  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8722
I0130 02:22:02.106837  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.483914 (* 1 = 0.483914 loss)
I0130 02:22:02.353022  7239 solver.cpp:218] Iteration 46400 (2.46003 iter/s, 40.6498s/100 iters), loss = 0.0601207
I0130 02:22:02.353045  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0601212 (* 1 = 0.0601212 loss)
I0130 02:22:02.353063  7239 sgd_solver.cpp:105] Iteration 46400, lr = 0.02
I0130 02:22:21.005008  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:22:25.630589  7239 solver.cpp:218] Iteration 46500 (4.29621 iter/s, 23.2764s/100 iters), loss = 0.0215879
I0130 02:22:25.630614  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215883 (* 1 = 0.0215883 loss)
I0130 02:22:25.630623  7239 sgd_solver.cpp:105] Iteration 46500, lr = 0.02
I0130 02:22:49.155244  7239 solver.cpp:218] Iteration 46600 (4.25108 iter/s, 23.5234s/100 iters), loss = 0.0174998
I0130 02:22:49.155274  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175002 (* 1 = 0.0175002 loss)
I0130 02:22:49.155282  7239 sgd_solver.cpp:105] Iteration 46600, lr = 0.02
I0130 02:23:12.667047  7239 solver.cpp:218] Iteration 46700 (4.25341 iter/s, 23.5106s/100 iters), loss = 0.111104
I0130 02:23:12.667780  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111104 (* 1 = 0.111104 loss)
I0130 02:23:12.667793  7239 sgd_solver.cpp:105] Iteration 46700, lr = 0.02
I0130 02:23:35.924795  7239 solver.cpp:330] Iteration 46800, Testing net (#0)
I0130 02:23:52.655905  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:23:52.993827  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8923
I0130 02:23:52.993854  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.404824 (* 1 = 0.404824 loss)
I0130 02:23:53.239401  7239 solver.cpp:218] Iteration 46800 (2.4649 iter/s, 40.5696s/100 iters), loss = 0.0266485
I0130 02:23:53.239426  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026649 (* 1 = 0.026649 loss)
I0130 02:23:53.239440  7239 sgd_solver.cpp:105] Iteration 46800, lr = 0.02
I0130 02:24:09.715203  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:24:16.411939  7239 solver.cpp:218] Iteration 46900 (4.31568 iter/s, 23.1713s/100 iters), loss = 0.0947761
I0130 02:24:16.411967  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0947766 (* 1 = 0.0947766 loss)
I0130 02:24:16.411978  7239 sgd_solver.cpp:105] Iteration 46900, lr = 0.02
I0130 02:24:40.027735  7239 solver.cpp:218] Iteration 47000 (4.23468 iter/s, 23.6146s/100 iters), loss = 0.0216494
I0130 02:24:40.030134  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216499 (* 1 = 0.0216499 loss)
I0130 02:24:40.030143  7239 sgd_solver.cpp:105] Iteration 47000, lr = 0.02
I0130 02:25:03.246937  7239 solver.cpp:218] Iteration 47100 (4.30745 iter/s, 23.2156s/100 iters), loss = 0.0114617
I0130 02:25:03.246965  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114623 (* 1 = 0.0114623 loss)
I0130 02:25:03.246973  7239 sgd_solver.cpp:105] Iteration 47100, lr = 0.02
I0130 02:25:26.445580  7239 solver.cpp:330] Iteration 47200, Testing net (#0)
I0130 02:25:43.329721  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:25:43.665626  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8874
I0130 02:25:43.665648  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.415544 (* 1 = 0.415544 loss)
I0130 02:25:43.913445  7239 solver.cpp:218] Iteration 47200 (2.45915 iter/s, 40.6644s/100 iters), loss = 0.0130171
I0130 02:25:43.913475  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130177 (* 1 = 0.0130177 loss)
I0130 02:25:43.913481  7239 sgd_solver.cpp:105] Iteration 47200, lr = 0.02
I0130 02:25:57.997956  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:26:07.303855  7239 solver.cpp:218] Iteration 47300 (4.27548 iter/s, 23.3892s/100 iters), loss = 0.00675468
I0130 02:26:07.303882  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00675529 (* 1 = 0.00675529 loss)
I0130 02:26:07.303889  7239 sgd_solver.cpp:105] Iteration 47300, lr = 0.02
I0130 02:26:30.910115  7239 solver.cpp:218] Iteration 47400 (4.23639 iter/s, 23.605s/100 iters), loss = 0.0231504
I0130 02:26:30.910183  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023151 (* 1 = 0.023151 loss)
I0130 02:26:30.910192  7239 sgd_solver.cpp:105] Iteration 47400, lr = 0.02
I0130 02:26:54.395911  7239 solver.cpp:218] Iteration 47500 (4.25812 iter/s, 23.4845s/100 iters), loss = 0.0820509
I0130 02:26:54.395938  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0820515 (* 1 = 0.0820515 loss)
I0130 02:26:54.395946  7239 sgd_solver.cpp:105] Iteration 47500, lr = 0.02
I0130 02:27:17.678714  7239 solver.cpp:330] Iteration 47600, Testing net (#0)
I0130 02:27:34.376415  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:27:34.710842  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.903
I0130 02:27:34.710865  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355649 (* 1 = 0.355649 loss)
I0130 02:27:34.955646  7239 solver.cpp:218] Iteration 47600 (2.46563 iter/s, 40.5576s/100 iters), loss = 0.00466861
I0130 02:27:34.955670  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466926 (* 1 = 0.00466926 loss)
I0130 02:27:34.955685  7239 sgd_solver.cpp:105] Iteration 47600, lr = 0.02
I0130 02:27:47.087358  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:27:58.129822  7239 solver.cpp:218] Iteration 47700 (4.31537 iter/s, 23.173s/100 iters), loss = 0.00785929
I0130 02:27:58.131315  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00785987 (* 1 = 0.00785987 loss)
I0130 02:27:58.131323  7239 sgd_solver.cpp:105] Iteration 47700, lr = 0.02
I0130 02:28:21.695957  7239 solver.cpp:218] Iteration 47800 (4.24386 iter/s, 23.5634s/100 iters), loss = 0.0957695
I0130 02:28:21.695984  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0957701 (* 1 = 0.0957701 loss)
I0130 02:28:21.695993  7239 sgd_solver.cpp:105] Iteration 47800, lr = 0.02
I0130 02:28:45.342360  7239 solver.cpp:218] Iteration 47900 (4.2292 iter/s, 23.6452s/100 iters), loss = 0.0112785
I0130 02:28:45.343060  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112791 (* 1 = 0.0112791 loss)
I0130 02:28:45.343070  7239 sgd_solver.cpp:105] Iteration 47900, lr = 0.02
I0130 02:29:08.791059  7239 solver.cpp:447] Snapshotting to binary proto file examples/bao/WRN-28_iter_48000.caffemodel
I0130 02:29:09.130709  7239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/bao/WRN-28_iter_48000.solverstate
I0130 02:29:09.328161  7239 solver.cpp:330] Iteration 48000, Testing net (#0)
I0130 02:29:26.101251  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:29:26.438557  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8962
I0130 02:29:26.438582  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349561 (* 1 = 0.349561 loss)
I0130 02:29:26.686337  7239 solver.cpp:218] Iteration 48000 (2.4189 iter/s, 41.3412s/100 iters), loss = 0.014289
I0130 02:29:26.686360  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142896 (* 1 = 0.0142896 loss)
I0130 02:29:26.686370  7265 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0130 02:29:26.686370  7267 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0130 02:29:26.686370  7239 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0130 02:29:26.686388  7239 sgd_solver.cpp:105] Iteration 48000, lr = 0.004
I0130 02:29:26.686372  7266 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0130 02:29:36.425964  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:29:50.047075  7239 solver.cpp:218] Iteration 48100 (4.28091 iter/s, 23.3595s/100 iters), loss = 0.00228328
I0130 02:29:50.047102  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228385 (* 1 = 0.00228385 loss)
I0130 02:29:50.047111  7239 sgd_solver.cpp:105] Iteration 48100, lr = 0.004
I0130 02:30:13.404587  7239 solver.cpp:218] Iteration 48200 (4.2815 iter/s, 23.3563s/100 iters), loss = 0.0108192
I0130 02:30:13.404680  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108198 (* 1 = 0.0108198 loss)
I0130 02:30:13.404690  7239 sgd_solver.cpp:105] Iteration 48200, lr = 0.004
I0130 02:30:36.894814  7239 solver.cpp:218] Iteration 48300 (4.25732 iter/s, 23.4889s/100 iters), loss = 0.00193308
I0130 02:30:36.894841  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193361 (* 1 = 0.00193361 loss)
I0130 02:30:36.894850  7239 sgd_solver.cpp:105] Iteration 48300, lr = 0.004
I0130 02:30:59.904439  7239 solver.cpp:330] Iteration 48400, Testing net (#0)
I0130 02:31:16.787362  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:31:17.129693  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9432
I0130 02:31:17.129719  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.194197 (* 1 = 0.194197 loss)
I0130 02:31:17.375977  7239 solver.cpp:218] Iteration 48400 (2.47041 iter/s, 40.4791s/100 iters), loss = 0.00824279
I0130 02:31:17.375999  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00824333 (* 1 = 0.00824333 loss)
I0130 02:31:17.376011  7239 sgd_solver.cpp:105] Iteration 48400, lr = 0.004
I0130 02:31:25.126196  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:31:40.730193  7239 solver.cpp:218] Iteration 48500 (4.28211 iter/s, 23.353s/100 iters), loss = 0.00348686
I0130 02:31:40.730760  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348739 (* 1 = 0.00348739 loss)
I0130 02:31:40.730769  7239 sgd_solver.cpp:105] Iteration 48500, lr = 0.004
I0130 02:32:04.114810  7239 solver.cpp:218] Iteration 48600 (4.27664 iter/s, 23.3829s/100 iters), loss = 0.00915451
I0130 02:32:04.114841  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00915504 (* 1 = 0.00915504 loss)
I0130 02:32:04.114848  7239 sgd_solver.cpp:105] Iteration 48600, lr = 0.004
I0130 02:32:27.930178  7239 solver.cpp:218] Iteration 48700 (4.19919 iter/s, 23.8141s/100 iters), loss = 0.00536285
I0130 02:32:27.934213  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536338 (* 1 = 0.00536338 loss)
I0130 02:32:27.934224  7239 sgd_solver.cpp:105] Iteration 48700, lr = 0.004
I0130 02:32:51.396150  7239 solver.cpp:330] Iteration 48800, Testing net (#0)
I0130 02:33:07.765655  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:33:08.095119  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9467
I0130 02:33:08.095146  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.185548 (* 1 = 0.185548 loss)
I0130 02:33:08.335358  7239 solver.cpp:218] Iteration 48800 (2.47536 iter/s, 40.3982s/100 iters), loss = 0.00597184
I0130 02:33:08.335383  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00597237 (* 1 = 0.00597237 loss)
I0130 02:33:08.335394  7239 sgd_solver.cpp:105] Iteration 48800, lr = 0.004
I0130 02:33:14.010972  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:33:31.789964  7239 solver.cpp:218] Iteration 48900 (4.26378 iter/s, 23.4534s/100 iters), loss = 0.00722473
I0130 02:33:31.789994  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00722527 (* 1 = 0.00722527 loss)
I0130 02:33:31.790004  7239 sgd_solver.cpp:105] Iteration 48900, lr = 0.004
I0130 02:33:55.280722  7239 solver.cpp:218] Iteration 49000 (4.25722 iter/s, 23.4895s/100 iters), loss = 0.00355275
I0130 02:33:55.281968  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355329 (* 1 = 0.00355329 loss)
I0130 02:33:55.281986  7239 sgd_solver.cpp:105] Iteration 49000, lr = 0.004
I0130 02:34:18.980989  7239 solver.cpp:218] Iteration 49100 (4.2198 iter/s, 23.6978s/100 iters), loss = 0.00235284
I0130 02:34:18.981020  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235338 (* 1 = 0.00235338 loss)
I0130 02:34:18.981030  7239 sgd_solver.cpp:105] Iteration 49100, lr = 0.004
I0130 02:34:42.122942  7239 solver.cpp:330] Iteration 49200, Testing net (#0)
I0130 02:34:58.883772  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:34:59.218772  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9502
I0130 02:34:59.218796  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.177251 (* 1 = 0.177251 loss)
I0130 02:34:59.464287  7239 solver.cpp:218] Iteration 49200 (2.47028 iter/s, 40.4812s/100 iters), loss = 0.00298306
I0130 02:34:59.464313  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298361 (* 1 = 0.00298361 loss)
I0130 02:34:59.464323  7239 sgd_solver.cpp:105] Iteration 49200, lr = 0.004
I0130 02:35:02.708990  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:35:22.910882  7239 solver.cpp:218] Iteration 49300 (4.26524 iter/s, 23.4454s/100 iters), loss = 0.00262661
I0130 02:35:22.910949  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262715 (* 1 = 0.00262715 loss)
I0130 02:35:22.910959  7239 sgd_solver.cpp:105] Iteration 49300, lr = 0.004
I0130 02:35:46.340191  7239 solver.cpp:218] Iteration 49400 (4.26839 iter/s, 23.428s/100 iters), loss = 0.00081146
I0130 02:35:46.340219  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000812007 (* 1 = 0.000812007 loss)
I0130 02:35:46.340225  7239 sgd_solver.cpp:105] Iteration 49400, lr = 0.004
I0130 02:36:09.762835  7239 solver.cpp:218] Iteration 49500 (4.2696 iter/s, 23.4214s/100 iters), loss = 0.00148089
I0130 02:36:09.763387  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148144 (* 1 = 0.00148144 loss)
I0130 02:36:09.763396  7239 sgd_solver.cpp:105] Iteration 49500, lr = 0.004
I0130 02:36:33.276705  7239 solver.cpp:330] Iteration 49600, Testing net (#0)
I0130 02:36:50.178799  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:36:50.511534  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9508
I0130 02:36:50.511560  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.179814 (* 1 = 0.179814 loss)
I0130 02:36:50.754709  7239 solver.cpp:218] Iteration 49600 (2.43966 iter/s, 40.9892s/100 iters), loss = 0.000869299
I0130 02:36:50.754741  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000869847 (* 1 = 0.000869847 loss)
I0130 02:36:50.754750  7239 sgd_solver.cpp:105] Iteration 49600, lr = 0.004
I0130 02:36:51.925572  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:37:14.050151  7239 solver.cpp:218] Iteration 49700 (4.29291 iter/s, 23.2942s/100 iters), loss = 0.00517258
I0130 02:37:14.050180  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00517313 (* 1 = 0.00517313 loss)
I0130 02:37:14.050187  7239 sgd_solver.cpp:105] Iteration 49700, lr = 0.004
I0130 02:37:37.430008  7239 solver.cpp:218] Iteration 49800 (4.27741 iter/s, 23.3786s/100 iters), loss = 0.000946034
I0130 02:37:37.430460  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000946587 (* 1 = 0.000946587 loss)
I0130 02:37:37.430470  7239 sgd_solver.cpp:105] Iteration 49800, lr = 0.004
I0130 02:38:01.096204  7239 solver.cpp:218] Iteration 49900 (4.22573 iter/s, 23.6645s/100 iters), loss = 0.00134969
I0130 02:38:01.096231  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135025 (* 1 = 0.00135025 loss)
I0130 02:38:01.096238  7239 sgd_solver.cpp:105] Iteration 49900, lr = 0.004
I0130 02:38:23.677253  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:38:24.380093  7239 solver.cpp:330] Iteration 50000, Testing net (#0)
I0130 02:38:41.058327  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:38:41.394284  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9516
I0130 02:38:41.394309  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.181479 (* 1 = 0.181479 loss)
I0130 02:38:41.641199  7239 solver.cpp:218] Iteration 50000 (2.46652 iter/s, 40.5429s/100 iters), loss = 0.000955175
I0130 02:38:41.641228  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000955738 (* 1 = 0.000955738 loss)
I0130 02:38:41.641237  7239 sgd_solver.cpp:105] Iteration 50000, lr = 0.004
I0130 02:39:04.815754  7239 solver.cpp:218] Iteration 50100 (4.3153 iter/s, 23.1733s/100 iters), loss = 0.00302485
I0130 02:39:04.815945  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302541 (* 1 = 0.00302541 loss)
I0130 02:39:04.815954  7239 sgd_solver.cpp:105] Iteration 50100, lr = 0.004
I0130 02:39:28.235435  7239 solver.cpp:218] Iteration 50200 (4.27017 iter/s, 23.4183s/100 iters), loss = 0.00180265
I0130 02:39:28.235461  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180321 (* 1 = 0.00180321 loss)
I0130 02:39:28.235473  7239 sgd_solver.cpp:105] Iteration 50200, lr = 0.004
I0130 02:39:52.033154  7239 solver.cpp:218] Iteration 50300 (4.2023 iter/s, 23.7965s/100 iters), loss = 0.00359497
I0130 02:39:52.034858  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359553 (* 1 = 0.00359553 loss)
I0130 02:39:52.034868  7239 sgd_solver.cpp:105] Iteration 50300, lr = 0.004
I0130 02:40:12.291132  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:40:15.313519  7239 solver.cpp:330] Iteration 50400, Testing net (#0)
I0130 02:40:31.928108  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:40:32.267078  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.951
I0130 02:40:32.267103  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.183259 (* 1 = 0.183259 loss)
I0130 02:40:32.514890  7239 solver.cpp:218] Iteration 50400 (2.47048 iter/s, 40.478s/100 iters), loss = 0.0832846
I0130 02:40:32.514915  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0832852 (* 1 = 0.0832852 loss)
I0130 02:40:32.514927  7239 sgd_solver.cpp:105] Iteration 50400, lr = 0.004
I0130 02:40:55.737628  7239 solver.cpp:218] Iteration 50500 (4.30635 iter/s, 23.2215s/100 iters), loss = 0.000893348
I0130 02:40:55.737655  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000893914 (* 1 = 0.000893914 loss)
I0130 02:40:55.737663  7239 sgd_solver.cpp:105] Iteration 50500, lr = 0.004
I0130 02:41:19.146391  7239 solver.cpp:218] Iteration 50600 (4.27213 iter/s, 23.4075s/100 iters), loss = 0.00347578
I0130 02:41:19.146459  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347635 (* 1 = 0.00347635 loss)
I0130 02:41:19.146468  7239 sgd_solver.cpp:105] Iteration 50600, lr = 0.004
I0130 02:41:42.952105  7239 solver.cpp:218] Iteration 50700 (4.2009 iter/s, 23.8044s/100 iters), loss = 0.00148585
I0130 02:41:42.952136  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148641 (* 1 = 0.00148641 loss)
I0130 02:41:42.952143  7239 sgd_solver.cpp:105] Iteration 50700, lr = 0.004
I0130 02:42:01.091312  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:42:06.187127  7239 solver.cpp:330] Iteration 50800, Testing net (#0)
I0130 02:42:22.943605  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:42:23.279747  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9518
I0130 02:42:23.279768  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.179494 (* 1 = 0.179494 loss)
I0130 02:42:23.520486  7239 solver.cpp:218] Iteration 50800 (2.4651 iter/s, 40.5663s/100 iters), loss = 0.00221756
I0130 02:42:23.520511  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221813 (* 1 = 0.00221813 loss)
I0130 02:42:23.520526  7239 sgd_solver.cpp:105] Iteration 50800, lr = 0.004
I0130 02:42:46.653367  7239 solver.cpp:218] Iteration 50900 (4.32308 iter/s, 23.1317s/100 iters), loss = 0.000776955
I0130 02:42:46.653450  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000777516 (* 1 = 0.000777516 loss)
I0130 02:42:46.653460  7239 sgd_solver.cpp:105] Iteration 50900, lr = 0.004
I0130 02:43:10.044569  7239 solver.cpp:218] Iteration 51000 (4.27535 iter/s, 23.3899s/100 iters), loss = 0.00131037
I0130 02:43:10.044598  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131093 (* 1 = 0.00131093 loss)
I0130 02:43:10.044605  7239 sgd_solver.cpp:105] Iteration 51000, lr = 0.004
I0130 02:43:33.794049  7239 solver.cpp:218] Iteration 51100 (4.21084 iter/s, 23.7482s/100 iters), loss = 0.00487045
I0130 02:43:33.794118  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487101 (* 1 = 0.00487101 loss)
I0130 02:43:33.794126  7239 sgd_solver.cpp:105] Iteration 51100, lr = 0.004
I0130 02:43:49.623461  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:43:57.062006  7239 solver.cpp:330] Iteration 51200, Testing net (#0)
I0130 02:44:13.609148  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:44:13.949589  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9523
I0130 02:44:13.949611  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.176516 (* 1 = 0.176516 loss)
I0130 02:44:14.193866  7239 solver.cpp:218] Iteration 51200 (2.47539 iter/s, 40.3977s/100 iters), loss = 0.00243777
I0130 02:44:14.193888  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243833 (* 1 = 0.00243833 loss)
I0130 02:44:14.193907  7239 sgd_solver.cpp:105] Iteration 51200, lr = 0.004
I0130 02:44:37.186010  7239 solver.cpp:218] Iteration 51300 (4.34954 iter/s, 22.9909s/100 iters), loss = 0.00107069
I0130 02:44:37.186038  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107126 (* 1 = 0.00107126 loss)
I0130 02:44:37.186044  7239 sgd_solver.cpp:105] Iteration 51300, lr = 0.004
I0130 02:45:00.575176  7239 solver.cpp:218] Iteration 51400 (4.27571 iter/s, 23.3879s/100 iters), loss = 0.000855385
I0130 02:45:00.575239  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000855949 (* 1 = 0.000855949 loss)
I0130 02:45:00.575248  7239 sgd_solver.cpp:105] Iteration 51400, lr = 0.004
I0130 02:45:24.453073  7239 solver.cpp:218] Iteration 51500 (4.1882 iter/s, 23.8766s/100 iters), loss = 0.00134215
I0130 02:45:24.453105  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134272 (* 1 = 0.00134272 loss)
I0130 02:45:24.453115  7239 sgd_solver.cpp:105] Iteration 51500, lr = 0.004
I0130 02:45:38.068753  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:45:47.714722  7239 solver.cpp:330] Iteration 51600, Testing net (#0)
I0130 02:46:04.199749  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:46:04.535063  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9506
I0130 02:46:04.535085  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.183556 (* 1 = 0.183556 loss)
I0130 02:46:04.779546  7239 solver.cpp:218] Iteration 51600 (2.47989 iter/s, 40.3244s/100 iters), loss = 0.00288035
I0130 02:46:04.779569  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288092 (* 1 = 0.00288092 loss)
I0130 02:46:04.779584  7239 sgd_solver.cpp:105] Iteration 51600, lr = 0.004
I0130 02:46:27.946820  7239 solver.cpp:218] Iteration 51700 (4.31666 iter/s, 23.1661s/100 iters), loss = 0.00211364
I0130 02:46:27.946892  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021142 (* 1 = 0.0021142 loss)
I0130 02:46:27.946900  7239 sgd_solver.cpp:105] Iteration 51700, lr = 0.004
I0130 02:46:51.339349  7239 solver.cpp:218] Iteration 51800 (4.2751 iter/s, 23.3913s/100 iters), loss = 0.00188582
I0130 02:46:51.339385  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188639 (* 1 = 0.00188639 loss)
I0130 02:46:51.339395  7239 sgd_solver.cpp:105] Iteration 51800, lr = 0.004
I0130 02:47:15.082949  7239 solver.cpp:218] Iteration 51900 (4.21188 iter/s, 23.7423s/100 iters), loss = 0.00115512
I0130 02:47:15.084053  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115569 (* 1 = 0.00115569 loss)
I0130 02:47:15.084066  7239 sgd_solver.cpp:105] Iteration 51900, lr = 0.004
I0130 02:47:26.806547  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:47:38.506675  7239 solver.cpp:330] Iteration 52000, Testing net (#0)
I0130 02:47:55.169114  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:47:55.510738  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9522
I0130 02:47:55.510761  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.182671 (* 1 = 0.182671 loss)
I0130 02:47:55.756669  7239 solver.cpp:218] Iteration 52000 (2.45878 iter/s, 40.6705s/100 iters), loss = 0.000769812
I0130 02:47:55.756690  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000770381 (* 1 = 0.000770381 loss)
I0130 02:47:55.756709  7239 sgd_solver.cpp:105] Iteration 52000, lr = 0.004
I0130 02:48:19.051403  7239 solver.cpp:218] Iteration 52100 (4.29304 iter/s, 23.2935s/100 iters), loss = 0.000975329
I0130 02:48:19.051430  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000975899 (* 1 = 0.000975899 loss)
I0130 02:48:19.051437  7239 sgd_solver.cpp:105] Iteration 52100, lr = 0.004
I0130 02:48:42.465745  7239 solver.cpp:218] Iteration 52200 (4.27111 iter/s, 23.4131s/100 iters), loss = 0.00194262
I0130 02:48:42.466150  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194319 (* 1 = 0.00194319 loss)
I0130 02:48:42.466157  7239 sgd_solver.cpp:105] Iteration 52200, lr = 0.004
I0130 02:49:05.859089  7239 solver.cpp:218] Iteration 52300 (4.27501 iter/s, 23.3917s/100 iters), loss = 0.00248963
I0130 02:49:05.859117  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0024902 (* 1 = 0.0024902 loss)
I0130 02:49:05.859128  7239 sgd_solver.cpp:105] Iteration 52300, lr = 0.004
I0130 02:49:15.221086  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:49:29.466032  7239 solver.cpp:330] Iteration 52400, Testing net (#0)
I0130 02:49:45.882581  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:49:46.219038  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9506
I0130 02:49:46.219063  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.184608 (* 1 = 0.184608 loss)
I0130 02:49:46.462399  7239 solver.cpp:218] Iteration 52400 (2.46298 iter/s, 40.6012s/100 iters), loss = 0.00132219
I0130 02:49:46.462424  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132276 (* 1 = 0.00132276 loss)
I0130 02:49:46.462433  7239 sgd_solver.cpp:105] Iteration 52400, lr = 0.004
I0130 02:50:09.783031  7239 solver.cpp:218] Iteration 52500 (4.28827 iter/s, 23.3194s/100 iters), loss = 0.00248549
I0130 02:50:09.783057  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248607 (* 1 = 0.00248607 loss)
I0130 02:50:09.783064  7239 sgd_solver.cpp:105] Iteration 52500, lr = 0.004
I0130 02:50:33.211565  7239 solver.cpp:218] Iteration 52600 (4.26852 iter/s, 23.4273s/100 iters), loss = 0.00184582
I0130 02:50:33.212690  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184639 (* 1 = 0.00184639 loss)
I0130 02:50:33.212699  7239 sgd_solver.cpp:105] Iteration 52600, lr = 0.004
I0130 02:50:56.804585  7239 solver.cpp:218] Iteration 52700 (4.23896 iter/s, 23.5907s/100 iters), loss = 0.00213696
I0130 02:50:56.804612  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213753 (* 1 = 0.00213753 loss)
I0130 02:50:56.804625  7239 sgd_solver.cpp:105] Iteration 52700, lr = 0.004
I0130 02:51:04.108536  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:51:20.564432  7239 solver.cpp:330] Iteration 52800, Testing net (#0)
I0130 02:51:37.185952  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:51:37.524502  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9546
I0130 02:51:37.524526  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.173177 (* 1 = 0.173177 loss)
I0130 02:51:37.769109  7239 solver.cpp:218] Iteration 52800 (2.44126 iter/s, 40.9624s/100 iters), loss = 0.00153415
I0130 02:51:37.769132  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153472 (* 1 = 0.00153472 loss)
I0130 02:51:37.769141  7239 sgd_solver.cpp:105] Iteration 52800, lr = 0.004
I0130 02:52:01.105123  7239 solver.cpp:218] Iteration 52900 (4.28545 iter/s, 23.3348s/100 iters), loss = 0.00518833
I0130 02:52:01.105154  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0051889 (* 1 = 0.0051889 loss)
I0130 02:52:01.105163  7239 sgd_solver.cpp:105] Iteration 52900, lr = 0.004
I0130 02:52:24.562089  7239 solver.cpp:218] Iteration 53000 (4.26335 iter/s, 23.4557s/100 iters), loss = 0.00106332
I0130 02:52:24.562599  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106389 (* 1 = 0.00106389 loss)
I0130 02:52:24.562608  7239 sgd_solver.cpp:105] Iteration 53000, lr = 0.004
I0130 02:52:48.019265  7239 solver.cpp:218] Iteration 53100 (4.2634 iter/s, 23.4555s/100 iters), loss = 0.000594229
I0130 02:52:48.019294  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000594797 (* 1 = 0.000594797 loss)
I0130 02:52:48.019304  7239 sgd_solver.cpp:105] Iteration 53100, lr = 0.004
I0130 02:52:52.917024  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:53:11.326656  7239 solver.cpp:330] Iteration 53200, Testing net (#0)
I0130 02:53:28.080018  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:53:28.412317  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9528
I0130 02:53:28.412339  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.176588 (* 1 = 0.176588 loss)
I0130 02:53:28.653600  7239 solver.cpp:218] Iteration 53200 (2.4611 iter/s, 40.6322s/100 iters), loss = 0.00265173
I0130 02:53:28.653632  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026523 (* 1 = 0.0026523 loss)
I0130 02:53:28.653640  7239 sgd_solver.cpp:105] Iteration 53200, lr = 0.004
I0130 02:53:51.747504  7239 solver.cpp:218] Iteration 53300 (4.33037 iter/s, 23.0927s/100 iters), loss = 0.000672353
I0130 02:53:51.747577  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000672922 (* 1 = 0.000672922 loss)
I0130 02:53:51.747586  7239 sgd_solver.cpp:105] Iteration 53300, lr = 0.004
I0130 02:54:15.428380  7239 solver.cpp:218] Iteration 53400 (4.22304 iter/s, 23.6796s/100 iters), loss = 0.00239528
I0130 02:54:15.428408  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239585 (* 1 = 0.00239585 loss)
I0130 02:54:15.428416  7239 sgd_solver.cpp:105] Iteration 53400, lr = 0.004
I0130 02:54:39.119015  7239 solver.cpp:218] Iteration 53500 (4.2213 iter/s, 23.6894s/100 iters), loss = 0.00293595
I0130 02:54:39.119084  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293652 (* 1 = 0.00293652 loss)
I0130 02:54:39.119093  7239 sgd_solver.cpp:105] Iteration 53500, lr = 0.004
I0130 02:54:41.673710  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:55:02.300940  7239 solver.cpp:330] Iteration 53600, Testing net (#0)
I0130 02:55:18.889358  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:55:19.220054  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.954
I0130 02:55:19.220077  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.174603 (* 1 = 0.174603 loss)
I0130 02:55:19.464668  7239 solver.cpp:218] Iteration 53600 (2.47871 iter/s, 40.3435s/100 iters), loss = 0.0021243
I0130 02:55:19.464691  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212487 (* 1 = 0.00212487 loss)
I0130 02:55:19.464705  7239 sgd_solver.cpp:105] Iteration 53600, lr = 0.004
I0130 02:55:42.408937  7239 solver.cpp:218] Iteration 53700 (4.35861 iter/s, 22.9431s/100 iters), loss = 0.00100611
I0130 02:55:42.408965  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100668 (* 1 = 0.00100668 loss)
I0130 02:55:42.408972  7239 sgd_solver.cpp:105] Iteration 53700, lr = 0.004
I0130 02:56:05.844290  7239 solver.cpp:218] Iteration 53800 (4.26728 iter/s, 23.4341s/100 iters), loss = 0.00114784
I0130 02:56:05.844408  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114841 (* 1 = 0.00114841 loss)
I0130 02:56:05.844419  7239 sgd_solver.cpp:105] Iteration 53800, lr = 0.004
I0130 02:56:29.474886  7239 solver.cpp:218] Iteration 53900 (4.23204 iter/s, 23.6293s/100 iters), loss = 0.000894386
I0130 02:56:29.474915  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000894952 (* 1 = 0.000894952 loss)
I0130 02:56:29.474923  7239 sgd_solver.cpp:105] Iteration 53900, lr = 0.004
I0130 02:56:29.960299  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:56:53.103931  7239 solver.cpp:330] Iteration 54000, Testing net (#0)
I0130 02:57:09.584468  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:57:09.916791  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9543
I0130 02:57:09.916813  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.178211 (* 1 = 0.178211 loss)
I0130 02:57:10.159869  7239 solver.cpp:218] Iteration 54000 (2.45753 iter/s, 40.6912s/100 iters), loss = 0.000613411
I0130 02:57:10.159893  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000613978 (* 1 = 0.000613978 loss)
I0130 02:57:10.159907  7239 sgd_solver.cpp:105] Iteration 54000, lr = 0.004
I0130 02:57:33.438321  7239 solver.cpp:218] Iteration 54100 (4.29455 iter/s, 23.2853s/100 iters), loss = 0.00189561
I0130 02:57:33.438385  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189618 (* 1 = 0.00189618 loss)
I0130 02:57:33.438395  7239 sgd_solver.cpp:105] Iteration 54100, lr = 0.004
I0130 02:57:56.926729  7239 solver.cpp:218] Iteration 54200 (4.25628 iter/s, 23.4947s/100 iters), loss = 0.00140655
I0130 02:57:56.926756  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140712 (* 1 = 0.00140712 loss)
I0130 02:57:56.926764  7239 sgd_solver.cpp:105] Iteration 54200, lr = 0.004
I0130 02:58:18.426950  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:58:20.324304  7239 solver.cpp:218] Iteration 54300 (4.2729 iter/s, 23.4033s/100 iters), loss = 0.00103465
I0130 02:58:20.324331  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103522 (* 1 = 0.00103522 loss)
I0130 02:58:20.324338  7239 sgd_solver.cpp:105] Iteration 54300, lr = 0.004
I0130 02:58:44.141204  7239 solver.cpp:330] Iteration 54400, Testing net (#0)
I0130 02:59:00.617126  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 02:59:00.949542  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9538
I0130 02:59:00.949566  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.172727 (* 1 = 0.172727 loss)
I0130 02:59:01.197149  7239 solver.cpp:218] Iteration 54400 (2.44608 iter/s, 40.8817s/100 iters), loss = 0.000884504
I0130 02:59:01.197171  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000885076 (* 1 = 0.000885076 loss)
I0130 02:59:01.197190  7239 sgd_solver.cpp:105] Iteration 54400, lr = 0.004
I0130 02:59:24.220949  7239 solver.cpp:218] Iteration 54500 (4.34251 iter/s, 23.0282s/100 iters), loss = 0.00102875
I0130 02:59:24.220976  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102932 (* 1 = 0.00102932 loss)
I0130 02:59:24.220983  7239 sgd_solver.cpp:105] Iteration 54500, lr = 0.004
I0130 02:59:47.776968  7239 solver.cpp:218] Iteration 54600 (4.24447 iter/s, 23.5601s/100 iters), loss = 0.00124411
I0130 02:59:47.777035  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124469 (* 1 = 0.00124469 loss)
I0130 02:59:47.777045  7239 sgd_solver.cpp:105] Iteration 54600, lr = 0.004
I0130 03:00:07.678670  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:00:11.780118  7239 solver.cpp:218] Iteration 54700 (4.16547 iter/s, 24.0069s/100 iters), loss = 0.000721968
I0130 03:00:11.780145  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000722542 (* 1 = 0.000722542 loss)
I0130 03:00:11.780154  7239 sgd_solver.cpp:105] Iteration 54700, lr = 0.004
I0130 03:00:35.095753  7239 solver.cpp:330] Iteration 54800, Testing net (#0)
I0130 03:00:51.727615  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:00:52.061363  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9537
I0130 03:00:52.061386  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.176257 (* 1 = 0.176257 loss)
I0130 03:00:52.306573  7239 solver.cpp:218] Iteration 54800 (2.46718 iter/s, 40.5321s/100 iters), loss = 0.00183327
I0130 03:00:52.306599  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183384 (* 1 = 0.00183384 loss)
I0130 03:00:52.306612  7239 sgd_solver.cpp:105] Iteration 54800, lr = 0.004
I0130 03:01:15.472086  7239 solver.cpp:218] Iteration 54900 (4.31624 iter/s, 23.1683s/100 iters), loss = 0.000949443
I0130 03:01:15.472157  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000950019 (* 1 = 0.000950019 loss)
I0130 03:01:15.472165  7239 sgd_solver.cpp:105] Iteration 54900, lr = 0.004
I0130 03:01:38.806490  7239 solver.cpp:218] Iteration 55000 (4.28506 iter/s, 23.3369s/100 iters), loss = 0.000804804
I0130 03:01:38.806520  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000805378 (* 1 = 0.000805378 loss)
I0130 03:01:38.806527  7239 sgd_solver.cpp:105] Iteration 55000, lr = 0.004
I0130 03:01:56.328086  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:02:02.398373  7239 solver.cpp:218] Iteration 55100 (4.23832 iter/s, 23.5942s/100 iters), loss = 0.000665946
I0130 03:02:02.398401  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00066652 (* 1 = 0.00066652 loss)
I0130 03:02:02.398408  7239 sgd_solver.cpp:105] Iteration 55100, lr = 0.004
I0130 03:02:25.947639  7239 solver.cpp:330] Iteration 55200, Testing net (#0)
I0130 03:02:42.332492  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:02:42.670449  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9514
I0130 03:02:42.670472  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.180764 (* 1 = 0.180764 loss)
I0130 03:02:42.912987  7239 solver.cpp:218] Iteration 55200 (2.46803 iter/s, 40.5182s/100 iters), loss = 0.00200191
I0130 03:02:42.913012  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200249 (* 1 = 0.00200249 loss)
I0130 03:02:42.913020  7239 sgd_solver.cpp:105] Iteration 55200, lr = 0.004
I0130 03:03:06.160675  7239 solver.cpp:218] Iteration 55300 (4.30118 iter/s, 23.2495s/100 iters), loss = 0.00147674
I0130 03:03:06.160702  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147732 (* 1 = 0.00147732 loss)
I0130 03:03:06.160709  7239 sgd_solver.cpp:105] Iteration 55300, lr = 0.004
I0130 03:03:29.565556  7239 solver.cpp:218] Iteration 55400 (4.27232 iter/s, 23.4065s/100 iters), loss = 0.00308177
I0130 03:03:29.566654  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308234 (* 1 = 0.00308234 loss)
I0130 03:03:29.566663  7239 sgd_solver.cpp:105] Iteration 55400, lr = 0.004
I0130 03:03:44.657208  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:03:53.300504  7239 solver.cpp:218] Iteration 55500 (4.21312 iter/s, 23.7354s/100 iters), loss = 0.00110082
I0130 03:03:53.300531  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110139 (* 1 = 0.00110139 loss)
I0130 03:03:53.300539  7239 sgd_solver.cpp:105] Iteration 55500, lr = 0.004
I0130 03:04:16.692059  7239 solver.cpp:330] Iteration 55600, Testing net (#0)
I0130 03:04:33.189380  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:04:33.528985  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953
I0130 03:04:33.529011  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.181299 (* 1 = 0.181299 loss)
I0130 03:04:33.771029  7239 solver.cpp:218] Iteration 55600 (2.4708 iter/s, 40.4728s/100 iters), loss = 0.00135761
I0130 03:04:33.771056  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135818 (* 1 = 0.00135818 loss)
I0130 03:04:33.771067  7239 sgd_solver.cpp:105] Iteration 55600, lr = 0.004
I0130 03:04:56.847867  7239 solver.cpp:218] Iteration 55700 (4.33314 iter/s, 23.0779s/100 iters), loss = 0.00182665
I0130 03:04:56.847941  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182722 (* 1 = 0.00182722 loss)
I0130 03:04:56.847950  7239 sgd_solver.cpp:105] Iteration 55700, lr = 0.004
I0130 03:05:20.792024  7239 solver.cpp:218] Iteration 55800 (4.17621 iter/s, 23.9451s/100 iters), loss = 0.00125024
I0130 03:05:20.792052  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125081 (* 1 = 0.00125081 loss)
I0130 03:05:20.792062  7239 sgd_solver.cpp:105] Iteration 55800, lr = 0.004
I0130 03:05:33.681475  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:05:44.150624  7239 solver.cpp:218] Iteration 55900 (4.28091 iter/s, 23.3595s/100 iters), loss = 0.000922388
I0130 03:05:44.150650  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00092296 (* 1 = 0.00092296 loss)
I0130 03:05:44.150656  7239 sgd_solver.cpp:105] Iteration 55900, lr = 0.004
I0130 03:06:07.468595  7239 solver.cpp:330] Iteration 56000, Testing net (#0)
I0130 03:06:24.195843  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:06:24.529978  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9543
I0130 03:06:24.530000  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.176913 (* 1 = 0.176913 loss)
I0130 03:06:24.783252  7239 solver.cpp:218] Iteration 56000 (2.46099 iter/s, 40.634s/100 iters), loss = 0.00129953
I0130 03:06:24.783280  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130011 (* 1 = 0.00130011 loss)
I0130 03:06:24.783289  7239 sgd_solver.cpp:105] Iteration 56000, lr = 0.004
I0130 03:06:48.038832  7239 solver.cpp:218] Iteration 56100 (4.29992 iter/s, 23.2562s/100 iters), loss = 0.00317178
I0130 03:06:48.038920  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317236 (* 1 = 0.00317236 loss)
I0130 03:06:48.038933  7239 sgd_solver.cpp:105] Iteration 56100, lr = 0.004
I0130 03:07:11.740270  7239 solver.cpp:218] Iteration 56200 (4.21905 iter/s, 23.702s/100 iters), loss = 0.000709751
I0130 03:07:11.740296  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000710322 (* 1 = 0.000710322 loss)
I0130 03:07:11.740303  7239 sgd_solver.cpp:105] Iteration 56200, lr = 0.004
I0130 03:07:22.570325  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:07:35.122534  7239 solver.cpp:218] Iteration 56300 (4.27665 iter/s, 23.3828s/100 iters), loss = 0.00203628
I0130 03:07:35.122563  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203685 (* 1 = 0.00203685 loss)
I0130 03:07:35.122573  7239 sgd_solver.cpp:105] Iteration 56300, lr = 0.004
I0130 03:07:58.604849  7239 solver.cpp:330] Iteration 56400, Testing net (#0)
I0130 03:08:15.083945  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:08:15.415266  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9531
I0130 03:08:15.415292  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.175453 (* 1 = 0.175453 loss)
I0130 03:08:15.660259  7239 solver.cpp:218] Iteration 56400 (2.46679 iter/s, 40.5385s/100 iters), loss = 0.00422492
I0130 03:08:15.660285  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422549 (* 1 = 0.00422549 loss)
I0130 03:08:15.660295  7239 sgd_solver.cpp:105] Iteration 56400, lr = 0.004
I0130 03:08:39.102479  7239 solver.cpp:218] Iteration 56500 (4.26574 iter/s, 23.4426s/100 iters), loss = 0.00338019
I0130 03:08:39.102576  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338076 (* 1 = 0.00338076 loss)
I0130 03:08:39.102583  7239 sgd_solver.cpp:105] Iteration 56500, lr = 0.004
I0130 03:09:02.398037  7239 solver.cpp:218] Iteration 56600 (4.29261 iter/s, 23.2958s/100 iters), loss = 0.00186402
I0130 03:09:02.398067  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186459 (* 1 = 0.00186459 loss)
I0130 03:09:02.398075  7239 sgd_solver.cpp:105] Iteration 56600, lr = 0.004
I0130 03:09:10.795606  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:09:26.162405  7239 solver.cpp:218] Iteration 56700 (4.20793 iter/s, 23.7647s/100 iters), loss = 0.00117322
I0130 03:09:26.162434  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011738 (* 1 = 0.0011738 loss)
I0130 03:09:26.162442  7239 sgd_solver.cpp:105] Iteration 56700, lr = 0.004
I0130 03:09:49.626526  7239 solver.cpp:330] Iteration 56800, Testing net (#0)
I0130 03:10:06.068953  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:10:06.400934  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9526
I0130 03:10:06.400955  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.178462 (* 1 = 0.178462 loss)
I0130 03:10:06.647516  7239 solver.cpp:218] Iteration 56800 (2.47002 iter/s, 40.4856s/100 iters), loss = 0.00156582
I0130 03:10:06.647544  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156639 (* 1 = 0.00156639 loss)
I0130 03:10:06.647552  7239 sgd_solver.cpp:105] Iteration 56800, lr = 0.004
I0130 03:10:29.935717  7239 solver.cpp:218] Iteration 56900 (4.29398 iter/s, 23.2884s/100 iters), loss = 0.00189151
I0130 03:10:29.935783  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189208 (* 1 = 0.00189208 loss)
I0130 03:10:29.935791  7239 sgd_solver.cpp:105] Iteration 56900, lr = 0.004
I0130 03:10:53.249344  7239 solver.cpp:218] Iteration 57000 (4.28931 iter/s, 23.3138s/100 iters), loss = 0.00169382
I0130 03:10:53.249378  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169439 (* 1 = 0.00169439 loss)
I0130 03:10:53.249388  7239 sgd_solver.cpp:105] Iteration 57000, lr = 0.004
I0130 03:10:59.568421  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:11:16.845697  7239 solver.cpp:218] Iteration 57100 (4.23792 iter/s, 23.5965s/100 iters), loss = 0.00205775
I0130 03:11:16.847483  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205832 (* 1 = 0.00205832 loss)
I0130 03:11:16.847492  7239 sgd_solver.cpp:105] Iteration 57100, lr = 0.004
I0130 03:11:39.834273  7239 solver.cpp:330] Iteration 57200, Testing net (#0)
I0130 03:11:56.685077  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:11:57.029909  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953
I0130 03:11:57.029933  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.177676 (* 1 = 0.177676 loss)
I0130 03:11:57.278076  7239 solver.cpp:218] Iteration 57200 (2.47336 iter/s, 40.4309s/100 iters), loss = 0.00169555
I0130 03:11:57.278101  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169612 (* 1 = 0.00169612 loss)
I0130 03:11:57.278112  7239 sgd_solver.cpp:105] Iteration 57200, lr = 0.004
I0130 03:12:20.347573  7239 solver.cpp:218] Iteration 57300 (4.33471 iter/s, 23.0696s/100 iters), loss = 0.00291233
I0130 03:12:20.347600  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291291 (* 1 = 0.00291291 loss)
I0130 03:12:20.347609  7239 sgd_solver.cpp:105] Iteration 57300, lr = 0.004
I0130 03:12:43.930153  7239 solver.cpp:218] Iteration 57400 (4.2404 iter/s, 23.5827s/100 iters), loss = 0.00174759
I0130 03:12:43.930225  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174816 (* 1 = 0.00174816 loss)
I0130 03:12:43.930234  7239 sgd_solver.cpp:105] Iteration 57400, lr = 0.004
I0130 03:12:48.000258  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:13:07.284006  7239 solver.cpp:218] Iteration 57500 (4.28195 iter/s, 23.3539s/100 iters), loss = 0.000951722
I0130 03:13:07.284035  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000952297 (* 1 = 0.000952297 loss)
I0130 03:13:07.284042  7239 sgd_solver.cpp:105] Iteration 57500, lr = 0.004
I0130 03:13:30.791070  7239 solver.cpp:330] Iteration 57600, Testing net (#0)
I0130 03:13:47.307472  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:13:47.643100  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9535
I0130 03:13:47.643123  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.179033 (* 1 = 0.179033 loss)
I0130 03:13:47.885331  7239 solver.cpp:218] Iteration 57600 (2.46297 iter/s, 40.6014s/100 iters), loss = 0.00224622
I0130 03:13:47.885355  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224679 (* 1 = 0.00224679 loss)
I0130 03:13:47.885365  7239 sgd_solver.cpp:105] Iteration 57600, lr = 0.004
I0130 03:14:10.964437  7239 solver.cpp:218] Iteration 57700 (4.33292 iter/s, 23.0791s/100 iters), loss = 0.0016611
I0130 03:14:10.964507  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166167 (* 1 = 0.00166167 loss)
I0130 03:14:10.964515  7239 sgd_solver.cpp:105] Iteration 57700, lr = 0.004
I0130 03:14:34.392340  7239 solver.cpp:218] Iteration 57800 (4.26898 iter/s, 23.4248s/100 iters), loss = 0.00170198
I0130 03:14:34.392377  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170255 (* 1 = 0.00170255 loss)
I0130 03:14:34.392388  7239 sgd_solver.cpp:105] Iteration 57800, lr = 0.004
I0130 03:14:36.263716  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:14:58.044425  7239 solver.cpp:218] Iteration 57900 (4.22925 iter/s, 23.6448s/100 iters), loss = 0.0015328
I0130 03:14:58.044489  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153338 (* 1 = 0.00153338 loss)
I0130 03:14:58.044498  7239 sgd_solver.cpp:105] Iteration 57900, lr = 0.004
I0130 03:15:21.614673  7239 solver.cpp:330] Iteration 58000, Testing net (#0)
I0130 03:15:38.202322  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:15:38.536818  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9522
I0130 03:15:38.536841  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.17842 (* 1 = 0.17842 loss)
I0130 03:15:38.780629  7239 solver.cpp:218] Iteration 58000 (2.45549 iter/s, 40.725s/100 iters), loss = 0.00137616
I0130 03:15:38.780653  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137674 (* 1 = 0.00137674 loss)
I0130 03:15:38.780668  7239 sgd_solver.cpp:105] Iteration 58000, lr = 0.004
I0130 03:16:01.697551  7239 solver.cpp:218] Iteration 58100 (4.36467 iter/s, 22.9113s/100 iters), loss = 0.00173833
I0130 03:16:01.697579  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017389 (* 1 = 0.0017389 loss)
I0130 03:16:01.697587  7239 sgd_solver.cpp:105] Iteration 58100, lr = 0.004
I0130 03:16:24.876576  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:16:25.111232  7239 solver.cpp:218] Iteration 58200 (4.27199 iter/s, 23.4083s/100 iters), loss = 0.00112377
I0130 03:16:25.111259  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112435 (* 1 = 0.00112435 loss)
I0130 03:16:25.111266  7239 sgd_solver.cpp:105] Iteration 58200, lr = 0.004
I0130 03:16:48.778547  7239 solver.cpp:218] Iteration 58300 (4.22614 iter/s, 23.6623s/100 iters), loss = 0.00161071
I0130 03:16:48.778573  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161129 (* 1 = 0.00161129 loss)
I0130 03:16:48.778581  7239 sgd_solver.cpp:105] Iteration 58300, lr = 0.004
I0130 03:17:11.904551  7239 solver.cpp:330] Iteration 58400, Testing net (#0)
I0130 03:17:28.605703  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:17:28.947633  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953501
I0130 03:17:28.947659  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.177239 (* 1 = 0.177239 loss)
I0130 03:17:29.191452  7239 solver.cpp:218] Iteration 58400 (2.47493 iter/s, 40.4051s/100 iters), loss = 0.00226817
I0130 03:17:29.191475  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226874 (* 1 = 0.00226874 loss)
I0130 03:17:29.191493  7239 sgd_solver.cpp:105] Iteration 58400, lr = 0.004
I0130 03:17:52.523437  7239 solver.cpp:218] Iteration 58500 (4.28671 iter/s, 23.3279s/100 iters), loss = 0.00134453
I0130 03:17:52.524605  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134511 (* 1 = 0.00134511 loss)
I0130 03:17:52.524616  7239 sgd_solver.cpp:105] Iteration 58500, lr = 0.004
I0130 03:18:13.381037  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:18:15.977465  7239 solver.cpp:218] Iteration 58600 (4.26456 iter/s, 23.4491s/100 iters), loss = 0.0054426
I0130 03:18:15.977491  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00544318 (* 1 = 0.00544318 loss)
I0130 03:18:15.977499  7239 sgd_solver.cpp:105] Iteration 58600, lr = 0.004
I0130 03:18:39.207005  7239 solver.cpp:218] Iteration 58700 (4.30552 iter/s, 23.226s/100 iters), loss = 0.00263028
I0130 03:18:39.207079  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00263086 (* 1 = 0.00263086 loss)
I0130 03:18:39.207088  7239 sgd_solver.cpp:105] Iteration 58700, lr = 0.004
I0130 03:19:02.711987  7239 solver.cpp:330] Iteration 58800, Testing net (#0)
I0130 03:19:19.550421  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:19:19.892446  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.952401
I0130 03:19:19.892472  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.176665 (* 1 = 0.176665 loss)
I0130 03:19:20.141789  7239 solver.cpp:218] Iteration 58800 (2.44325 iter/s, 40.9291s/100 iters), loss = 0.00118943
I0130 03:19:20.141815  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119001 (* 1 = 0.00119001 loss)
I0130 03:19:20.141826  7239 sgd_solver.cpp:105] Iteration 58800, lr = 0.004
I0130 03:19:43.446182  7239 solver.cpp:218] Iteration 58900 (4.29159 iter/s, 23.3014s/100 iters), loss = 0.00161168
I0130 03:19:43.446208  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161226 (* 1 = 0.00161226 loss)
I0130 03:19:43.446215  7239 sgd_solver.cpp:105] Iteration 58900, lr = 0.004
I0130 03:20:02.242733  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:20:06.932428  7239 solver.cpp:218] Iteration 59000 (4.25832 iter/s, 23.4834s/100 iters), loss = 0.000831169
I0130 03:20:06.932457  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000831749 (* 1 = 0.000831749 loss)
I0130 03:20:06.932466  7239 sgd_solver.cpp:105] Iteration 59000, lr = 0.004
I0130 03:20:30.226102  7239 solver.cpp:218] Iteration 59100 (4.2935 iter/s, 23.291s/100 iters), loss = 0.00190522
I0130 03:20:30.226128  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019058 (* 1 = 0.0019058 loss)
I0130 03:20:30.226136  7239 sgd_solver.cpp:105] Iteration 59100, lr = 0.004
I0130 03:20:53.805562  7239 solver.cpp:330] Iteration 59200, Testing net (#0)
I0130 03:21:10.390419  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:21:10.723183  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9529
I0130 03:21:10.723206  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.174821 (* 1 = 0.174821 loss)
I0130 03:21:10.967149  7239 solver.cpp:218] Iteration 59200 (2.45478 iter/s, 40.7368s/100 iters), loss = 0.00140045
I0130 03:21:10.967175  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140103 (* 1 = 0.00140103 loss)
I0130 03:21:10.967183  7239 sgd_solver.cpp:105] Iteration 59200, lr = 0.004
I0130 03:21:34.005676  7239 solver.cpp:218] Iteration 59300 (4.34098 iter/s, 23.0363s/100 iters), loss = 0.00142304
I0130 03:21:34.007020  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142362 (* 1 = 0.00142362 loss)
I0130 03:21:34.007030  7239 sgd_solver.cpp:105] Iteration 59300, lr = 0.004
I0130 03:21:50.708037  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:21:57.651271  7239 solver.cpp:218] Iteration 59400 (4.22974 iter/s, 23.6421s/100 iters), loss = 0.00155508
I0130 03:21:57.651299  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155566 (* 1 = 0.00155566 loss)
I0130 03:21:57.651306  7239 sgd_solver.cpp:105] Iteration 59400, lr = 0.004
I0130 03:22:20.922763  7239 solver.cpp:218] Iteration 59500 (4.29748 iter/s, 23.2694s/100 iters), loss = 0.00167157
I0130 03:22:20.925609  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167215 (* 1 = 0.00167215 loss)
I0130 03:22:20.925622  7239 sgd_solver.cpp:105] Iteration 59500, lr = 0.004
I0130 03:22:44.309979  7239 solver.cpp:330] Iteration 59600, Testing net (#0)
I0130 03:23:00.875752  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:23:01.208042  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.953801
I0130 03:23:01.208066  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.174928 (* 1 = 0.174928 loss)
I0130 03:23:01.455924  7239 solver.cpp:218] Iteration 59600 (2.46749 iter/s, 40.527s/100 iters), loss = 0.00126564
I0130 03:23:01.455947  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126622 (* 1 = 0.00126622 loss)
I0130 03:23:01.455962  7239 sgd_solver.cpp:105] Iteration 59600, lr = 0.004
I0130 03:23:24.652622  7239 solver.cpp:218] Iteration 59700 (4.31129 iter/s, 23.1949s/100 iters), loss = 0.00153907
I0130 03:23:24.652650  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153964 (* 1 = 0.00153964 loss)
I0130 03:23:24.652657  7239 sgd_solver.cpp:105] Iteration 59700, lr = 0.004
I0130 03:23:38.854125  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:23:47.903228  7239 solver.cpp:218] Iteration 59800 (4.30128 iter/s, 23.2489s/100 iters), loss = 0.00147232
I0130 03:23:47.903255  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014729 (* 1 = 0.0014729 loss)
I0130 03:23:47.903264  7239 sgd_solver.cpp:105] Iteration 59800, lr = 0.004
I0130 03:24:11.427393  7239 solver.cpp:218] Iteration 59900 (4.25125 iter/s, 23.5225s/100 iters), loss = 0.00133265
I0130 03:24:11.429379  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133323 (* 1 = 0.00133323 loss)
I0130 03:24:11.429388  7239 sgd_solver.cpp:105] Iteration 59900, lr = 0.004
I0130 03:24:34.961624  7239 solver.cpp:447] Snapshotting to binary proto file examples/bao/WRN-28_iter_60000.caffemodel
I0130 03:24:35.312670  7239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/bao/WRN-28_iter_60000.solverstate
I0130 03:24:35.510398  7239 solver.cpp:330] Iteration 60000, Testing net (#0)
I0130 03:24:51.911276  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:24:52.245560  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9529
I0130 03:24:52.245587  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.177131 (* 1 = 0.177131 loss)
I0130 03:24:52.488814  7239 solver.cpp:218] Iteration 60000 (2.43566 iter/s, 41.0567s/100 iters), loss = 0.00211945
I0130 03:24:52.488838  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212003 (* 1 = 0.00212003 loss)
I0130 03:24:52.488853  7239 sgd_solver.cpp:105] Iteration 60000, lr = 0.004
I0130 03:25:15.538712  7239 solver.cpp:218] Iteration 60100 (4.3387 iter/s, 23.0484s/100 iters), loss = 0.00103011
I0130 03:25:15.538743  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103069 (* 1 = 0.00103069 loss)
I0130 03:25:15.538749  7239 sgd_solver.cpp:105] Iteration 60100, lr = 0.004
I0130 03:25:27.693075  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:25:38.865119  7239 solver.cpp:218] Iteration 60200 (4.28726 iter/s, 23.3249s/100 iters), loss = 0.00128425
I0130 03:25:38.865147  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128483 (* 1 = 0.00128483 loss)
I0130 03:25:38.865155  7239 sgd_solver.cpp:105] Iteration 60200, lr = 0.004
I0130 03:26:02.484450  7239 solver.cpp:218] Iteration 60300 (4.23408 iter/s, 23.6179s/100 iters), loss = 0.00224558
I0130 03:26:02.485149  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224616 (* 1 = 0.00224616 loss)
I0130 03:26:02.485159  7239 sgd_solver.cpp:105] Iteration 60300, lr = 0.004
I0130 03:26:26.084436  7239 solver.cpp:330] Iteration 60400, Testing net (#0)
I0130 03:26:42.510896  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:26:42.843122  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9539
I0130 03:26:42.843145  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.17345 (* 1 = 0.17345 loss)
I0130 03:26:43.086405  7239 solver.cpp:218] Iteration 60400 (2.46312 iter/s, 40.5989s/100 iters), loss = 0.00151531
I0130 03:26:43.086427  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151589 (* 1 = 0.00151589 loss)
I0130 03:26:43.086441  7239 sgd_solver.cpp:105] Iteration 60400, lr = 0.004
I0130 03:27:06.217217  7239 solver.cpp:218] Iteration 60500 (4.32348 iter/s, 23.1295s/100 iters), loss = 0.00154785
I0130 03:27:06.217243  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154843 (* 1 = 0.00154843 loss)
I0130 03:27:06.217250  7239 sgd_solver.cpp:105] Iteration 60500, lr = 0.004
I0130 03:27:15.924800  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:27:29.554124  7239 solver.cpp:218] Iteration 60600 (4.28529 iter/s, 23.3356s/100 iters), loss = 0.00102249
I0130 03:27:29.554154  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102308 (* 1 = 0.00102308 loss)
I0130 03:27:29.554162  7239 sgd_solver.cpp:105] Iteration 60600, lr = 0.004
I0130 03:27:53.349800  7239 solver.cpp:218] Iteration 60700 (4.20267 iter/s, 23.7944s/100 iters), loss = 0.00130919
I0130 03:27:53.349871  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130977 (* 1 = 0.00130977 loss)
I0130 03:27:53.349880  7239 sgd_solver.cpp:105] Iteration 60700, lr = 0.004
I0130 03:28:16.725944  7239 solver.cpp:330] Iteration 60800, Testing net (#0)
I0130 03:28:33.155788  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:28:33.496073  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9542
I0130 03:28:33.496098  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.17451 (* 1 = 0.17451 loss)
I0130 03:28:33.740959  7239 solver.cpp:218] Iteration 60800 (2.47592 iter/s, 40.389s/100 iters), loss = 0.00177893
I0130 03:28:33.740983  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177951 (* 1 = 0.00177951 loss)
I0130 03:28:33.740998  7239 sgd_solver.cpp:105] Iteration 60800, lr = 0.004
I0130 03:28:56.705700  7239 solver.cpp:218] Iteration 60900 (4.35472 iter/s, 22.9636s/100 iters), loss = 0.00170146
I0130 03:28:56.705730  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170204 (* 1 = 0.00170204 loss)
I0130 03:28:56.705737  7239 sgd_solver.cpp:105] Iteration 60900, lr = 0.004
I0130 03:29:04.434350  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:29:20.152673  7239 solver.cpp:218] Iteration 61000 (4.26516 iter/s, 23.4458s/100 iters), loss = 0.00176163
I0130 03:29:20.152698  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176221 (* 1 = 0.00176221 loss)
I0130 03:29:20.152709  7239 sgd_solver.cpp:105] Iteration 61000, lr = 0.004
I0130 03:29:43.410542  7239 solver.cpp:218] Iteration 61100 (4.29983 iter/s, 23.2567s/100 iters), loss = 0.00147812
I0130 03:29:43.410609  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014787 (* 1 = 0.0014787 loss)
I0130 03:29:43.410621  7239 sgd_solver.cpp:105] Iteration 61100, lr = 0.004
I0130 03:30:06.637756  7239 solver.cpp:330] Iteration 61200, Testing net (#0)
I0130 03:30:23.473914  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:30:23.809062  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9551
I0130 03:30:23.809084  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.172318 (* 1 = 0.172318 loss)
I0130 03:30:24.053912  7239 solver.cpp:218] Iteration 61200 (2.46055 iter/s, 40.6414s/100 iters), loss = 0.00224224
I0130 03:30:24.053942  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224282 (* 1 = 0.00224282 loss)
I0130 03:30:24.053949  7239 sgd_solver.cpp:105] Iteration 61200, lr = 0.004
I0130 03:30:47.408272  7239 solver.cpp:218] Iteration 61300 (4.28206 iter/s, 23.3532s/100 iters), loss = 0.00316351
I0130 03:30:47.408298  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0031641 (* 1 = 0.0031641 loss)
I0130 03:30:47.408306  7239 sgd_solver.cpp:105] Iteration 61300, lr = 0.004
I0130 03:30:53.009209  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:31:10.826884  7239 solver.cpp:218] Iteration 61400 (4.27031 iter/s, 23.4175s/100 iters), loss = 0.00113029
I0130 03:31:10.828501  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113087 (* 1 = 0.00113087 loss)
I0130 03:31:10.828510  7239 sgd_solver.cpp:105] Iteration 61400, lr = 0.004
I0130 03:31:34.654161  7239 solver.cpp:218] Iteration 61500 (4.19732 iter/s, 23.8247s/100 iters), loss = 0.00101659
I0130 03:31:34.654187  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101718 (* 1 = 0.00101718 loss)
I0130 03:31:34.654199  7239 sgd_solver.cpp:105] Iteration 61500, lr = 0.004
I0130 03:31:57.910826  7239 solver.cpp:330] Iteration 61600, Testing net (#0)
I0130 03:32:14.469038  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:32:14.803045  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9563
I0130 03:32:14.803067  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.171231 (* 1 = 0.171231 loss)
I0130 03:32:15.043865  7239 solver.cpp:218] Iteration 61600 (2.47593 iter/s, 40.3888s/100 iters), loss = 0.00417544
I0130 03:32:15.043895  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417602 (* 1 = 0.00417602 loss)
I0130 03:32:15.043901  7239 sgd_solver.cpp:105] Iteration 61600, lr = 0.004
I0130 03:32:38.309685  7239 solver.cpp:218] Iteration 61700 (4.29825 iter/s, 23.2653s/100 iters), loss = 0.00582867
I0130 03:32:38.309780  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00582926 (* 1 = 0.00582926 loss)
I0130 03:32:38.309788  7239 sgd_solver.cpp:105] Iteration 61700, lr = 0.004
I0130 03:32:41.532783  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:33:01.446352  7239 solver.cpp:218] Iteration 61800 (4.32226 iter/s, 23.136s/100 iters), loss = 0.0014486
I0130 03:33:01.446382  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144919 (* 1 = 0.00144919 loss)
I0130 03:33:01.446388  7239 sgd_solver.cpp:105] Iteration 61800, lr = 0.004
I0130 03:33:25.132843  7239 solver.cpp:218] Iteration 61900 (4.22192 iter/s, 23.6859s/100 iters), loss = 0.00151751
I0130 03:33:25.132990  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151809 (* 1 = 0.00151809 loss)
I0130 03:33:25.132999  7239 sgd_solver.cpp:105] Iteration 61900, lr = 0.004
I0130 03:33:48.971541  7239 solver.cpp:330] Iteration 62000, Testing net (#0)
I0130 03:34:05.279129  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:34:05.613183  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9541
I0130 03:34:05.613205  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.176621 (* 1 = 0.176621 loss)
I0130 03:34:05.857846  7239 solver.cpp:218] Iteration 62000 (2.45556 iter/s, 40.7239s/100 iters), loss = 0.00123448
I0130 03:34:05.857869  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123507 (* 1 = 0.00123507 loss)
I0130 03:34:05.857884  7239 sgd_solver.cpp:105] Iteration 62000, lr = 0.004
I0130 03:34:28.816120  7239 solver.cpp:218] Iteration 62100 (4.35584 iter/s, 22.9577s/100 iters), loss = 0.0014987
I0130 03:34:28.816148  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149928 (* 1 = 0.00149928 loss)
I0130 03:34:28.816154  7239 sgd_solver.cpp:105] Iteration 62100, lr = 0.004
I0130 03:34:29.969041  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:34:52.328850  7239 solver.cpp:218] Iteration 62200 (4.25313 iter/s, 23.5121s/100 iters), loss = 0.0115203
I0130 03:34:52.328938  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115209 (* 1 = 0.0115209 loss)
I0130 03:34:52.328946  7239 sgd_solver.cpp:105] Iteration 62200, lr = 0.004
I0130 03:35:16.008409  7239 solver.cpp:218] Iteration 62300 (4.22318 iter/s, 23.6789s/100 iters), loss = 0.00128601
I0130 03:35:16.008440  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128659 (* 1 = 0.00128659 loss)
I0130 03:35:16.008447  7239 sgd_solver.cpp:105] Iteration 62300, lr = 0.004
I0130 03:35:39.572890  7239 solver.cpp:330] Iteration 62400, Testing net (#0)
I0130 03:35:56.052512  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:35:56.379674  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9553
I0130 03:35:56.379696  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.178218 (* 1 = 0.178218 loss)
I0130 03:35:56.619982  7239 solver.cpp:218] Iteration 62400 (2.46242 iter/s, 40.6105s/100 iters), loss = 0.00143098
I0130 03:35:56.620003  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143157 (* 1 = 0.00143157 loss)
I0130 03:35:56.620018  7239 sgd_solver.cpp:105] Iteration 62400, lr = 0.004
I0130 03:36:18.675031  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:36:19.597898  7239 solver.cpp:218] Iteration 62500 (4.35213 iter/s, 22.9773s/100 iters), loss = 0.00128579
I0130 03:36:19.597925  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128638 (* 1 = 0.00128638 loss)
I0130 03:36:19.597934  7239 sgd_solver.cpp:105] Iteration 62500, lr = 0.004
I0130 03:36:43.023838  7239 solver.cpp:218] Iteration 62600 (4.2689 iter/s, 23.4253s/100 iters), loss = 0.00104783
I0130 03:36:43.023865  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104841 (* 1 = 0.00104841 loss)
I0130 03:36:43.023872  7239 sgd_solver.cpp:105] Iteration 62600, lr = 0.004
I0130 03:37:06.809046  7239 solver.cpp:218] Iteration 62700 (4.20442 iter/s, 23.7845s/100 iters), loss = 0.00246141
I0130 03:37:06.810719  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246199 (* 1 = 0.00246199 loss)
I0130 03:37:06.810732  7239 sgd_solver.cpp:105] Iteration 62700, lr = 0.004
I0130 03:37:30.048491  7239 solver.cpp:330] Iteration 62800, Testing net (#0)
I0130 03:37:46.887735  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:37:47.218062  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9536
I0130 03:37:47.218083  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.177077 (* 1 = 0.177077 loss)
I0130 03:37:47.462268  7239 solver.cpp:218] Iteration 62800 (2.46 iter/s, 40.6504s/100 iters), loss = 0.00338461
I0130 03:37:47.462292  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338519 (* 1 = 0.00338519 loss)
I0130 03:37:47.462306  7239 sgd_solver.cpp:105] Iteration 62800, lr = 0.004
I0130 03:38:07.218391  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:38:10.544365  7239 solver.cpp:218] Iteration 62900 (4.3325 iter/s, 23.0814s/100 iters), loss = 0.0034886
I0130 03:38:10.544394  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348918 (* 1 = 0.00348918 loss)
I0130 03:38:10.544404  7239 sgd_solver.cpp:105] Iteration 62900, lr = 0.004
I0130 03:38:34.073657  7239 solver.cpp:218] Iteration 63000 (4.25015 iter/s, 23.5286s/100 iters), loss = 0.0013744
I0130 03:38:34.074648  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137498 (* 1 = 0.00137498 loss)
I0130 03:38:34.074663  7239 sgd_solver.cpp:105] Iteration 63000, lr = 0.004
I0130 03:38:57.824826  7239 solver.cpp:218] Iteration 63100 (4.21062 iter/s, 23.7495s/100 iters), loss = 0.00282723
I0130 03:38:57.824852  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282781 (* 1 = 0.00282781 loss)
I0130 03:38:57.824862  7239 sgd_solver.cpp:105] Iteration 63100, lr = 0.004
I0130 03:39:21.188918  7239 solver.cpp:330] Iteration 63200, Testing net (#0)
I0130 03:39:37.934198  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:39:38.272773  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9539
I0130 03:39:38.272795  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.17888 (* 1 = 0.17888 loss)
I0130 03:39:38.519762  7239 solver.cpp:218] Iteration 63200 (2.45739 iter/s, 40.6937s/100 iters), loss = 0.000933561
I0130 03:39:38.519788  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000934141 (* 1 = 0.000934141 loss)
I0130 03:39:38.519795  7239 sgd_solver.cpp:105] Iteration 63200, lr = 0.004
I0130 03:39:56.389891  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:40:01.835728  7239 solver.cpp:218] Iteration 63300 (4.28905 iter/s, 23.3152s/100 iters), loss = 0.00117678
I0130 03:40:01.835757  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117736 (* 1 = 0.00117736 loss)
I0130 03:40:01.835763  7239 sgd_solver.cpp:105] Iteration 63300, lr = 0.004
I0130 03:40:25.032269  7239 solver.cpp:218] Iteration 63400 (4.31113 iter/s, 23.1958s/100 iters), loss = 0.00121774
I0130 03:40:25.032299  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121832 (* 1 = 0.00121832 loss)
I0130 03:40:25.032306  7239 sgd_solver.cpp:105] Iteration 63400, lr = 0.004
I0130 03:40:48.950219  7239 solver.cpp:218] Iteration 63500 (4.1811 iter/s, 23.9172s/100 iters), loss = 0.00386839
I0130 03:40:48.950290  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386897 (* 1 = 0.00386897 loss)
I0130 03:40:48.950299  7239 sgd_solver.cpp:105] Iteration 63500, lr = 0.004
I0130 03:41:12.381732  7239 solver.cpp:330] Iteration 63600, Testing net (#0)
I0130 03:41:29.064666  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:41:29.404327  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.955
I0130 03:41:29.404353  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.173991 (* 1 = 0.173991 loss)
I0130 03:41:29.648120  7239 solver.cpp:218] Iteration 63600 (2.45721 iter/s, 40.6965s/100 iters), loss = 0.00196612
I0130 03:41:29.648152  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019667 (* 1 = 0.0019667 loss)
I0130 03:41:29.648162  7239 sgd_solver.cpp:105] Iteration 63600, lr = 0.004
I0130 03:41:45.176111  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:41:52.802266  7239 solver.cpp:218] Iteration 63700 (4.31903 iter/s, 23.1534s/100 iters), loss = 0.0034425
I0130 03:41:52.802294  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344308 (* 1 = 0.00344308 loss)
I0130 03:41:52.802302  7239 sgd_solver.cpp:105] Iteration 63700, lr = 0.004
I0130 03:42:16.276338  7239 solver.cpp:218] Iteration 63800 (4.26016 iter/s, 23.4733s/100 iters), loss = 0.00131628
I0130 03:42:16.276402  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131686 (* 1 = 0.00131686 loss)
I0130 03:42:16.276412  7239 sgd_solver.cpp:105] Iteration 63800, lr = 0.004
I0130 03:42:40.133486  7239 solver.cpp:218] Iteration 63900 (4.19177 iter/s, 23.8563s/100 iters), loss = 0.00122288
I0130 03:42:40.133513  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122346 (* 1 = 0.00122346 loss)
I0130 03:42:40.133520  7239 sgd_solver.cpp:105] Iteration 63900, lr = 0.004
I0130 03:43:03.306735  7239 solver.cpp:330] Iteration 64000, Testing net (#0)
I0130 03:43:19.950947  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:43:20.290477  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.954201
I0130 03:43:20.290503  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.170821 (* 1 = 0.170821 loss)
I0130 03:43:20.535322  7239 solver.cpp:218] Iteration 64000 (2.47522 iter/s, 40.4005s/100 iters), loss = 0.00204621
I0130 03:43:20.535346  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020468 (* 1 = 0.0020468 loss)
I0130 03:43:20.535358  7239 sgd_solver.cpp:46] MultiStep Status: Iteration 64000, step = 3
I0130 03:43:20.535362  7239 sgd_solver.cpp:105] Iteration 64000, lr = 0.0008
I0130 03:43:20.535359  7266 sgd_solver.cpp:46] MultiStep Status: Iteration 64000, step = 3
I0130 03:43:20.535359  7267 sgd_solver.cpp:46] MultiStep Status: Iteration 64000, step = 3
I0130 03:43:20.535359  7265 sgd_solver.cpp:46] MultiStep Status: Iteration 64000, step = 3
I0130 03:43:34.128255  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:43:43.837241  7239 solver.cpp:218] Iteration 64100 (4.29164 iter/s, 23.3011s/100 iters), loss = 0.00198581
I0130 03:43:43.837270  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019864 (* 1 = 0.0019864 loss)
I0130 03:43:43.837278  7239 sgd_solver.cpp:105] Iteration 64100, lr = 0.0008
I0130 03:44:07.259495  7239 solver.cpp:218] Iteration 64200 (4.26959 iter/s, 23.4214s/100 iters), loss = 0.00324786
I0130 03:44:07.260495  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324844 (* 1 = 0.00324844 loss)
I0130 03:44:07.260509  7239 sgd_solver.cpp:105] Iteration 64200, lr = 0.0008
I0130 03:44:30.930263  7239 solver.cpp:218] Iteration 64300 (4.22494 iter/s, 23.669s/100 iters), loss = 0.00176216
I0130 03:44:30.930290  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176275 (* 1 = 0.00176275 loss)
I0130 03:44:30.930299  7239 sgd_solver.cpp:105] Iteration 64300, lr = 0.0008
I0130 03:44:54.298729  7239 solver.cpp:330] Iteration 64400, Testing net (#0)
I0130 03:45:10.882361  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:45:11.219679  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9578
I0130 03:45:11.219702  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.164911 (* 1 = 0.164911 loss)
I0130 03:45:11.468199  7239 solver.cpp:218] Iteration 64400 (2.46691 iter/s, 40.5365s/100 iters), loss = 0.0015503
I0130 03:45:11.468225  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155088 (* 1 = 0.00155088 loss)
I0130 03:45:11.468232  7239 sgd_solver.cpp:105] Iteration 64400, lr = 0.0008
I0130 03:45:22.819092  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:45:34.717402  7239 solver.cpp:218] Iteration 64500 (4.30138 iter/s, 23.2484s/100 iters), loss = 0.00188097
I0130 03:45:34.718174  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188156 (* 1 = 0.00188156 loss)
I0130 03:45:34.718183  7239 sgd_solver.cpp:105] Iteration 64500, lr = 0.0008
I0130 03:45:58.350257  7239 solver.cpp:218] Iteration 64600 (4.23168 iter/s, 23.6313s/100 iters), loss = 0.00151212
I0130 03:45:58.350284  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151271 (* 1 = 0.00151271 loss)
I0130 03:45:58.350292  7239 sgd_solver.cpp:105] Iteration 64600, lr = 0.0008
I0130 03:46:21.841753  7239 solver.cpp:218] Iteration 64700 (4.25701 iter/s, 23.4907s/100 iters), loss = 0.00338049
I0130 03:46:21.845455  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338107 (* 1 = 0.00338107 loss)
I0130 03:46:21.845464  7239 sgd_solver.cpp:105] Iteration 64700, lr = 0.0008
I0130 03:46:45.020920  7239 solver.cpp:330] Iteration 64800, Testing net (#0)
I0130 03:47:01.963838  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:47:02.318470  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.958501
I0130 03:47:02.318495  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.161154 (* 1 = 0.161154 loss)
I0130 03:47:02.565757  7239 solver.cpp:218] Iteration 64800 (2.45586 iter/s, 40.7189s/100 iters), loss = 0.0043907
I0130 03:47:02.565781  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439128 (* 1 = 0.00439128 loss)
I0130 03:47:02.565788  7239 sgd_solver.cpp:105] Iteration 64800, lr = 0.0008
I0130 03:47:11.543030  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:47:25.801407  7239 solver.cpp:218] Iteration 64900 (4.30389 iter/s, 23.2348s/100 iters), loss = 0.00141726
I0130 03:47:25.801442  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141785 (* 1 = 0.00141785 loss)
I0130 03:47:25.801453  7239 sgd_solver.cpp:105] Iteration 64900, lr = 0.0008
I0130 03:47:49.443446  7239 solver.cpp:218] Iteration 65000 (4.22991 iter/s, 23.6412s/100 iters), loss = 0.00142981
I0130 03:47:49.443539  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143039 (* 1 = 0.00143039 loss)
I0130 03:47:49.443549  7239 sgd_solver.cpp:105] Iteration 65000, lr = 0.0008
I0130 03:48:13.292361  7239 solver.cpp:218] Iteration 65100 (4.19323 iter/s, 23.848s/100 iters), loss = 0.00266337
I0130 03:48:13.292399  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266395 (* 1 = 0.00266395 loss)
I0130 03:48:13.292410  7239 sgd_solver.cpp:105] Iteration 65100, lr = 0.0008
I0130 03:48:36.351529  7239 solver.cpp:330] Iteration 65200, Testing net (#0)
I0130 03:48:53.185750  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:48:53.522156  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9597
I0130 03:48:53.522181  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.158191 (* 1 = 0.158191 loss)
I0130 03:48:53.764552  7239 solver.cpp:218] Iteration 65200 (2.47092 iter/s, 40.4707s/100 iters), loss = 0.00273866
I0130 03:48:53.764577  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273924 (* 1 = 0.00273924 loss)
I0130 03:48:53.764591  7239 sgd_solver.cpp:105] Iteration 65200, lr = 0.0008
I0130 03:49:00.747043  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:49:16.979537  7239 solver.cpp:218] Iteration 65300 (4.30772 iter/s, 23.2141s/100 iters), loss = 0.0015612
I0130 03:49:16.979609  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156178 (* 1 = 0.00156178 loss)
I0130 03:49:16.979616  7239 sgd_solver.cpp:105] Iteration 65300, lr = 0.0008
I0130 03:49:40.783586  7239 solver.cpp:218] Iteration 65400 (4.20113 iter/s, 23.8031s/100 iters), loss = 0.00202337
I0130 03:49:40.783620  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202395 (* 1 = 0.00202395 loss)
I0130 03:49:40.783632  7239 sgd_solver.cpp:105] Iteration 65400, lr = 0.0008
I0130 03:50:04.392851  7239 solver.cpp:218] Iteration 65500 (4.23578 iter/s, 23.6084s/100 iters), loss = 0.00165374
I0130 03:50:04.392920  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165432 (* 1 = 0.00165432 loss)
I0130 03:50:04.392927  7239 sgd_solver.cpp:105] Iteration 65500, lr = 0.0008
I0130 03:50:27.913854  7239 solver.cpp:330] Iteration 65600, Testing net (#0)
I0130 03:50:44.523288  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:50:44.858676  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9593
I0130 03:50:44.858698  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.157739 (* 1 = 0.157739 loss)
I0130 03:50:45.101694  7239 solver.cpp:218] Iteration 65600 (2.45656 iter/s, 40.7073s/100 iters), loss = 0.00108824
I0130 03:50:45.101717  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108882 (* 1 = 0.00108882 loss)
I0130 03:50:45.101732  7239 sgd_solver.cpp:105] Iteration 65600, lr = 0.0008
I0130 03:50:49.936640  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:51:08.269440  7239 solver.cpp:218] Iteration 65700 (4.31651 iter/s, 23.1669s/100 iters), loss = 0.00158108
I0130 03:51:08.269469  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158166 (* 1 = 0.00158166 loss)
I0130 03:51:08.269476  7239 sgd_solver.cpp:105] Iteration 65700, lr = 0.0008
I0130 03:51:31.613906  7239 solver.cpp:218] Iteration 65800 (4.28383 iter/s, 23.3436s/100 iters), loss = 0.00130383
I0130 03:51:31.613972  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130442 (* 1 = 0.00130442 loss)
I0130 03:51:31.613981  7239 sgd_solver.cpp:105] Iteration 65800, lr = 0.0008
I0130 03:51:55.044693  7239 solver.cpp:218] Iteration 65900 (4.26806 iter/s, 23.4299s/100 iters), loss = 0.00249468
I0130 03:51:55.044723  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249527 (* 1 = 0.00249527 loss)
I0130 03:51:55.044729  7239 sgd_solver.cpp:105] Iteration 65900, lr = 0.0008
I0130 03:52:18.490028  7239 solver.cpp:330] Iteration 66000, Testing net (#0)
I0130 03:52:35.255995  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:52:35.596113  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9601
I0130 03:52:35.596135  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156878 (* 1 = 0.156878 loss)
I0130 03:52:35.837759  7239 solver.cpp:218] Iteration 66000 (2.45149 iter/s, 40.7916s/100 iters), loss = 0.00171028
I0130 03:52:35.837783  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171086 (* 1 = 0.00171086 loss)
I0130 03:52:35.837796  7239 sgd_solver.cpp:105] Iteration 66000, lr = 0.0008
I0130 03:52:38.457098  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:52:59.230075  7239 solver.cpp:218] Iteration 66100 (4.27507 iter/s, 23.3914s/100 iters), loss = 0.00212038
I0130 03:52:59.230152  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212096 (* 1 = 0.00212096 loss)
I0130 03:52:59.230160  7239 sgd_solver.cpp:105] Iteration 66100, lr = 0.0008
I0130 03:53:22.641248  7239 solver.cpp:218] Iteration 66200 (4.27164 iter/s, 23.4102s/100 iters), loss = 0.00149198
I0130 03:53:22.641276  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149256 (* 1 = 0.00149256 loss)
I0130 03:53:22.641284  7239 sgd_solver.cpp:105] Iteration 66200, lr = 0.0008
I0130 03:53:46.110009  7239 solver.cpp:218] Iteration 66300 (4.26115 iter/s, 23.4679s/100 iters), loss = 0.00643779
I0130 03:53:46.110079  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00643837 (* 1 = 0.00643837 loss)
I0130 03:53:46.110087  7239 sgd_solver.cpp:105] Iteration 66300, lr = 0.0008
I0130 03:54:09.467392  7239 solver.cpp:330] Iteration 66400, Testing net (#0)
I0130 03:54:26.180866  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:54:26.507618  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96
I0130 03:54:26.507647  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156163 (* 1 = 0.156163 loss)
I0130 03:54:26.753612  7239 solver.cpp:218] Iteration 66400 (2.46051 iter/s, 40.6421s/100 iters), loss = 0.00149759
I0130 03:54:26.753638  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149817 (* 1 = 0.00149817 loss)
I0130 03:54:26.753645  7239 sgd_solver.cpp:105] Iteration 66400, lr = 0.0008
I0130 03:54:27.241613  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:54:49.855767  7239 solver.cpp:218] Iteration 66500 (4.32876 iter/s, 23.1013s/100 iters), loss = 0.00154695
I0130 03:54:49.855796  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154753 (* 1 = 0.00154753 loss)
I0130 03:54:49.855806  7239 sgd_solver.cpp:105] Iteration 66500, lr = 0.0008
I0130 03:55:13.408267  7239 solver.cpp:218] Iteration 66600 (4.246 iter/s, 23.5516s/100 iters), loss = 0.00269968
I0130 03:55:13.408330  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270026 (* 1 = 0.00270026 loss)
I0130 03:55:13.408341  7239 sgd_solver.cpp:105] Iteration 66600, lr = 0.0008
I0130 03:55:36.942152  7239 solver.cpp:218] Iteration 66700 (4.24936 iter/s, 23.533s/100 iters), loss = 0.0019033
I0130 03:55:36.942179  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190388 (* 1 = 0.00190388 loss)
I0130 03:55:36.942186  7239 sgd_solver.cpp:105] Iteration 66700, lr = 0.0008
I0130 03:55:58.553146  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:56:00.258167  7239 solver.cpp:330] Iteration 66800, Testing net (#0)
I0130 03:56:16.852970  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:56:17.189775  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9603
I0130 03:56:17.189798  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155398 (* 1 = 0.155398 loss)
I0130 03:56:17.439755  7239 solver.cpp:218] Iteration 66800 (2.46937 iter/s, 40.4961s/100 iters), loss = 0.00181024
I0130 03:56:17.439785  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181082 (* 1 = 0.00181082 loss)
I0130 03:56:17.439792  7239 sgd_solver.cpp:105] Iteration 66800, lr = 0.0008
I0130 03:56:40.407600  7239 solver.cpp:218] Iteration 66900 (4.35408 iter/s, 22.967s/100 iters), loss = 0.00152727
I0130 03:56:40.408615  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152785 (* 1 = 0.00152785 loss)
I0130 03:56:40.408624  7239 sgd_solver.cpp:105] Iteration 66900, lr = 0.0008
I0130 03:57:04.100191  7239 solver.cpp:218] Iteration 67000 (4.22107 iter/s, 23.6907s/100 iters), loss = 0.00222821
I0130 03:57:04.100226  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222879 (* 1 = 0.00222879 loss)
I0130 03:57:04.100236  7239 sgd_solver.cpp:105] Iteration 67000, lr = 0.0008
I0130 03:57:27.935761  7239 solver.cpp:218] Iteration 67100 (4.19557 iter/s, 23.8347s/100 iters), loss = 0.00125344
I0130 03:57:27.935829  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125402 (* 1 = 0.00125402 loss)
I0130 03:57:27.935838  7239 sgd_solver.cpp:105] Iteration 67100, lr = 0.0008
I0130 03:57:47.480216  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:57:51.237761  7239 solver.cpp:330] Iteration 67200, Testing net (#0)
I0130 03:58:07.617087  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:58:07.955907  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9608
I0130 03:58:07.955929  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155466 (* 1 = 0.155466 loss)
I0130 03:58:08.198451  7239 solver.cpp:218] Iteration 67200 (2.48378 iter/s, 40.2611s/100 iters), loss = 0.00187725
I0130 03:58:08.198473  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187784 (* 1 = 0.00187784 loss)
I0130 03:58:08.198489  7239 sgd_solver.cpp:105] Iteration 67200, lr = 0.0008
I0130 03:58:31.321730  7239 solver.cpp:218] Iteration 67300 (4.32481 iter/s, 23.1224s/100 iters), loss = 0.00176099
I0130 03:58:31.321759  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176157 (* 1 = 0.00176157 loss)
I0130 03:58:31.321768  7239 sgd_solver.cpp:105] Iteration 67300, lr = 0.0008
I0130 03:58:54.784015  7239 solver.cpp:218] Iteration 67400 (4.26232 iter/s, 23.4614s/100 iters), loss = 0.00120645
I0130 03:58:54.784090  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120703 (* 1 = 0.00120703 loss)
I0130 03:58:54.784097  7239 sgd_solver.cpp:105] Iteration 67400, lr = 0.0008
I0130 03:59:18.426875  7239 solver.cpp:218] Iteration 67500 (4.22978 iter/s, 23.6419s/100 iters), loss = 0.00155724
I0130 03:59:18.426903  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155782 (* 1 = 0.00155782 loss)
I0130 03:59:18.426910  7239 sgd_solver.cpp:105] Iteration 67500, lr = 0.0008
I0130 03:59:36.302122  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:59:42.135418  7239 solver.cpp:330] Iteration 67600, Testing net (#0)
I0130 03:59:58.603518  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 03:59:58.946662  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9601
I0130 03:59:58.946684  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156223 (* 1 = 0.156223 loss)
I0130 03:59:59.188779  7239 solver.cpp:218] Iteration 67600 (2.45336 iter/s, 40.7604s/100 iters), loss = 0.000971146
I0130 03:59:59.188802  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000971726 (* 1 = 0.000971726 loss)
I0130 03:59:59.188815  7239 sgd_solver.cpp:105] Iteration 67600, lr = 0.0008
I0130 04:00:22.283224  7239 solver.cpp:218] Iteration 67700 (4.33021 iter/s, 23.0936s/100 iters), loss = 0.00117959
I0130 04:00:22.283290  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118017 (* 1 = 0.00118017 loss)
I0130 04:00:22.283298  7239 sgd_solver.cpp:105] Iteration 67700, lr = 0.0008
I0130 04:00:45.872011  7239 solver.cpp:218] Iteration 67800 (4.23947 iter/s, 23.5878s/100 iters), loss = 0.00187816
I0130 04:00:45.872041  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187874 (* 1 = 0.00187874 loss)
I0130 04:00:45.872050  7239 sgd_solver.cpp:105] Iteration 67800, lr = 0.0008
I0130 04:01:09.640933  7239 solver.cpp:218] Iteration 67900 (4.20734 iter/s, 23.768s/100 iters), loss = 0.00215623
I0130 04:01:09.641016  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215681 (* 1 = 0.00215681 loss)
I0130 04:01:09.641026  7239 sgd_solver.cpp:105] Iteration 67900, lr = 0.0008
I0130 04:01:24.592890  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:01:32.747946  7239 solver.cpp:330] Iteration 68000, Testing net (#0)
I0130 04:01:49.573071  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:01:49.918782  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9604
I0130 04:01:49.918807  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155363 (* 1 = 0.155363 loss)
I0130 04:01:50.166074  7239 solver.cpp:218] Iteration 68000 (2.4677 iter/s, 40.5236s/100 iters), loss = 0.00150498
I0130 04:01:50.166097  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150556 (* 1 = 0.00150556 loss)
I0130 04:01:50.166113  7239 sgd_solver.cpp:105] Iteration 68000, lr = 0.0008
I0130 04:02:13.288492  7239 solver.cpp:218] Iteration 68100 (4.32497 iter/s, 23.1215s/100 iters), loss = 0.00141747
I0130 04:02:13.288522  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141805 (* 1 = 0.00141805 loss)
I0130 04:02:13.288528  7239 sgd_solver.cpp:105] Iteration 68100, lr = 0.0008
I0130 04:02:36.965505  7239 solver.cpp:218] Iteration 68200 (4.22367 iter/s, 23.6761s/100 iters), loss = 0.00206692
I0130 04:02:36.965576  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020675 (* 1 = 0.0020675 loss)
I0130 04:02:36.965589  7239 sgd_solver.cpp:105] Iteration 68200, lr = 0.0008
I0130 04:03:00.286464  7239 solver.cpp:218] Iteration 68300 (4.28816 iter/s, 23.32s/100 iters), loss = 0.00117659
I0130 04:03:00.286495  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117717 (* 1 = 0.00117717 loss)
I0130 04:03:00.286506  7239 sgd_solver.cpp:105] Iteration 68300, lr = 0.0008
I0130 04:03:13.029784  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:03:23.333617  7239 solver.cpp:330] Iteration 68400, Testing net (#0)
I0130 04:03:40.147542  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:03:40.488641  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9607
I0130 04:03:40.488668  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.154931 (* 1 = 0.154931 loss)
I0130 04:03:40.736843  7239 solver.cpp:218] Iteration 68400 (2.47226 iter/s, 40.4488s/100 iters), loss = 0.00127395
I0130 04:03:40.736870  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127453 (* 1 = 0.00127453 loss)
I0130 04:03:40.736881  7239 sgd_solver.cpp:105] Iteration 68400, lr = 0.0008
I0130 04:04:03.937403  7239 solver.cpp:218] Iteration 68500 (4.31041 iter/s, 23.1997s/100 iters), loss = 0.0018498
I0130 04:04:03.937476  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185038 (* 1 = 0.00185038 loss)
I0130 04:04:03.937485  7239 sgd_solver.cpp:105] Iteration 68500, lr = 0.0008
I0130 04:04:27.571316  7239 solver.cpp:218] Iteration 68600 (4.23138 iter/s, 23.633s/100 iters), loss = 0.00368861
I0130 04:04:27.571353  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00368919 (* 1 = 0.00368919 loss)
I0130 04:04:27.571364  7239 sgd_solver.cpp:105] Iteration 68600, lr = 0.0008
I0130 04:04:51.042608  7239 solver.cpp:218] Iteration 68700 (4.26069 iter/s, 23.4704s/100 iters), loss = 0.0011549
I0130 04:04:51.042680  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115548 (* 1 = 0.00115548 loss)
I0130 04:04:51.042688  7239 sgd_solver.cpp:105] Iteration 68700, lr = 0.0008
I0130 04:05:01.942827  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:05:14.385128  7239 solver.cpp:330] Iteration 68800, Testing net (#0)
I0130 04:05:30.930039  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:05:31.264333  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9601
I0130 04:05:31.264358  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.15638 (* 1 = 0.15638 loss)
I0130 04:05:31.506664  7239 solver.cpp:218] Iteration 68800 (2.47143 iter/s, 40.4625s/100 iters), loss = 0.00268348
I0130 04:05:31.506690  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268406 (* 1 = 0.00268406 loss)
I0130 04:05:31.506701  7239 sgd_solver.cpp:105] Iteration 68800, lr = 0.0008
I0130 04:05:54.714507  7239 solver.cpp:218] Iteration 68900 (4.30901 iter/s, 23.2072s/100 iters), loss = 0.00140284
I0130 04:05:54.714534  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140342 (* 1 = 0.00140342 loss)
I0130 04:05:54.714542  7239 sgd_solver.cpp:105] Iteration 68900, lr = 0.0008
I0130 04:06:18.115476  7239 solver.cpp:218] Iteration 69000 (4.27343 iter/s, 23.4004s/100 iters), loss = 0.00553784
I0130 04:06:18.115553  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00553842 (* 1 = 0.00553842 loss)
I0130 04:06:18.115563  7239 sgd_solver.cpp:105] Iteration 69000, lr = 0.0008
I0130 04:06:41.862237  7239 solver.cpp:218] Iteration 69100 (4.21121 iter/s, 23.7461s/100 iters), loss = 0.00473982
I0130 04:06:41.862265  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047404 (* 1 = 0.0047404 loss)
I0130 04:06:41.862274  7239 sgd_solver.cpp:105] Iteration 69100, lr = 0.0008
I0130 04:06:50.232563  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:07:05.402907  7239 solver.cpp:330] Iteration 69200, Testing net (#0)
I0130 04:07:21.786339  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:07:22.122779  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9611
I0130 04:07:22.122803  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155194 (* 1 = 0.155194 loss)
I0130 04:07:22.376569  7239 solver.cpp:218] Iteration 69200 (2.46832 iter/s, 40.5134s/100 iters), loss = 0.00137977
I0130 04:07:22.376597  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138035 (* 1 = 0.00138035 loss)
I0130 04:07:22.376605  7239 sgd_solver.cpp:105] Iteration 69200, lr = 0.0008
I0130 04:07:45.679337  7239 solver.cpp:218] Iteration 69300 (4.29145 iter/s, 23.3022s/100 iters), loss = 0.00235057
I0130 04:07:45.679368  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235114 (* 1 = 0.00235114 loss)
I0130 04:07:45.679375  7239 sgd_solver.cpp:105] Iteration 69300, lr = 0.0008
I0130 04:08:09.043928  7239 solver.cpp:218] Iteration 69400 (4.28009 iter/s, 23.364s/100 iters), loss = 0.00434041
I0130 04:08:09.044000  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00434099 (* 1 = 0.00434099 loss)
I0130 04:08:09.044010  7239 sgd_solver.cpp:105] Iteration 69400, lr = 0.0008
I0130 04:08:32.498780  7239 solver.cpp:218] Iteration 69500 (4.26363 iter/s, 23.4542s/100 iters), loss = 0.00192636
I0130 04:08:32.498806  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192694 (* 1 = 0.00192694 loss)
I0130 04:08:32.498817  7239 sgd_solver.cpp:105] Iteration 69500, lr = 0.0008
I0130 04:08:38.878113  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:08:55.830173  7239 solver.cpp:330] Iteration 69600, Testing net (#0)
I0130 04:09:12.634467  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:09:12.970950  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9608
I0130 04:09:12.970989  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.153923 (* 1 = 0.153923 loss)
I0130 04:09:13.219249  7239 solver.cpp:218] Iteration 69600 (2.45583 iter/s, 40.7194s/100 iters), loss = 0.00147973
I0130 04:09:13.219271  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148031 (* 1 = 0.00148031 loss)
I0130 04:09:13.219282  7239 sgd_solver.cpp:105] Iteration 69600, lr = 0.0008
I0130 04:09:36.535791  7239 solver.cpp:218] Iteration 69700 (4.28892 iter/s, 23.3159s/100 iters), loss = 0.00190715
I0130 04:09:36.535889  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190773 (* 1 = 0.00190773 loss)
I0130 04:09:36.535898  7239 sgd_solver.cpp:105] Iteration 69700, lr = 0.0008
I0130 04:09:59.758306  7239 solver.cpp:218] Iteration 69800 (4.3063 iter/s, 23.2218s/100 iters), loss = 0.00186458
I0130 04:09:59.758333  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186516 (* 1 = 0.00186516 loss)
I0130 04:09:59.758342  7239 sgd_solver.cpp:105] Iteration 69800, lr = 0.0008
I0130 04:10:23.493645  7239 solver.cpp:218] Iteration 69900 (4.21325 iter/s, 23.7347s/100 iters), loss = 0.00176533
I0130 04:10:23.493753  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176591 (* 1 = 0.00176591 loss)
I0130 04:10:23.493763  7239 sgd_solver.cpp:105] Iteration 69900, lr = 0.0008
I0130 04:10:27.424935  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:10:46.948633  7239 solver.cpp:330] Iteration 70000, Testing net (#0)
I0130 04:11:03.517503  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:11:03.856118  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9607
I0130 04:11:03.856142  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155373 (* 1 = 0.155373 loss)
I0130 04:11:04.107010  7239 solver.cpp:218] Iteration 70000 (2.46232 iter/s, 40.6121s/100 iters), loss = 0.0012176
I0130 04:11:04.107035  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121818 (* 1 = 0.00121818 loss)
I0130 04:11:04.107044  7239 sgd_solver.cpp:105] Iteration 70000, lr = 0.0008
I0130 04:11:27.312419  7239 solver.cpp:218] Iteration 70100 (4.30947 iter/s, 23.2047s/100 iters), loss = 0.00238681
I0130 04:11:27.312446  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238739 (* 1 = 0.00238739 loss)
I0130 04:11:27.312454  7239 sgd_solver.cpp:105] Iteration 70100, lr = 0.0008
I0130 04:11:50.522953  7239 solver.cpp:218] Iteration 70200 (4.30852 iter/s, 23.2098s/100 iters), loss = 0.00227261
I0130 04:11:50.523216  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227319 (* 1 = 0.00227319 loss)
I0130 04:11:50.523226  7239 sgd_solver.cpp:105] Iteration 70200, lr = 0.0008
I0130 04:12:13.848585  7239 solver.cpp:218] Iteration 70300 (4.2873 iter/s, 23.3247s/100 iters), loss = 0.00182992
I0130 04:12:13.848613  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183049 (* 1 = 0.00183049 loss)
I0130 04:12:13.848619  7239 sgd_solver.cpp:105] Iteration 70300, lr = 0.0008
I0130 04:12:15.703522  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:12:37.025673  7239 solver.cpp:330] Iteration 70400, Testing net (#0)
I0130 04:12:53.798406  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:12:54.139349  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9607
I0130 04:12:54.139376  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155517 (* 1 = 0.155517 loss)
I0130 04:12:54.381825  7239 solver.cpp:218] Iteration 70400 (2.46718 iter/s, 40.532s/100 iters), loss = 0.00163687
I0130 04:12:54.381850  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163745 (* 1 = 0.00163745 loss)
I0130 04:12:54.381867  7239 sgd_solver.cpp:105] Iteration 70400, lr = 0.0008
I0130 04:13:17.644207  7239 solver.cpp:218] Iteration 70500 (4.29892 iter/s, 23.2617s/100 iters), loss = 0.00147071
I0130 04:13:17.644274  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147129 (* 1 = 0.00147129 loss)
I0130 04:13:17.644284  7239 sgd_solver.cpp:105] Iteration 70500, lr = 0.0008
I0130 04:13:40.992935  7239 solver.cpp:218] Iteration 70600 (4.28303 iter/s, 23.348s/100 iters), loss = 0.00132375
I0130 04:13:40.992962  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132433 (* 1 = 0.00132433 loss)
I0130 04:13:40.992971  7239 sgd_solver.cpp:105] Iteration 70600, lr = 0.0008
I0130 04:14:04.065127  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:14:04.301666  7239 solver.cpp:218] Iteration 70700 (4.29037 iter/s, 23.308s/100 iters), loss = 0.00181821
I0130 04:14:04.301694  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181879 (* 1 = 0.00181879 loss)
I0130 04:14:04.301702  7239 sgd_solver.cpp:105] Iteration 70700, lr = 0.0008
I0130 04:14:27.530617  7239 solver.cpp:330] Iteration 70800, Testing net (#0)
I0130 04:14:44.196233  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:14:44.534400  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9602
I0130 04:14:44.534423  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156426 (* 1 = 0.156426 loss)
I0130 04:14:44.777007  7239 solver.cpp:218] Iteration 70800 (2.47072 iter/s, 40.4741s/100 iters), loss = 0.00103525
I0130 04:14:44.777036  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103583 (* 1 = 0.00103583 loss)
I0130 04:14:44.777047  7239 sgd_solver.cpp:105] Iteration 70800, lr = 0.0008
I0130 04:15:07.649199  7239 solver.cpp:218] Iteration 70900 (4.37226 iter/s, 22.8715s/100 iters), loss = 0.00224393
I0130 04:15:07.649227  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224451 (* 1 = 0.00224451 loss)
I0130 04:15:07.649235  7239 sgd_solver.cpp:105] Iteration 70900, lr = 0.0008
I0130 04:15:31.025892  7239 solver.cpp:218] Iteration 71000 (4.2779 iter/s, 23.3759s/100 iters), loss = 0.00308111
I0130 04:15:31.029937  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308169 (* 1 = 0.00308169 loss)
I0130 04:15:31.029954  7239 sgd_solver.cpp:105] Iteration 71000, lr = 0.0008
I0130 04:15:52.407122  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:15:55.103570  7239 solver.cpp:218] Iteration 71100 (4.15405 iter/s, 24.0729s/100 iters), loss = 0.00418689
I0130 04:15:55.103598  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418747 (* 1 = 0.00418747 loss)
I0130 04:15:55.103606  7239 sgd_solver.cpp:105] Iteration 71100, lr = 0.0008
I0130 04:16:18.403228  7239 solver.cpp:330] Iteration 71200, Testing net (#0)
I0130 04:16:35.045410  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:16:35.378343  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9604
I0130 04:16:35.378366  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156086 (* 1 = 0.156086 loss)
I0130 04:16:35.618319  7239 solver.cpp:218] Iteration 71200 (2.46832 iter/s, 40.5135s/100 iters), loss = 0.00150319
I0130 04:16:35.618343  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150377 (* 1 = 0.00150377 loss)
I0130 04:16:35.618353  7239 sgd_solver.cpp:105] Iteration 71200, lr = 0.0008
I0130 04:16:58.982097  7239 solver.cpp:218] Iteration 71300 (4.28027 iter/s, 23.363s/100 iters), loss = 0.00151342
I0130 04:16:58.982285  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001514 (* 1 = 0.001514 loss)
I0130 04:16:58.982296  7239 sgd_solver.cpp:105] Iteration 71300, lr = 0.0008
I0130 04:17:22.367259  7239 solver.cpp:218] Iteration 71400 (4.27639 iter/s, 23.3842s/100 iters), loss = 0.00147429
I0130 04:17:22.367286  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147487 (* 1 = 0.00147487 loss)
I0130 04:17:22.367293  7239 sgd_solver.cpp:105] Iteration 71400, lr = 0.0008
I0130 04:17:41.258985  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:17:46.047765  7239 solver.cpp:218] Iteration 71500 (4.22302 iter/s, 23.6797s/100 iters), loss = 0.000927315
I0130 04:17:46.047792  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000927896 (* 1 = 0.000927896 loss)
I0130 04:17:46.047799  7239 sgd_solver.cpp:105] Iteration 71500, lr = 0.0008
I0130 04:18:09.160301  7239 solver.cpp:330] Iteration 71600, Testing net (#0)
I0130 04:18:25.833155  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:18:26.167455  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9597
I0130 04:18:26.167477  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156205 (* 1 = 0.156205 loss)
I0130 04:18:26.412098  7239 solver.cpp:218] Iteration 71600 (2.47752 iter/s, 40.363s/100 iters), loss = 0.00151512
I0130 04:18:26.412127  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015157 (* 1 = 0.0015157 loss)
I0130 04:18:26.412135  7239 sgd_solver.cpp:105] Iteration 71600, lr = 0.0008
I0130 04:18:49.768286  7239 solver.cpp:218] Iteration 71700 (4.28167 iter/s, 23.3554s/100 iters), loss = 0.00102179
I0130 04:18:49.768316  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102237 (* 1 = 0.00102237 loss)
I0130 04:18:49.768324  7239 sgd_solver.cpp:105] Iteration 71700, lr = 0.0008
I0130 04:19:13.341069  7239 solver.cpp:218] Iteration 71800 (4.24232 iter/s, 23.572s/100 iters), loss = 0.00168081
I0130 04:19:13.341159  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168139 (* 1 = 0.00168139 loss)
I0130 04:19:13.341172  7239 sgd_solver.cpp:105] Iteration 71800, lr = 0.0008
I0130 04:19:30.225976  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:19:37.026576  7239 solver.cpp:218] Iteration 71900 (4.22214 iter/s, 23.6846s/100 iters), loss = 0.00219623
I0130 04:19:37.026603  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219681 (* 1 = 0.00219681 loss)
I0130 04:19:37.026610  7239 sgd_solver.cpp:105] Iteration 71900, lr = 0.0008
I0130 04:20:00.078064  7239 solver.cpp:447] Snapshotting to binary proto file examples/bao/WRN-28_iter_72000.caffemodel
I0130 04:20:00.447927  7239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/bao/WRN-28_iter_72000.solverstate
I0130 04:20:00.644512  7239 solver.cpp:330] Iteration 72000, Testing net (#0)
I0130 04:20:17.478739  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:20:17.816759  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9603
I0130 04:20:17.816783  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155978 (* 1 = 0.155978 loss)
I0130 04:20:18.060331  7239 solver.cpp:218] Iteration 72000 (2.4371 iter/s, 41.0324s/100 iters), loss = 0.0026441
I0130 04:20:18.060354  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264468 (* 1 = 0.00264468 loss)
I0130 04:20:18.060372  7239 sgd_solver.cpp:105] Iteration 72000, lr = 0.0008
I0130 04:20:41.288852  7239 solver.cpp:218] Iteration 72100 (4.3052 iter/s, 23.2277s/100 iters), loss = 0.00154173
I0130 04:20:41.288923  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154231 (* 1 = 0.00154231 loss)
I0130 04:20:41.288930  7239 sgd_solver.cpp:105] Iteration 72100, lr = 0.0008
I0130 04:21:04.826802  7239 solver.cpp:218] Iteration 72200 (4.24861 iter/s, 23.5371s/100 iters), loss = 0.00170908
I0130 04:21:04.826829  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170966 (* 1 = 0.00170966 loss)
I0130 04:21:04.826836  7239 sgd_solver.cpp:105] Iteration 72200, lr = 0.0008
I0130 04:21:19.161115  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:21:28.360728  7239 solver.cpp:218] Iteration 72300 (4.24933 iter/s, 23.5331s/100 iters), loss = 0.00205621
I0130 04:21:28.360756  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020568 (* 1 = 0.0020568 loss)
I0130 04:21:28.360764  7239 sgd_solver.cpp:105] Iteration 72300, lr = 0.0008
I0130 04:21:51.612730  7239 solver.cpp:330] Iteration 72400, Testing net (#0)
I0130 04:22:08.437773  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:22:08.776273  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9602
I0130 04:22:08.776296  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155644 (* 1 = 0.155644 loss)
I0130 04:22:09.024585  7239 solver.cpp:218] Iteration 72400 (2.45927 iter/s, 40.6625s/100 iters), loss = 0.0019732
I0130 04:22:09.024610  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197378 (* 1 = 0.00197378 loss)
I0130 04:22:09.024619  7239 sgd_solver.cpp:105] Iteration 72400, lr = 0.0008
I0130 04:22:32.084802  7239 solver.cpp:218] Iteration 72500 (4.33662 iter/s, 23.0594s/100 iters), loss = 0.0018911
I0130 04:22:32.084898  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189168 (* 1 = 0.00189168 loss)
I0130 04:22:32.084908  7239 sgd_solver.cpp:105] Iteration 72500, lr = 0.0008
I0130 04:22:55.480963  7239 solver.cpp:218] Iteration 72600 (4.27437 iter/s, 23.3953s/100 iters), loss = 0.00154903
I0130 04:22:55.480990  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154961 (* 1 = 0.00154961 loss)
I0130 04:22:55.480998  7239 sgd_solver.cpp:105] Iteration 72600, lr = 0.0008
I0130 04:23:07.638180  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:23:19.043850  7239 solver.cpp:218] Iteration 72700 (4.24411 iter/s, 23.5621s/100 iters), loss = 0.00129967
I0130 04:23:19.043879  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130025 (* 1 = 0.00130025 loss)
I0130 04:23:19.043891  7239 sgd_solver.cpp:105] Iteration 72700, lr = 0.0008
I0130 04:23:42.469568  7239 solver.cpp:330] Iteration 72800, Testing net (#0)
I0130 04:23:59.012284  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:23:59.341311  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9609
I0130 04:23:59.341333  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155695 (* 1 = 0.155695 loss)
I0130 04:23:59.582156  7239 solver.cpp:218] Iteration 72800 (2.46689 iter/s, 40.5369s/100 iters), loss = 0.0023335
I0130 04:23:59.582180  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233408 (* 1 = 0.00233408 loss)
I0130 04:23:59.582195  7239 sgd_solver.cpp:105] Iteration 72800, lr = 0.0008
I0130 04:24:22.761301  7239 solver.cpp:218] Iteration 72900 (4.31437 iter/s, 23.1783s/100 iters), loss = 0.00199092
I0130 04:24:22.761368  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019915 (* 1 = 0.0019915 loss)
I0130 04:24:22.761378  7239 sgd_solver.cpp:105] Iteration 72900, lr = 0.0008
I0130 04:24:46.554457  7239 solver.cpp:218] Iteration 73000 (4.20304 iter/s, 23.7923s/100 iters), loss = 0.00203911
I0130 04:24:46.554492  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203969 (* 1 = 0.00203969 loss)
I0130 04:24:46.554502  7239 sgd_solver.cpp:105] Iteration 73000, lr = 0.0008
I0130 04:24:56.510499  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:25:10.231684  7239 solver.cpp:218] Iteration 73100 (4.22362 iter/s, 23.6764s/100 iters), loss = 0.00143793
I0130 04:25:10.231716  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143851 (* 1 = 0.00143851 loss)
I0130 04:25:10.231726  7239 sgd_solver.cpp:105] Iteration 73100, lr = 0.0008
I0130 04:25:33.721712  7239 solver.cpp:330] Iteration 73200, Testing net (#0)
I0130 04:25:50.140445  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:25:50.464653  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9605
I0130 04:25:50.464675  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155785 (* 1 = 0.155785 loss)
I0130 04:25:50.705551  7239 solver.cpp:218] Iteration 73200 (2.47082 iter/s, 40.4725s/100 iters), loss = 0.00136389
I0130 04:25:50.705574  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136447 (* 1 = 0.00136447 loss)
I0130 04:25:50.705588  7239 sgd_solver.cpp:105] Iteration 73200, lr = 0.0008
I0130 04:26:14.127740  7239 solver.cpp:218] Iteration 73300 (4.26961 iter/s, 23.4214s/100 iters), loss = 0.00218211
I0130 04:26:14.127811  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218269 (* 1 = 0.00218269 loss)
I0130 04:26:14.127820  7239 sgd_solver.cpp:105] Iteration 73300, lr = 0.0008
I0130 04:26:37.617429  7239 solver.cpp:218] Iteration 73400 (4.25735 iter/s, 23.4888s/100 iters), loss = 0.00161174
I0130 04:26:37.617455  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161232 (* 1 = 0.00161232 loss)
I0130 04:26:37.617463  7239 sgd_solver.cpp:105] Iteration 73400, lr = 0.0008
I0130 04:26:45.627457  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:27:01.606487  7239 solver.cpp:218] Iteration 73500 (4.16872 iter/s, 23.9882s/100 iters), loss = 0.00152263
I0130 04:27:01.606514  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152321 (* 1 = 0.00152321 loss)
I0130 04:27:01.606523  7239 sgd_solver.cpp:105] Iteration 73500, lr = 0.0008
I0130 04:27:24.864490  7239 solver.cpp:330] Iteration 73600, Testing net (#0)
I0130 04:27:41.517567  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:27:41.851528  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9607
I0130 04:27:41.851553  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155658 (* 1 = 0.155658 loss)
I0130 04:27:42.099395  7239 solver.cpp:218] Iteration 73600 (2.46965 iter/s, 40.4915s/100 iters), loss = 0.00156029
I0130 04:27:42.099422  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156087 (* 1 = 0.00156087 loss)
I0130 04:27:42.099431  7239 sgd_solver.cpp:105] Iteration 73600, lr = 0.0008
I0130 04:28:05.507704  7239 solver.cpp:218] Iteration 73700 (4.27214 iter/s, 23.4075s/100 iters), loss = 0.00218891
I0130 04:28:05.509621  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218949 (* 1 = 0.00218949 loss)
I0130 04:28:05.509631  7239 sgd_solver.cpp:105] Iteration 73700, lr = 0.0008
I0130 04:28:28.777063  7239 solver.cpp:218] Iteration 73800 (4.298 iter/s, 23.2666s/100 iters), loss = 0.00211801
I0130 04:28:28.777091  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211859 (* 1 = 0.00211859 loss)
I0130 04:28:28.777099  7239 sgd_solver.cpp:105] Iteration 73800, lr = 0.0008
I0130 04:28:34.392809  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:28:52.583901  7239 solver.cpp:218] Iteration 73900 (4.20062 iter/s, 23.806s/100 iters), loss = 0.00117325
I0130 04:28:52.583966  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117383 (* 1 = 0.00117383 loss)
I0130 04:28:52.583973  7239 sgd_solver.cpp:105] Iteration 73900, lr = 0.0008
I0130 04:29:15.847529  7239 solver.cpp:330] Iteration 74000, Testing net (#0)
I0130 04:29:32.744231  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:29:33.077433  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96
I0130 04:29:33.077456  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156644 (* 1 = 0.156644 loss)
I0130 04:29:33.321799  7239 solver.cpp:218] Iteration 74000 (2.4548 iter/s, 40.7364s/100 iters), loss = 0.00139474
I0130 04:29:33.321820  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139532 (* 1 = 0.00139532 loss)
I0130 04:29:33.321830  7239 sgd_solver.cpp:105] Iteration 74000, lr = 0.0008
I0130 04:29:56.662765  7239 solver.cpp:218] Iteration 74100 (4.28447 iter/s, 23.3401s/100 iters), loss = 0.0019474
I0130 04:29:56.662791  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194797 (* 1 = 0.00194797 loss)
I0130 04:29:56.662801  7239 sgd_solver.cpp:105] Iteration 74100, lr = 0.0008
I0130 04:30:20.063421  7239 solver.cpp:218] Iteration 74200 (4.27354 iter/s, 23.3998s/100 iters), loss = 0.00244034
I0130 04:30:20.064826  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244092 (* 1 = 0.00244092 loss)
I0130 04:30:20.064836  7239 sgd_solver.cpp:105] Iteration 74200, lr = 0.0008
I0130 04:30:23.339871  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:30:43.833860  7239 solver.cpp:218] Iteration 74300 (4.2073 iter/s, 23.7682s/100 iters), loss = 0.0018494
I0130 04:30:43.833889  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184997 (* 1 = 0.00184997 loss)
I0130 04:30:43.833899  7239 sgd_solver.cpp:105] Iteration 74300, lr = 0.0008
I0130 04:31:07.562088  7239 solver.cpp:330] Iteration 74400, Testing net (#0)
I0130 04:31:24.008587  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:31:24.345448  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9606
I0130 04:31:24.345474  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.15626 (* 1 = 0.15626 loss)
I0130 04:31:24.590859  7239 solver.cpp:218] Iteration 74400 (2.45365 iter/s, 40.7556s/100 iters), loss = 0.00148337
I0130 04:31:24.590885  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148395 (* 1 = 0.00148395 loss)
I0130 04:31:24.590898  7239 sgd_solver.cpp:105] Iteration 74400, lr = 0.0008
I0130 04:31:47.901326  7239 solver.cpp:218] Iteration 74500 (4.29007 iter/s, 23.3096s/100 iters), loss = 0.00168661
I0130 04:31:47.901415  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168719 (* 1 = 0.00168719 loss)
I0130 04:31:47.901424  7239 sgd_solver.cpp:105] Iteration 74500, lr = 0.0008
I0130 04:32:11.453689  7239 solver.cpp:218] Iteration 74600 (4.24602 iter/s, 23.5515s/100 iters), loss = 0.00141821
I0130 04:32:11.453718  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141879 (* 1 = 0.00141879 loss)
I0130 04:32:11.453727  7239 sgd_solver.cpp:105] Iteration 74600, lr = 0.0008
I0130 04:32:12.677860  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:32:35.126734  7239 solver.cpp:218] Iteration 74700 (4.22437 iter/s, 23.6722s/100 iters), loss = 0.0018526
I0130 04:32:35.126806  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185318 (* 1 = 0.00185318 loss)
I0130 04:32:35.126813  7239 sgd_solver.cpp:105] Iteration 74700, lr = 0.0008
I0130 04:32:58.620348  7239 solver.cpp:330] Iteration 74800, Testing net (#0)
I0130 04:33:15.095240  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:33:15.430397  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9604
I0130 04:33:15.430420  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155655 (* 1 = 0.155655 loss)
I0130 04:33:15.673077  7239 solver.cpp:218] Iteration 74800 (2.4664 iter/s, 40.5449s/100 iters), loss = 0.00158908
I0130 04:33:15.673100  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158966 (* 1 = 0.00158966 loss)
I0130 04:33:15.673115  7239 sgd_solver.cpp:105] Iteration 74800, lr = 0.0008
I0130 04:33:39.062039  7239 solver.cpp:218] Iteration 74900 (4.27568 iter/s, 23.3881s/100 iters), loss = 0.00262545
I0130 04:33:39.062067  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262602 (* 1 = 0.00262602 loss)
I0130 04:33:39.062074  7239 sgd_solver.cpp:105] Iteration 74900, lr = 0.0008
I0130 04:34:01.411656  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:34:02.328502  7239 solver.cpp:218] Iteration 75000 (4.29819 iter/s, 23.2656s/100 iters), loss = 0.00120446
I0130 04:34:02.328529  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120503 (* 1 = 0.00120503 loss)
I0130 04:34:02.328538  7239 sgd_solver.cpp:105] Iteration 75000, lr = 0.0008
I0130 04:34:25.797181  7239 solver.cpp:218] Iteration 75100 (4.26115 iter/s, 23.4678s/100 iters), loss = 0.00190488
I0130 04:34:25.797210  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190545 (* 1 = 0.00190545 loss)
I0130 04:34:25.797217  7239 sgd_solver.cpp:105] Iteration 75100, lr = 0.0008
I0130 04:34:49.192096  7239 solver.cpp:330] Iteration 75200, Testing net (#0)
I0130 04:35:05.871649  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:35:06.205068  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9603
I0130 04:35:06.205096  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156768 (* 1 = 0.156768 loss)
I0130 04:35:06.447193  7239 solver.cpp:218] Iteration 75200 (2.46011 iter/s, 40.6486s/100 iters), loss = 0.00174803
I0130 04:35:06.447218  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174861 (* 1 = 0.00174861 loss)
I0130 04:35:06.447227  7239 sgd_solver.cpp:105] Iteration 75200, lr = 0.0008
I0130 04:35:29.502687  7239 solver.cpp:218] Iteration 75300 (4.33752 iter/s, 23.0547s/100 iters), loss = 0.00213739
I0130 04:35:29.502761  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213797 (* 1 = 0.00213797 loss)
I0130 04:35:29.502770  7239 sgd_solver.cpp:105] Iteration 75300, lr = 0.0008
I0130 04:35:49.501749  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:35:52.731954  7239 solver.cpp:218] Iteration 75400 (4.30508 iter/s, 23.2284s/100 iters), loss = 0.00188253
I0130 04:35:52.731982  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188311 (* 1 = 0.00188311 loss)
I0130 04:35:52.731989  7239 sgd_solver.cpp:105] Iteration 75400, lr = 0.0008
I0130 04:36:15.931906  7239 solver.cpp:218] Iteration 75500 (4.31051 iter/s, 23.1991s/100 iters), loss = 0.00126018
I0130 04:36:15.934976  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126076 (* 1 = 0.00126076 loss)
I0130 04:36:15.934985  7239 sgd_solver.cpp:105] Iteration 75500, lr = 0.0008
I0130 04:36:39.175107  7239 solver.cpp:330] Iteration 75600, Testing net (#0)
I0130 04:36:55.861377  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:36:56.196879  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9604
I0130 04:36:56.196905  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.1565 (* 1 = 0.1565 loss)
I0130 04:36:56.442615  7239 solver.cpp:218] Iteration 75600 (2.46876 iter/s, 40.5062s/100 iters), loss = 0.00290688
I0130 04:36:56.442639  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290746 (* 1 = 0.00290746 loss)
I0130 04:36:56.442656  7239 sgd_solver.cpp:105] Iteration 75600, lr = 0.0008
I0130 04:37:19.473438  7239 solver.cpp:218] Iteration 75700 (4.34216 iter/s, 23.03s/100 iters), loss = 0.00109831
I0130 04:37:19.473464  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109889 (* 1 = 0.00109889 loss)
I0130 04:37:19.473471  7239 sgd_solver.cpp:105] Iteration 75700, lr = 0.0008
I0130 04:37:37.663725  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:37:42.981976  7239 solver.cpp:218] Iteration 75800 (4.25393 iter/s, 23.5077s/100 iters), loss = 0.0011316
I0130 04:37:42.982002  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113218 (* 1 = 0.00113218 loss)
I0130 04:37:42.982009  7239 sgd_solver.cpp:105] Iteration 75800, lr = 0.0008
I0130 04:38:06.705087  7239 solver.cpp:218] Iteration 75900 (4.21545 iter/s, 23.7223s/100 iters), loss = 0.00168563
I0130 04:38:06.705114  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168621 (* 1 = 0.00168621 loss)
I0130 04:38:06.705121  7239 sgd_solver.cpp:105] Iteration 75900, lr = 0.0008
I0130 04:38:30.003746  7239 solver.cpp:330] Iteration 76000, Testing net (#0)
I0130 04:38:46.823266  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:38:47.158236  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9604
I0130 04:38:47.158263  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155754 (* 1 = 0.155754 loss)
I0130 04:38:47.401093  7239 solver.cpp:218] Iteration 76000 (2.45733 iter/s, 40.6946s/100 iters), loss = 0.00208612
I0130 04:38:47.401116  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208669 (* 1 = 0.00208669 loss)
I0130 04:38:47.401131  7239 sgd_solver.cpp:105] Iteration 76000, lr = 0.0008
I0130 04:39:10.464280  7239 solver.cpp:218] Iteration 76100 (4.33607 iter/s, 23.0624s/100 iters), loss = 0.0025282
I0130 04:39:10.464359  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252878 (* 1 = 0.00252878 loss)
I0130 04:39:10.464372  7239 sgd_solver.cpp:105] Iteration 76100, lr = 0.0008
I0130 04:39:26.067625  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:39:33.753599  7239 solver.cpp:218] Iteration 76200 (4.29398 iter/s, 23.2884s/100 iters), loss = 0.00206846
I0130 04:39:33.753626  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206904 (* 1 = 0.00206904 loss)
I0130 04:39:33.753634  7239 sgd_solver.cpp:105] Iteration 76200, lr = 0.0008
I0130 04:39:57.261247  7239 solver.cpp:218] Iteration 76300 (4.25422 iter/s, 23.5061s/100 iters), loss = 0.00145654
I0130 04:39:57.261315  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145712 (* 1 = 0.00145712 loss)
I0130 04:39:57.261324  7239 sgd_solver.cpp:105] Iteration 76300, lr = 0.0008
I0130 04:40:20.358672  7239 solver.cpp:330] Iteration 76400, Testing net (#0)
I0130 04:40:37.101754  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:40:37.430346  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9602
I0130 04:40:37.430369  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156057 (* 1 = 0.156057 loss)
I0130 04:40:37.669986  7239 solver.cpp:218] Iteration 76400 (2.47496 iter/s, 40.4047s/100 iters), loss = 0.00153405
I0130 04:40:37.670012  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153463 (* 1 = 0.00153463 loss)
I0130 04:40:37.670023  7239 sgd_solver.cpp:105] Iteration 76400, lr = 0.0008
I0130 04:41:00.655793  7239 solver.cpp:218] Iteration 76500 (4.35093 iter/s, 22.9836s/100 iters), loss = 0.00185737
I0130 04:41:00.655823  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185795 (* 1 = 0.00185795 loss)
I0130 04:41:00.655831  7239 sgd_solver.cpp:105] Iteration 76500, lr = 0.0008
I0130 04:41:14.152598  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:41:23.979575  7239 solver.cpp:218] Iteration 76600 (4.28787 iter/s, 23.3216s/100 iters), loss = 0.0026762
I0130 04:41:23.979602  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267678 (* 1 = 0.00267678 loss)
I0130 04:41:23.979610  7239 sgd_solver.cpp:105] Iteration 76600, lr = 0.0008
I0130 04:41:47.303820  7239 solver.cpp:218] Iteration 76700 (4.28778 iter/s, 23.3221s/100 iters), loss = 0.00240658
I0130 04:41:47.303889  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240716 (* 1 = 0.00240716 loss)
I0130 04:41:47.303897  7239 sgd_solver.cpp:105] Iteration 76700, lr = 0.0008
I0130 04:42:10.469105  7239 solver.cpp:330] Iteration 76800, Testing net (#0)
I0130 04:42:27.187889  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:42:27.515672  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9606
I0130 04:42:27.515696  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155788 (* 1 = 0.155788 loss)
I0130 04:42:27.759599  7239 solver.cpp:218] Iteration 76800 (2.47205 iter/s, 40.4522s/100 iters), loss = 0.00147663
I0130 04:42:27.759626  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147721 (* 1 = 0.00147721 loss)
I0130 04:42:27.759637  7239 sgd_solver.cpp:105] Iteration 76800, lr = 0.0008
I0130 04:42:50.972220  7239 solver.cpp:218] Iteration 76900 (4.30837 iter/s, 23.2106s/100 iters), loss = 0.00147531
I0130 04:42:50.972249  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147589 (* 1 = 0.00147589 loss)
I0130 04:42:50.972255  7239 sgd_solver.cpp:105] Iteration 76900, lr = 0.0008
I0130 04:43:02.465484  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:43:14.448719  7239 solver.cpp:218] Iteration 77000 (4.25994 iter/s, 23.4745s/100 iters), loss = 0.0018511
I0130 04:43:14.448748  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185168 (* 1 = 0.00185168 loss)
I0130 04:43:14.448756  7239 sgd_solver.cpp:105] Iteration 77000, lr = 0.0008
I0130 04:43:38.035534  7239 solver.cpp:218] Iteration 77100 (4.24001 iter/s, 23.5849s/100 iters), loss = 0.00194988
I0130 04:43:38.035606  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195046 (* 1 = 0.00195046 loss)
I0130 04:43:38.035615  7239 sgd_solver.cpp:105] Iteration 77100, lr = 0.0008
I0130 04:44:01.403378  7239 solver.cpp:330] Iteration 77200, Testing net (#0)
I0130 04:44:18.145226  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:44:18.480156  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9601
I0130 04:44:18.480180  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156224 (* 1 = 0.156224 loss)
I0130 04:44:18.721756  7239 solver.cpp:218] Iteration 77200 (2.45803 iter/s, 40.683s/100 iters), loss = 0.00189275
I0130 04:44:18.721778  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189333 (* 1 = 0.00189333 loss)
I0130 04:44:18.721793  7239 sgd_solver.cpp:105] Iteration 77200, lr = 0.0008
I0130 04:44:41.942915  7239 solver.cpp:218] Iteration 77300 (4.30675 iter/s, 23.2194s/100 iters), loss = 0.00540289
I0130 04:44:41.942942  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540347 (* 1 = 0.00540347 loss)
I0130 04:44:41.942951  7239 sgd_solver.cpp:105] Iteration 77300, lr = 0.0008
I0130 04:44:51.045982  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:45:05.308578  7239 solver.cpp:218] Iteration 77400 (4.28011 iter/s, 23.3639s/100 iters), loss = 0.00137876
I0130 04:45:05.308607  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137934 (* 1 = 0.00137934 loss)
I0130 04:45:05.308614  7239 sgd_solver.cpp:105] Iteration 77400, lr = 0.0008
I0130 04:45:29.287472  7239 solver.cpp:218] Iteration 77500 (4.17065 iter/s, 23.9771s/100 iters), loss = 0.00136726
I0130 04:45:29.287546  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136784 (* 1 = 0.00136784 loss)
I0130 04:45:29.287559  7239 sgd_solver.cpp:105] Iteration 77500, lr = 0.0008
I0130 04:45:52.581766  7239 solver.cpp:330] Iteration 77600, Testing net (#0)
I0130 04:46:09.143645  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:46:09.477973  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9604
I0130 04:46:09.477996  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156504 (* 1 = 0.156504 loss)
I0130 04:46:09.722055  7239 solver.cpp:218] Iteration 77600 (2.47331 iter/s, 40.4316s/100 iters), loss = 0.00227164
I0130 04:46:09.722079  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227222 (* 1 = 0.00227222 loss)
I0130 04:46:09.722090  7239 sgd_solver.cpp:105] Iteration 77600, lr = 0.0008
I0130 04:46:32.866817  7239 solver.cpp:218] Iteration 77700 (4.32094 iter/s, 23.1431s/100 iters), loss = 0.00123225
I0130 04:46:32.866849  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123283 (* 1 = 0.00123283 loss)
I0130 04:46:32.866859  7239 sgd_solver.cpp:105] Iteration 77700, lr = 0.0008
I0130 04:46:40.050927  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:46:56.528539  7239 solver.cpp:218] Iteration 77800 (4.22653 iter/s, 23.6601s/100 iters), loss = 0.0040317
I0130 04:46:56.528570  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403228 (* 1 = 0.00403228 loss)
I0130 04:46:56.528581  7239 sgd_solver.cpp:105] Iteration 77800, lr = 0.0008
I0130 04:47:19.979841  7239 solver.cpp:218] Iteration 77900 (4.26445 iter/s, 23.4497s/100 iters), loss = 0.00181059
I0130 04:47:19.979914  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181117 (* 1 = 0.00181117 loss)
I0130 04:47:19.979923  7239 sgd_solver.cpp:105] Iteration 77900, lr = 0.0008
I0130 04:47:43.367074  7239 solver.cpp:330] Iteration 78000, Testing net (#0)
I0130 04:48:00.050882  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:48:00.386736  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9602
I0130 04:48:00.386759  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155664 (* 1 = 0.155664 loss)
I0130 04:48:00.633769  7239 solver.cpp:218] Iteration 78000 (2.45995 iter/s, 40.6512s/100 iters), loss = 0.00135827
I0130 04:48:00.633793  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135885 (* 1 = 0.00135885 loss)
I0130 04:48:00.633803  7239 sgd_solver.cpp:105] Iteration 78000, lr = 0.0008
I0130 04:48:23.722250  7239 solver.cpp:218] Iteration 78100 (4.33145 iter/s, 23.087s/100 iters), loss = 0.00127242
I0130 04:48:23.722278  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001273 (* 1 = 0.001273 loss)
I0130 04:48:23.722286  7239 sgd_solver.cpp:105] Iteration 78100, lr = 0.0008
I0130 04:48:28.615732  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:48:47.294808  7239 solver.cpp:218] Iteration 78200 (4.2425 iter/s, 23.571s/100 iters), loss = 0.001798
I0130 04:48:47.294878  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179858 (* 1 = 0.00179858 loss)
I0130 04:48:47.294888  7239 sgd_solver.cpp:105] Iteration 78200, lr = 0.0008
I0130 04:49:10.753954  7239 solver.cpp:218] Iteration 78300 (4.26301 iter/s, 23.4576s/100 iters), loss = 0.00128627
I0130 04:49:10.753981  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128685 (* 1 = 0.00128685 loss)
I0130 04:49:10.753989  7239 sgd_solver.cpp:105] Iteration 78300, lr = 0.0008
I0130 04:49:33.930227  7239 solver.cpp:330] Iteration 78400, Testing net (#0)
I0130 04:49:50.773686  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:49:51.105034  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.96
I0130 04:49:51.105062  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156459 (* 1 = 0.156459 loss)
I0130 04:49:51.346406  7239 solver.cpp:218] Iteration 78400 (2.46367 iter/s, 40.5899s/100 iters), loss = 0.00124723
I0130 04:49:51.346431  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124781 (* 1 = 0.00124781 loss)
I0130 04:49:51.346446  7239 sgd_solver.cpp:105] Iteration 78400, lr = 0.0008
I0130 04:50:14.545717  7239 solver.cpp:218] Iteration 78500 (4.31074 iter/s, 23.1979s/100 iters), loss = 0.011386
I0130 04:50:14.545786  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113866 (* 1 = 0.0113866 loss)
I0130 04:50:14.545799  7239 sgd_solver.cpp:105] Iteration 78500, lr = 0.0008
I0130 04:50:17.170384  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:50:38.112732  7239 solver.cpp:218] Iteration 78600 (4.24348 iter/s, 23.5655s/100 iters), loss = 0.00363069
I0130 04:50:38.112759  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363127 (* 1 = 0.00363127 loss)
I0130 04:50:38.112767  7239 sgd_solver.cpp:105] Iteration 78600, lr = 0.0008
I0130 04:51:01.657804  7239 solver.cpp:218] Iteration 78700 (4.24743 iter/s, 23.5437s/100 iters), loss = 0.00123917
I0130 04:51:01.658391  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123975 (* 1 = 0.00123975 loss)
I0130 04:51:01.658401  7239 sgd_solver.cpp:105] Iteration 78700, lr = 0.0008
I0130 04:51:24.938478  7239 solver.cpp:330] Iteration 78800, Testing net (#0)
I0130 04:51:41.549664  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:51:41.891577  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9595
I0130 04:51:41.891602  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156597 (* 1 = 0.156597 loss)
I0130 04:51:42.133649  7239 solver.cpp:218] Iteration 78800 (2.47079 iter/s, 40.4729s/100 iters), loss = 0.00148151
I0130 04:51:42.133674  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148209 (* 1 = 0.00148209 loss)
I0130 04:51:42.133685  7239 sgd_solver.cpp:105] Iteration 78800, lr = 0.0008
I0130 04:52:05.348635  7239 solver.cpp:218] Iteration 78900 (4.30781 iter/s, 23.2136s/100 iters), loss = 0.00414781
I0130 04:52:05.348664  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414839 (* 1 = 0.00414839 loss)
I0130 04:52:05.348671  7239 sgd_solver.cpp:105] Iteration 78900, lr = 0.0008
I0130 04:52:05.816608  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:52:28.524163  7239 solver.cpp:218] Iteration 79000 (4.31515 iter/s, 23.1742s/100 iters), loss = 0.000985434
I0130 04:52:28.526054  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000986014 (* 1 = 0.000986014 loss)
I0130 04:52:28.526063  7239 sgd_solver.cpp:105] Iteration 79000, lr = 0.0008
I0130 04:52:52.077167  7239 solver.cpp:218] Iteration 79100 (4.24632 iter/s, 23.5498s/100 iters), loss = 0.00212816
I0130 04:52:52.077193  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212874 (* 1 = 0.00212874 loss)
I0130 04:52:52.077201  7239 sgd_solver.cpp:105] Iteration 79100, lr = 0.0008
I0130 04:53:15.558933  7239 solver.cpp:330] Iteration 79200, Testing net (#0)
I0130 04:53:32.002406  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:53:32.339503  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9606
I0130 04:53:32.339524  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155526 (* 1 = 0.155526 loss)
I0130 04:53:32.586997  7239 solver.cpp:218] Iteration 79200 (2.46867 iter/s, 40.5076s/100 iters), loss = 0.00225577
I0130 04:53:32.587023  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225635 (* 1 = 0.00225635 loss)
I0130 04:53:32.587033  7239 sgd_solver.cpp:105] Iteration 79200, lr = 0.0008
I0130 04:53:53.902848  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:53:55.735314  7239 solver.cpp:218] Iteration 79300 (4.32021 iter/s, 23.147s/100 iters), loss = 0.00135768
I0130 04:53:55.735340  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135826 (* 1 = 0.00135826 loss)
I0130 04:53:55.735347  7239 sgd_solver.cpp:105] Iteration 79300, lr = 0.0008
I0130 04:54:19.314797  7239 solver.cpp:218] Iteration 79400 (4.24121 iter/s, 23.5782s/100 iters), loss = 0.00165699
I0130 04:54:19.314831  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165757 (* 1 = 0.00165757 loss)
I0130 04:54:19.314841  7239 sgd_solver.cpp:105] Iteration 79400, lr = 0.0008
I0130 04:54:42.976977  7239 solver.cpp:218] Iteration 79500 (4.22638 iter/s, 23.6609s/100 iters), loss = 0.00151612
I0130 04:54:42.980131  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015167 (* 1 = 0.0015167 loss)
I0130 04:54:42.980140  7239 sgd_solver.cpp:105] Iteration 79500, lr = 0.0008
I0130 04:55:06.119043  7239 solver.cpp:330] Iteration 79600, Testing net (#0)
I0130 04:55:22.993418  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:55:23.325942  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9603
I0130 04:55:23.325965  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.155695 (* 1 = 0.155695 loss)
I0130 04:55:23.570796  7239 solver.cpp:218] Iteration 79600 (2.46375 iter/s, 40.5885s/100 iters), loss = 0.00222691
I0130 04:55:23.570822  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222749 (* 1 = 0.00222749 loss)
I0130 04:55:23.570829  7239 sgd_solver.cpp:105] Iteration 79600, lr = 0.0008
I0130 04:55:42.616133  7260 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:55:46.515120  7239 solver.cpp:218] Iteration 79700 (4.35861 iter/s, 22.9431s/100 iters), loss = 0.00134593
I0130 04:55:46.515146  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134651 (* 1 = 0.00134651 loss)
I0130 04:55:46.515154  7239 sgd_solver.cpp:105] Iteration 79700, lr = 0.0008
I0130 04:56:09.847800  7239 solver.cpp:218] Iteration 79800 (4.28606 iter/s, 23.3315s/100 iters), loss = 0.00111655
I0130 04:56:09.847870  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111713 (* 1 = 0.00111713 loss)
I0130 04:56:09.847879  7239 sgd_solver.cpp:105] Iteration 79800, lr = 0.0008
I0130 04:56:33.518365  7239 solver.cpp:218] Iteration 79900 (4.22488 iter/s, 23.6693s/100 iters), loss = 0.0014396
I0130 04:56:33.518394  7239 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144018 (* 1 = 0.00144018 loss)
I0130 04:56:33.518402  7239 sgd_solver.cpp:105] Iteration 79900, lr = 0.0008
I0130 04:56:57.028745  7239 solver.cpp:447] Snapshotting to binary proto file examples/bao/WRN-28_iter_80000.caffemodel
I0130 04:56:57.372119  7239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/bao/WRN-28_iter_80000.solverstate
I0130 04:56:57.632643  7239 solver.cpp:310] Iteration 80000, loss = 0.00133615
I0130 04:56:57.632668  7239 solver.cpp:330] Iteration 80000, Testing net (#0)
I0130 04:57:14.263834  7264 data_layer.cpp:73] Restarting data prefetching from start.
I0130 04:57:14.599321  7239 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9608
I0130 04:57:14.599349  7239 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.156685 (* 1 = 0.156685 loss)
I0130 04:57:14.599355  7239 solver.cpp:315] Optimization Done.
I0130 04:57:16.573339  7239 caffe.cpp:259] Optimization Done.
